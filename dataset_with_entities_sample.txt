['620' '61.0' '13'
 "Note that contrarily to the pre-tokenizer or the normalizer, you don't\nneed to retrain a tokenizer after changing its post-processor.\n\n## All together: a BERT tokenizer from scratch\n\nLet's put all those pieces together to build a BERT tokenizer. First,\nBERT relies on WordPiece, so we instantiate a new\n`Tokenizer` with this model:"
 list([{'entity_group': 'ORG', 'score': 0.65435356, 'word': 'BERT', 'start': 154, 'end': 158}, {'entity_group': 'MISC', 'score': 0.5543117, 'word': 'B', 'start': 230, 'end': 231}, {'entity_group': 'ORG', 'score': 0.55342877, 'word': '##ERT', 'start': 231, 'end': 234}, {'entity_group': 'ORG', 'score': 0.9138827, 'word': 'BERT', 'start': 253, 'end': 257}, {'entity_group': 'ORG', 'score': 0.8661185, 'word': 'WordPiece', 'start': 268, 'end': 277}, {'entity_group': 'MISC', 'score': 0.47593698, 'word': 'To', 'start': 304, 'end': 306}])
 list([{'entity_group': 'ORG', 'score': 0.9138827, 'word': 'BERT', 'start': 253, 'end': 257}, {'entity_group': 'ORG', 'score': 0.8661185, 'word': 'WordPiece', 'start': 268, 'end': 277}])]
['621' '61.0' '14'
 '<tokenizerslangcontent>\n<python>\n<literalinclude>\n{"path": "../../bindings/python/tests/documentation/test_pipeline.py",\n"language": "python",\n"start-after": "START bert_setup_tokenizer",\n"end-before": "END bert_setup_tokenizer",\n"dedent": 8}\n</literalinclude>\n</python>\n<rust>\n<literalinclude>\n{"path": "../../tokenizers/tests/documentation.rs",\n"language": "rust",\n"start-after": "START bert_setup_tokenizer",\n"end-before": "END bert_setup_tokenizer",\n"dedent": 4}\n</literalinclude>\n</rust>\n<node>\n<literalinclude>\n{"path": "../../bindings/node/examples/documentation/pipeline.test.ts",\n"language": "js",\n"start-after": "START bert_setup_tokenizer",\n"end-before": "END bert_setup_tokenizer",\n"dedent": 8}\n</literalinclude>\n</node>\n</tokenizerslangcontent>\n\nThen we know that BERT preprocesses texts by removing accents and\nlowercasing. We also use a unicode normalizer:'
 list([{'entity_group': 'ORG', 'score': 0.6955044, 'word': 'BERT', 'start': 777, 'end': 781}])
 list([])]
['622' '61.0' '15'
 '<tokenizerslangcontent>\n<python>\n<literalinclude>\n{"path": "../../bindings/python/tests/documentation/test_pipeline.py",\n"language": "python",\n"start-after": "START bert_setup_normalizer",\n"end-before": "END bert_setup_normalizer",\n"dedent": 8}\n</literalinclude>\n</python>\n<rust>\n<literalinclude>\n{"path": "../../tokenizers/tests/documentation.rs",\n"language": "rust",\n"start-after": "START bert_setup_normalizer",\n"end-before": "END bert_setup_normalizer",\n"dedent": 4}\n</literalinclude>\n</rust>\n<node>\n<literalinclude>\n{"path": "../../bindings/node/examples/documentation/pipeline.test.ts",\n"language": "js",\n"start-after": "START bert_setup_normalizer",\n"end-before": "END bert_setup_normalizer",\n"dedent": 8}\n</literalinclude>\n</node>\n</tokenizerslangcontent>\n\nThe pre-tokenizer is just splitting on whitespace and punctuation:'
 list([]) list([])]
['623' '61.0' '16'
 'The pre-tokenizer is just splitting on whitespace and punctuation:\n\n<tokenizerslangcontent>\n<python>\n<literalinclude>\n{"path": "../../bindings/python/tests/documentation/test_pipeline.py",\n"language": "python",\n"start-after": "START bert_setup_pre_tokenizer",\n"end-before": "END bert_setup_pre_tokenizer",\n"dedent": 8}\n</literalinclude>\n</python>\n<rust>\n<literalinclude>\n{"path": "../../tokenizers/tests/documentation.rs",\n"language": "rust",\n"start-after": "START bert_setup_pre_tokenizer",\n"end-before": "END bert_setup_pre_tokenizer",\n"dedent": 4}\n</literalinclude>\n</rust>\n<node>\n<literalinclude>\n{"path": "../../bindings/node/examples/documentation/pipeline.test.ts",\n"language": "js",\n"start-after": "START bert_setup_pre_tokenizer",\n"end-before": "END bert_setup_pre_tokenizer",\n"dedent": 8}\n</literalinclude>\n</node>\n</tokenizerslangcontent>\n\nAnd the post-processing uses the template we saw in the previous\nsection:'
 list([]) list([])]
['624' '61.0' '17'
 'And the post-processing uses the template we saw in the previous\nsection:\n\n<tokenizerslangcontent>\n<python>\n<literalinclude>\n{"path": "../../bindings/python/tests/documentation/test_pipeline.py",\n"language": "python",\n"start-after": "START bert_setup_processor",\n"end-before": "END bert_setup_processor",\n"dedent": 8}\n</literalinclude>\n</python>\n<rust>\n<literalinclude>\n{"path": "../../tokenizers/tests/documentation.rs",\n"language": "rust",\n"start-after": "START bert_setup_processor",\n"end-before": "END bert_setup_processor",\n"dedent": 4}\n</literalinclude>\n</rust>\n<node>\n<literalinclude>\n{"path": "../../bindings/node/examples/documentation/pipeline.test.ts",\n"language": "js",\n"start-after": "START bert_setup_processor",\n"end-before": "END bert_setup_processor",\n"dedent": 8}\n</literalinclude>\n</node>\n</tokenizerslangcontent>\n\nWe can use this tokenizer and train on it on wikitext like in the\n`quicktour`:'
 list([]) list([])]
['625' '61.0' '18'
 'We can use this tokenizer and train on it on wikitext like in the\n`quicktour`:\n\n<tokenizerslangcontent>\n<python>\n<literalinclude>\n{"path": "../../bindings/python/tests/documentation/test_pipeline.py",\n"language": "python",\n"start-after": "START bert_train_tokenizer",\n"end-before": "END bert_train_tokenizer",\n"dedent": 8}\n</literalinclude>\n</python>\n<rust>\n<literalinclude>\n{"path": "../../tokenizers/tests/documentation.rs",\n"language": "rust",\n"start-after": "START bert_train_tokenizer",\n"end-before": "END bert_train_tokenizer",\n"dedent": 4}\n</literalinclude>\n</rust>\n<node>\n<literalinclude>\n{"path": "../../bindings/node/examples/documentation/pipeline.test.ts",\n"language": "js",\n"start-after": "START bert_train_tokenizer",\n"end-before": "END bert_train_tokenizer",\n"dedent": 8}\n</literalinclude>\n</node>\n</tokenizerslangcontent>\n\n## Decoding'
 list([]) list([])]
['626' '61.0' '19'
 "## Decoding\n\nOn top of encoding the input texts, a `Tokenizer` also has an API for decoding, that is converting IDs\ngenerated by your model back to a text. This is done by the methods\n`Tokenizer.decode` (for one predicted text) and `Tokenizer.decode_batch` (for a batch of predictions).\n\nThe `decoder` will first convert the IDs back to tokens\n(using the tokenizer's vocabulary) and remove all special tokens, then\njoin those tokens with spaces:"
 list([]) list([])]
['627' '61.0' '20'
 '<tokenizerslangcontent>\n<python>\n<literalinclude>\n{"path": "../../bindings/python/tests/documentation/test_pipeline.py",\n"language": "python",\n"start-after": "START test_decoding",\n"end-before": "END test_decoding",\n"dedent": 8}\n</literalinclude>\n</python>\n<rust>\n<literalinclude>\n{"path": "../../tokenizers/tests/documentation.rs",\n"language": "rust",\n"start-after": "START pipeline_test_decoding",\n"end-before": "END pipeline_test_decoding",\n"dedent": 4}\n</literalinclude>\n</rust>\n<node>\n<literalinclude>\n{"path": "../../bindings/node/examples/documentation/pipeline.test.ts",\n"language": "js",\n"start-after": "START test_decoding",\n"end-before": "END test_decoding",\n"dedent": 8}\n</literalinclude>\n</node>\n</tokenizerslangcontent>'
 list([]) list([])]
['628' '61.0' '21'
 'If you used a model that added special characters to represent subtokens\nof a given "word" (like the `"##"` in\nWordPiece) you will need to customize the `decoder` to treat\nthem properly. If we take our previous `bert_tokenizer` for instance the\ndefault decoding will give:'
 list([{'entity_group': 'MISC', 'score': 0.6364296, 'word': 'Word', 'start': 111, 'end': 115}, {'entity_group': 'ORG', 'score': 0.7351001, 'word': '##Piece', 'start': 115, 'end': 120}])
 list([])]
['629' '61.0' '22'
 '<tokenizerslangcontent>\n<python>\n<literalinclude>\n{"path": "../../bindings/python/tests/documentation/test_pipeline.py",\n"language": "python",\n"start-after": "START bert_test_decoding",\n"end-before": "END bert_test_decoding",\n"dedent": 8}\n</literalinclude>\n</python>\n<rust>\n<literalinclude>\n{"path": "../../tokenizers/tests/documentation.rs",\n"language": "rust",\n"start-after": "START bert_test_decoding",\n"end-before": "END bert_test_decoding",\n"dedent": 4}\n</literalinclude>\n</rust>\n<node>\n<literalinclude>\n{"path": "../../bindings/node/examples/documentation/pipeline.test.ts",\n"language": "js",\n"start-after": "START bert_test_decoding",\n"end-before": "END bert_test_decoding",\n"dedent": 8}\n</literalinclude>\n</node>\n</tokenizerslangcontent>\n\nBut by changing it to a proper decoder, we get:'
 list([]) list([])]
['630' '61.0' '23'
 'But by changing it to a proper decoder, we get:\n\n<tokenizerslangcontent>\n<python>\n<literalinclude>\n{"path": "../../bindings/python/tests/documentation/test_pipeline.py",\n"language": "python",\n"start-after": "START bert_proper_decoding",\n"end-before": "END bert_proper_decoding",\n"dedent": 8}\n</literalinclude>\n</python>\n<rust>\n<literalinclude>\n{"path": "../../tokenizers/tests/documentation.rs",\n"language": "rust",\n"start-after": "START bert_proper_decoding",\n"end-before": "END bert_proper_decoding",\n"dedent": 4}\n</literalinclude>\n</rust>\n<node>\n<literalinclude>\n{"path": "../../bindings/node/examples/documentation/pipeline.test.ts",\n"language": "js",\n"start-after": "START bert_proper_decoding",\n"end-before": "END bert_proper_decoding",\n"dedent": 8}\n</literalinclude>\n</node>\n</tokenizerslangcontent>'
 list([]) list([])]
['631' '62.0' '0'
 "TResNet\n\nA **TResNet** is a variant on a [ResNet](https://paperswithcode.com/method/resnet) that aim to boost accuracy while maintaining GPU training and inference efficiency.  They contain several design tricks including a SpaceToDepth stem, [Anti-Alias downsampling](https://paperswithcode.com/method/anti-alias-downsampling), In-Place Activated BatchNorm, Blocks selection and [squeeze-and-excitation layers](https://paperswithcode.com/method/squeeze-and-excitation-block).\n\n## How do I use this model on an image?\nTo load a pretrained model:\n\n```python\nimport timm\nmodel = timm.create_model('tresnet_l', pretrained=True)\nmodel.eval()"
 list([{'entity_group': 'MISC', 'score': 0.48554307, 'word': '##esNet', 'start': 2, 'end': 7}, {'entity_group': 'MISC', 'score': 0.54325473, 'word': '##esNet', 'start': 15, 'end': 20}, {'entity_group': 'MISC', 'score': 0.7326646, 'word': 'ResNet', 'start': 42, 'end': 48}, {'entity_group': 'MISC', 'score': 0.45917267, 'word': 'Space', 'start': 224, 'end': 229}, {'entity_group': 'ORG', 'score': 0.6134926, 'word': '##Dept', 'start': 231, 'end': 235}, {'entity_group': 'MISC', 'score': 0.675466, 'word': 'Alias', 'start': 249, 'end': 254}])
 list([])]
['632' '62.0' '1'
 '```\n\nTo load and preprocess the image:\n```python \nimport urllib\nfrom PIL import Image\nfrom timm.data import resolve_data_config\nfrom timm.data.transforms_factory import create_transform\n\nconfig = resolve_data_config({}, model=model)\ntransform = create_transform(**config)\n\nurl, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")\nurllib.request.urlretrieve(url, filename)\nimg = Image.open(filename).convert(\'RGB\')\ntensor = transform(img).unsqueeze(0) # transform and add batch dimension\n```\n\nTo get the model predictions:\n```python\nimport torch\nwith torch.no_grad():\n    out = model(tensor)\nprobabilities = torch.nn.functional.softmax(out[0], dim=0)\nprint(probabilities.shape)\n# prints: torch.Size([1000])'
 list([{'entity_group': 'ORG', 'score': 0.96517193, 'word': 'PIL', 'start': 69, 'end': 72}])
 list([{'entity_group': 'ORG', 'score': 0.96517193, 'word': 'PIL', 'start': 69, 'end': 72}])]
['633' '62.0' '2'
 '```\n\nTo get the top-5 predictions class names:\n```python\n# Get imagenet class mappings\nurl, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")\nurllib.request.urlretrieve(url, filename) \nwith open("imagenet_classes.txt", "r") as f:\n    categories = [s.strip() for s in f.readlines()]\n\n# Print top categories per image\ntop5_prob, top5_catid = torch.topk(probabilities, 5)\nfor i in range(top5_prob.size(0)):\n    print(categories[top5_catid[i]], top5_prob[i].item())\n# prints class names and probabilities like:\n# [(\'Samoyed\', 0.6425196528434753), (\'Pomeranian\', 0.04062102362513542), (\'keeshond\', 0.03186424449086189), (\'white wolf\', 0.01739676296710968), (\'Eskimo dog\', 0.011717947199940681)]'
 list([{'entity_group': 'MISC', 'score': 0.73558086, 'word': 'Samoyed', 'start': 575, 'end': 582}, {'entity_group': 'MISC', 'score': 0.9528955, 'word': 'Pomeranian', 'start': 608, 'end': 618}, {'entity_group': 'MISC', 'score': 0.97252536, 'word': 'Eskimo', 'start': 717, 'end': 723}])
 list([{'entity_group': 'MISC', 'score': 0.9528955, 'word': 'Pomeranian', 'start': 608, 'end': 618}, {'entity_group': 'MISC', 'score': 0.97252536, 'word': 'Eskimo', 'start': 717, 'end': 723}])]
['634' '62.0' '3'
 "```\n\nReplace the model name with the variant you want to use, e.g. `tresnet_l`. You can find the IDs in the model summaries at the top of this page.\n\nTo extract image features with this model, follow the [timm feature extraction examples](https://rwightman.github.io/pytorch-image-models/feature_extraction/), just change the name of the model you want to use.\n\n## How do I finetune this model?\nYou can finetune any of the pre-trained models just by changing the classifier (the last layer).\n```python\nmodel = timm.create_model('tresnet_l', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)"
 list([]) list([])]
['635' '62.0' '4'
 "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscript](https://github.com/rwightman/pytorch-image-models/blob/master/train.py) to use your dataset.\n\n## How do I train this model?\n\nYou can follow the [timm recipe scripts](https://rwightman.github.io/pytorch-image-models/scripts/) for training a new model afresh.\n\n## Citation\n\n```BibTeX\n@misc{ridnik2020tresnet,\n      title={TResNet: High Performance GPU-Dedicated Architecture}, \n      author={Tal Ridnik and Hussam Lawen and Asaf Noy and Emanuel Ben Baruch and Gilad Sharir and Itamar Friedman},\n      year={2020},\n      eprint={2003.13630},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}"
 list([{'entity_group': 'ORG', 'score': 0.47893512, 'word': '##R', 'start': 426, 'end': 427}, {'entity_group': 'PER', 'score': 0.9956848, 'word': 'Tal Ridnik', 'start': 495, 'end': 505}, {'entity_group': 'PER', 'score': 0.99814165, 'word': 'Hussam Lawen', 'start': 510, 'end': 522}, {'entity_group': 'PER', 'score': 0.9956679, 'word': 'Asaf Noy', 'start': 527, 'end': 535}, {'entity_group': 'PER', 'score': 0.9986834, 'word': 'Emanuel Ben Baruch', 'start': 540, 'end': 558}, {'entity_group': 'PER', 'score': 0.9983972, 'word': 'Gilad Sharir', 'start': 563, 'end': 575}, {'entity_group': 'PER', 'score': 0.9980526, 'word': 'Itamar Friedman', 'start': 580, 'end': 595}])
 list([{'entity_group': 'PER', 'score': 0.9956848, 'word': 'Tal Ridnik', 'start': 495, 'end': 505}, {'entity_group': 'PER', 'score': 0.99814165, 'word': 'Hussam Lawen', 'start': 510, 'end': 522}, {'entity_group': 'PER', 'score': 0.9956679, 'word': 'Asaf Noy', 'start': 527, 'end': 535}, {'entity_group': 'PER', 'score': 0.9986834, 'word': 'Emanuel Ben Baruch', 'start': 540, 'end': 558}, {'entity_group': 'PER', 'score': 0.9983972, 'word': 'Gilad Sharir', 'start': 563, 'end': 575}, {'entity_group': 'PER', 'score': 0.9980526, 'word': 'Itamar Friedman', 'start': 580, 'end': 595}])]
['636' '62.0' '5' '```'
 list([{'entity_group': 'PER', 'score': 0.4322449, 'word': '`', 'start': 0, 'end': 1}, {'entity_group': 'PER', 'score': 0.43227673, 'word': '`', 'start': 1, 'end': 2}, {'entity_group': 'PER', 'score': 0.43234685, 'word': '`', 'start': 2, 'end': 3}])
 list([])]
['637' '62.0' '6'
 "<!--\nType: model-index\nCollections:\n- Name: TResNet\n  Paper:\n    Title: 'TResNet: High Performance GPU-Dedicated Architecture'\n    URL: https://paperswithcode.com/paper/tresnet-high-performance-gpu-dedicated\nModels:\n- Name: tresnet_l\n  In Collection: TResNet\n  Metadata:\n    FLOPs: 10873416792\n    Parameters: 53456696\n    File Size: 224440219\n    Architecture:\n    - 1x1 Convolution\n    - Anti-Alias Downsampling\n    - Convolution\n    - Global Average Pooling\n    - InPlace-ABN\n    - Leaky ReLU\n    - ReLU\n    - Residual Connection\n    - Squeeze-and-Excitation Block\n    Tasks:\n    - Image Classification\n    Training Techniques:\n    - AutoAugment\n    - Cutout\n    - Label Smoothing\n    - SGD with Momentum\n    - Weight Decay\n    Training Data:\n    - ImageNet\n    Training Resources: 8x NVIDIA 100 GPUs\n    ID: tresnet_l\n    LR: 0.01\n    Epochs: 300\n    Crop Pct: '0.875'\n    Momentum: 0.9\n    Image Size: '224'\n    Weight Decay: 0.0001\n    Interpolation: bilinear"
 list([{'entity_group': 'ORG', 'score': 0.9090037, 'word': 'TResNet', 'start': 44, 'end': 51}, {'entity_group': 'ORG', 'score': 0.45059222, 'word': '##R', 'start': 74, 'end': 75}, {'entity_group': 'ORG', 'score': 0.46158358, 'word': '##Net', 'start': 77, 'end': 80}, {'entity_group': 'ORG', 'score': 0.9499634, 'word': 'TResNet', 'start': 251, 'end': 258}, {'entity_group': 'ORG', 'score': 0.8678832, 'word': 'ImageNet', 'start': 752, 'end': 760}, {'entity_group': 'MISC', 'score': 0.8716833, 'word': 'NVIDIA', 'start': 788, 'end': 794}])
 list([{'entity_group': 'ORG', 'score': 0.9090037, 'word': 'TResNet', 'start': 44, 'end': 51}, {'entity_group': 'ORG', 'score': 0.9499634, 'word': 'TResNet', 'start': 251, 'end': 258}, {'entity_group': 'ORG', 'score': 0.8678832, 'word': 'ImageNet', 'start': 752, 'end': 760}, {'entity_group': 'MISC', 'score': 0.8716833, 'word': 'NVIDIA', 'start': 788, 'end': 794}])]
['638' '62.0' '7'
 "Momentum: 0.9\n    Image Size: '224'\n    Weight Decay: 0.0001\n    Interpolation: bilinear\n  Code: https://github.com/rwightman/pytorch-image-models/blob/9a25fdf3ad0414b4d66da443fe60ae0aa14edc84/timm/models/tresnet.py#L267\n  Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_l_81_5-235b486c.pth\n  Results:\n  - Task: Image Classification\n    Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 81.49%\n      Top 5 Accuracy: 95.62%\n- Name: tresnet_l_448\n  In Collection: TResNet\n  Metadata:\n    FLOPs: 43488238584\n    Parameters: 53456696\n    File Size: 224440219\n    Architecture:\n    - 1x1 Convolution\n    - Anti-Alias Downsampling\n    - Convolution\n    - Global Average Pooling\n    - InPlace-ABN\n    - Leaky ReLU\n    - ReLU\n    - Residual Connection\n    - Squeeze-and-Excitation Block\n    Tasks:\n    - Image Classification\n    Training Techniques:\n    - AutoAugment\n    - Cutout\n    - Label Smoothing\n    - SGD with Momentum\n    - Weight Decay"
 list([{'entity_group': 'ORG', 'score': 0.5977907, 'word': 'g', 'start': 105, 'end': 106}, {'entity_group': 'ORG', 'score': 0.6302323, 'word': 'ImageNet', 'start': 396, 'end': 404}, {'entity_group': 'ORG', 'score': 0.90094227, 'word': 'TResNet', 'start': 515, 'end': 522}])
 list([{'entity_group': 'ORG', 'score': 0.90094227, 'word': 'TResNet', 'start': 515, 'end': 522}])]
['639' '62.0' '8'
 "- AutoAugment\n    - Cutout\n    - Label Smoothing\n    - SGD with Momentum\n    - Weight Decay\n    Training Data:\n    - ImageNet\n    Training Resources: 8x NVIDIA 100 GPUs\n    ID: tresnet_l_448\n    LR: 0.01\n    Epochs: 300\n    Crop Pct: '0.875'\n    Momentum: 0.9\n    Image Size: '448'\n    Weight Decay: 0.0001\n    Interpolation: bilinear\n  Code: https://github.com/rwightman/pytorch-image-models/blob/9a25fdf3ad0414b4d66da443fe60ae0aa14edc84/timm/models/tresnet.py#L285\n  Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_l_448-940d0cd1.pth\n  Results:\n  - Task: Image Classification\n    Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 82.26%\n      Top 5 Accuracy: 95.98%\n- Name: tresnet_m\n  In Collection: TResNet\n  Metadata:\n    FLOPs: 5733048064\n    Parameters: 41282200\n    File Size: 125861314\n    Architecture:\n    - 1x1 Convolution\n    - Anti-Alias Downsampling\n    - Convolution\n    - Global Average Pooling\n    - InPlace-ABN"
 list([{'entity_group': 'ORG', 'score': 0.7085008, 'word': 'S', 'start': 55, 'end': 56}, {'entity_group': 'ORG', 'score': 0.9344478, 'word': 'ImageNet', 'start': 117, 'end': 125}, {'entity_group': 'MISC', 'score': 0.81028044, 'word': 'NVIDIA', 'start': 153, 'end': 159}, {'entity_group': 'ORG', 'score': 0.89466274, 'word': 'ImageNet', 'start': 641, 'end': 649}, {'entity_group': 'ORG', 'score': 0.8027929, 'word': 'TR', 'start': 756, 'end': 758}, {'entity_group': 'ORG', 'score': 0.4720594, 'word': '##Net', 'start': 760, 'end': 763}])
 list([{'entity_group': 'ORG', 'score': 0.9344478, 'word': 'ImageNet', 'start': 117, 'end': 125}, {'entity_group': 'MISC', 'score': 0.81028044, 'word': 'NVIDIA', 'start': 153, 'end': 159}, {'entity_group': 'ORG', 'score': 0.89466274, 'word': 'ImageNet', 'start': 641, 'end': 649}, {'entity_group': 'ORG', 'score': 0.8027929, 'word': 'TR', 'start': 756, 'end': 758}])]
['640' '62.0' '9'
 "- Anti-Alias Downsampling\n    - Convolution\n    - Global Average Pooling\n    - InPlace-ABN\n    - Leaky ReLU\n    - ReLU\n    - Residual Connection\n    - Squeeze-and-Excitation Block\n    Tasks:\n    - Image Classification\n    Training Techniques:\n    - AutoAugment\n    - Cutout\n    - Label Smoothing\n    - SGD with Momentum\n    - Weight Decay\n    Training Data:\n    - ImageNet\n    Training Resources: 8x NVIDIA 100 GPUs\n    Training Time: < 24 hours\n    ID: tresnet_m\n    LR: 0.01\n    Epochs: 300\n    Crop Pct: '0.875'\n    Momentum: 0.9\n    Image Size: '224'\n    Weight Decay: 0.0001\n    Interpolation: bilinear\n  Code: https://github.com/rwightman/pytorch-image-models/blob/9a25fdf3ad0414b4d66da443fe60ae0aa14edc84/timm/models/tresnet.py#L261\n  Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_m_80_8-dbc13962.pth\n  Results:\n  - Task: Image Classification\n    Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 80.8%\n      Top 5 Accuracy: 94.86%"
 list([{'entity_group': 'ORG', 'score': 0.6068534, 'word': 'ImageNet', 'start': 364, 'end': 372}, {'entity_group': 'MISC', 'score': 0.89921665, 'word': 'N', 'start': 400, 'end': 401}, {'entity_group': 'MISC', 'score': 0.49409083, 'word': '##DI', 'start': 403, 'end': 405}, {'entity_group': 'ORG', 'score': 0.63739944, 'word': 'ImageNet', 'start': 915, 'end': 923}])
 list([{'entity_group': 'MISC', 'score': 0.89921665, 'word': 'N', 'start': 400, 'end': 401}])]
['641' '62.0' '10'
 "Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 80.8%\n      Top 5 Accuracy: 94.86%\n- Name: tresnet_m_448\n  In Collection: TResNet\n  Metadata:\n    FLOPs: 22929743104\n    Parameters: 29278464\n    File Size: 125861314\n    Architecture:\n    - 1x1 Convolution\n    - Anti-Alias Downsampling\n    - Convolution\n    - Global Average Pooling\n    - InPlace-ABN\n    - Leaky ReLU\n    - ReLU\n    - Residual Connection\n    - Squeeze-and-Excitation Block\n    Tasks:\n    - Image Classification\n    Training Techniques:\n    - AutoAugment\n    - Cutout\n    - Label Smoothing\n    - SGD with Momentum\n    - Weight Decay\n    Training Data:\n    - ImageNet\n    Training Resources: 8x NVIDIA 100 GPUs\n    ID: tresnet_m_448\n    LR: 0.01\n    Epochs: 300\n    Crop Pct: '0.875'\n    Momentum: 0.9\n    Image Size: '448'\n    Weight Decay: 0.0001\n    Interpolation: bilinear\n  Code: https://github.com/rwightman/pytorch-image-models/blob/9a25fdf3ad0414b4d66da443fe60ae0aa14edc84/timm/models/tresnet.py#L279"
 list([{'entity_group': 'ORG', 'score': 0.9341192, 'word': 'ImageNet', 'start': 9, 'end': 17}, {'entity_group': 'ORG', 'score': 0.94124925, 'word': 'TResNet', 'start': 127, 'end': 134}, {'entity_group': 'ORG', 'score': 0.82610816, 'word': 'ImageNet', 'start': 628, 'end': 636}, {'entity_group': 'MISC', 'score': 0.7619234, 'word': 'NVIDIA', 'start': 664, 'end': 670}])
 list([{'entity_group': 'ORG', 'score': 0.9341192, 'word': 'ImageNet', 'start': 9, 'end': 17}, {'entity_group': 'ORG', 'score': 0.94124925, 'word': 'TResNet', 'start': 127, 'end': 134}, {'entity_group': 'ORG', 'score': 0.82610816, 'word': 'ImageNet', 'start': 628, 'end': 636}])]
['642' '62.0' '11'
 "Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_m_448-bc359d10.pth\n  Results:\n  - Task: Image Classification\n    Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 81.72%\n      Top 5 Accuracy: 95.57%\n- Name: tresnet_xl\n  In Collection: TResNet\n  Metadata:\n    FLOPs: 15162534034\n    Parameters: 75646610\n    File Size: 314378965\n    Architecture:\n    - 1x1 Convolution\n    - Anti-Alias Downsampling\n    - Convolution\n    - Global Average Pooling\n    - InPlace-ABN\n    - Leaky ReLU\n    - ReLU\n    - Residual Connection\n    - Squeeze-and-Excitation Block\n    Tasks:\n    - Image Classification\n    Training Techniques:\n    - AutoAugment\n    - Cutout\n    - Label Smoothing\n    - SGD with Momentum\n    - Weight Decay\n    Training Data:\n    - ImageNet\n    Training Resources: 8x NVIDIA 100 GPUs\n    ID: tresnet_xl\n    LR: 0.01\n    Epochs: 300\n    Crop Pct: '0.875'\n    Momentum: 0.9\n    Image Size: '224'\n    Weight Decay: 0.0001"
 list([{'entity_group': 'ORG', 'score': 0.8908814, 'word': 'ImageNet', 'start': 172, 'end': 180}, {'entity_group': 'ORG', 'score': 0.70774245, 'word': 'TR', 'start': 288, 'end': 290}, {'entity_group': 'ORG', 'score': 0.51547384, 'word': '##Net', 'start': 292, 'end': 295}, {'entity_group': 'ORG', 'score': 0.74468756, 'word': 'ImageNet', 'start': 789, 'end': 797}, {'entity_group': 'MISC', 'score': 0.81522346, 'word': 'NVIDIA', 'start': 825, 'end': 831}])
 list([{'entity_group': 'ORG', 'score': 0.8908814, 'word': 'ImageNet', 'start': 172, 'end': 180}, {'entity_group': 'MISC', 'score': 0.81522346, 'word': 'NVIDIA', 'start': 825, 'end': 831}])]
['643' '62.0' '12'
 "Crop Pct: '0.875'\n    Momentum: 0.9\n    Image Size: '224'\n    Weight Decay: 0.0001\n    Interpolation: bilinear\n  Code: https://github.com/rwightman/pytorch-image-models/blob/9a25fdf3ad0414b4d66da443fe60ae0aa14edc84/timm/models/tresnet.py#L273\n  Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_xl_82_0-a2d51b00.pth\n  Results:\n  - Task: Image Classification\n    Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 82.05%\n      Top 5 Accuracy: 95.93%\n- Name: tresnet_xl_448\n  In Collection: TResNet\n  Metadata:\n    FLOPs: 60641712730\n    Parameters: 75646610\n    File Size: 224440219\n    Architecture:\n    - 1x1 Convolution\n    - Anti-Alias Downsampling\n    - Convolution\n    - Global Average Pooling\n    - InPlace-ABN\n    - Leaky ReLU\n    - ReLU\n    - Residual Connection\n    - Squeeze-and-Excitation Block\n    Tasks:\n    - Image Classification\n    Training Techniques:\n    - AutoAugment\n    - Cutout\n    - Label Smoothing\n    - SGD with Momentum"
 list([{'entity_group': 'ORG', 'score': 0.65456784, 'word': 'ImageNet', 'start': 419, 'end': 427}, {'entity_group': 'ORG', 'score': 0.87489533, 'word': 'TResNet', 'start': 539, 'end': 546}])
 list([{'entity_group': 'ORG', 'score': 0.87489533, 'word': 'TResNet', 'start': 539, 'end': 546}])]
['644' '62.0' '13'
 "- AutoAugment\n    - Cutout\n    - Label Smoothing\n    - SGD with Momentum\n    - Weight Decay\n    Training Data:\n    - ImageNet\n    Training Resources: 8x NVIDIA 100 GPUs\n    ID: tresnet_xl_448\n    LR: 0.01\n    Epochs: 300\n    Crop Pct: '0.875'\n    Momentum: 0.9\n    Image Size: '448'\n    Weight Decay: 0.0001\n    Interpolation: bilinear\n  Code: https://github.com/rwightman/pytorch-image-models/blob/9a25fdf3ad0414b4d66da443fe60ae0aa14edc84/timm/models/tresnet.py#L291\n  Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_l_448-940d0cd1.pth\n  Results:\n  - Task: Image Classification\n    Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 83.06%\n      Top 5 Accuracy: 96.19%\n-->"
 list([{'entity_group': 'ORG', 'score': 0.67768073, 'word': 'S', 'start': 55, 'end': 56}, {'entity_group': 'ORG', 'score': 0.93068385, 'word': 'ImageNet', 'start': 117, 'end': 125}, {'entity_group': 'MISC', 'score': 0.807641, 'word': 'NVIDIA', 'start': 153, 'end': 159}, {'entity_group': 'ORG', 'score': 0.83420634, 'word': 'ImageNet', 'start': 642, 'end': 650}])
 list([{'entity_group': 'ORG', 'score': 0.93068385, 'word': 'ImageNet', 'start': 117, 'end': 125}, {'entity_group': 'MISC', 'score': 0.807641, 'word': 'NVIDIA', 'start': 153, 'end': 159}, {'entity_group': 'ORG', 'score': 0.83420634, 'word': 'ImageNet', 'start': 642, 'end': 650}])]
['645' '63.0' '0'
 'Configure the Dataset Viewer\n\nThe Dataset Viewer supports many [data files formats](./datasets-adding#file-formats), from text to tabular and from image to audio formats.\nIt also separates the train/validation/test splits based on file and folder names.\n\nTo configure the Dataset Viewer for your dataset, first make sure your dataset is in a [supported data format](./datasets-adding#files-formats).\n\n## Configure dropdowns for splits or subsets\n\nIn the Dataset Viewer you can view the [train/validation/test](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets) splits of datasets, and sometimes additionally choose between multiple subsets (e.g. one per language).\n\nTo define those dropdowns, you can name the data files or their folder after their split names (train/validation/test).\nIt is also possible to customize your splits manually using YAML.'
 list([{'entity_group': 'ORG', 'score': 0.4361445, 'word': 'Data', 'start': 14, 'end': 18}, {'entity_group': 'ORG', 'score': 0.6635054, 'word': 'View', 'start': 22, 'end': 26}, {'entity_group': 'ORG', 'score': 0.7406507, 'word': 'Dataset Viewer', 'start': 34, 'end': 48}, {'entity_group': 'ORG', 'score': 0.79903674, 'word': 'Dataset Viewer', 'start': 272, 'end': 286}, {'entity_group': 'MISC', 'score': 0.5299405, 'word': 'Dataset', 'start': 454, 'end': 461}, {'entity_group': 'ORG', 'score': 0.5631775, 'word': 'Viewer', 'start': 462, 'end': 468}, {'entity_group': 'MISC', 'score': 0.346868, 'word': '##ia', 'start': 528, 'end': 530}])
 list([])]
['646' '63.0' '1'
 "For more information, feel free to check out the documentation on [Data files Configuration](./datasets-data-files-configuration).\n\n## Disable the viewer\n\nThe dataset viewer can be disabled. To do this, add a YAML section to the dataset's `README.md` file (create one if it does not already exist) and add a `viewer` property with the value `false`."
 list([]) list([])]
['647' '63.0' '2'
 '```\n---\nviewer: false\n---\n```\n\nNote that the viewer is always disabled on the private datasets.'
 list([]) list([])]
['648' '64.0' '0'
 'Author: [@vasudevgupta7](https://github.com/thevasudevgupta/)\n\n## Intro\n\nIn this project, we fine-tuned [**BigBird**](https://arxiv.org/abs/2007.14062) on [**natural-questions**](https://huggingface.co/datasets/natural_questions) dataset for **question-answering** task on long documents. **BigBird**, is a **sparse-attention based transformer** which extends Transformer based models, such as BERT to much **longer sequences**.\n\nRead more about BigBird at https://huggingface.co/blog/big-bird\n\n## Fine-tuning\n\n**Setup**\n\nYou need to install jax yourself by following the official docs ([refer this](https://github.com/google/jax#installation)). Other requirements for this project can be installed by running following command:\n\n```shell\npip3 install -qr requirements.txt'
 list([{'entity_group': 'PER', 'score': 0.5166916, 'word': '##gu', 'start': 17, 'end': 19}, {'entity_group': 'PER', 'score': 0.49556142, 'word': '##gu', 'start': 54, 'end': 56}, {'entity_group': 'ORG', 'score': 0.8779703, 'word': 'BigBird', 'start': 107, 'end': 114}, {'entity_group': 'ORG', 'score': 0.63276607, 'word': '##face', 'start': 194, 'end': 198}, {'entity_group': 'ORG', 'score': 0.49956754, 'word': 'co', 'start': 199, 'end': 201}, {'entity_group': 'ORG', 'score': 0.83122593, 'word': 'BigBird', 'start': 291, 'end': 298}, {'entity_group': 'MISC', 'score': 0.872148, 'word': 'Trans', 'start': 360, 'end': 365}, {'entity_group': 'ORG', 'score': 0.7327005, 'word': 'BERT', 'start': 394, 'end': 398}, {'entity_group': 'ORG', 'score': 0.8716096, 'word': 'BigBird', 'start': 446, 'end': 453}])
 list([{'entity_group': 'ORG', 'score': 0.8779703, 'word': 'BigBird', 'start': 107, 'end': 114}, {'entity_group': 'ORG', 'score': 0.83122593, 'word': 'BigBird', 'start': 291, 'end': 298}, {'entity_group': 'MISC', 'score': 0.872148, 'word': 'Trans', 'start': 360, 'end': 365}, {'entity_group': 'ORG', 'score': 0.8716096, 'word': 'BigBird', 'start': 446, 'end': 453}])]
['649' '64.0' '1'
 "```\n\n**Download & prepare dataset**\n\nThe Natural Questions corpus contains questions from real users, and it requires QA systems to read and comprehend an entire Wikipedia article that may or may not contain the answer to the question. This corpus takes ~100 GB on disk. We have used HuggingFace datasets to download & process the dataset.\n\n```shell\n# just run following CMD\npython3 prepare_natural_questions.py\n\n# this will download the whole dataset from HuggingFace Hub & will make it ready for training\n# this script takes ~3 hours to process the dataset\n```\n\n**Launch Training**\n\nWe have trained on Cloud's TPU v3-8. Each epoch took around 4.5 hours and the model got converged in just 2 epochs. You can see complete training args in [this script](bigbird_flax.py).\n\n```shell\n# just run following CMD\npython3 train.py\n\n# In case, you want to try hparams tuning, you can run wandb sweep\nwandb sweep --project=bigbird sweep_flax.yaml\nwandb agent <agent-id-obtained-by-above-CMD>"
 list([{'entity_group': 'MISC', 'score': 0.82986224, 'word': 'Natural Questions', 'start': 41, 'end': 58}, {'entity_group': 'MISC', 'score': 0.7993675, 'word': 'Wikipedia', 'start': 162, 'end': 171}, {'entity_group': 'ORG', 'score': 0.9303667, 'word': 'HuggingFace', 'start': 284, 'end': 295}, {'entity_group': 'ORG', 'score': 0.75813955, 'word': 'CMD', 'start': 371, 'end': 374}, {'entity_group': 'ORG', 'score': 0.89420265, 'word': 'HuggingFace Hub', 'start': 457, 'end': 472}, {'entity_group': 'ORG', 'score': 0.98186904, 'word': 'Cloud', 'start': 604, 'end': 609}, {'entity_group': 'ORG', 'score': 0.70898676, 'word': 'CMD', 'start': 802, 'end': 805}, {'entity_group': 'ORG', 'score': 0.7813391, 'word': 'C', 'start': 977, 'end': 978}])
 list([{'entity_group': 'MISC', 'score': 0.82986224, 'word': 'Natural Questions', 'start': 41, 'end': 58}, {'entity_group': 'ORG', 'score': 0.9303667, 'word': 'HuggingFace', 'start': 284, 'end': 295}, {'entity_group': 'ORG', 'score': 0.89420265, 'word': 'HuggingFace Hub', 'start': 457, 'end': 472}, {'entity_group': 'ORG', 'score': 0.98186904, 'word': 'Cloud', 'start': 604, 'end': 609}])]
['650' '64.0' '2'
 '```\n\n## Evaluation\n\nOur evaluation script is different from the original script and we are evaluating sequences with length up to 4096 for simplicity. We managed to get the **EM score of ~55.2** using our evaluation script.\n\n```shell\n# download validation-dataset first\nmkdir natural-questions-validation\nwget https://huggingface.co/datasets/vasudevgupta/natural-questions-validation/resolve/main/natural_questions-validation.arrow -P natural-questions-validation\nwget https://huggingface.co/datasets/vasudevgupta/natural-questions-validation/resolve/main/dataset_info.json -P natural-questions-validation\nwget https://huggingface.co/datasets/vasudevgupta/natural-questions-validation/resolve/main/state.json -P natural-questions-validation\n\n# simply run following command\npython3 evaluate.py'
 list([{'entity_group': 'MISC', 'score': 0.80243576, 'word': 'E', 'start': 175, 'end': 176}])
 list([{'entity_group': 'MISC', 'score': 0.80243576, 'word': 'E', 'start': 175, 'end': 176}])]
['651' '64.0' '3'
 '```\n\nYou can find our checkpoint on HuggingFace Hub ([see this](https://huggingface.co/vasudevgupta/flax-bigbird-natural-questions)). In case you are interested in PyTorch BigBird fine-tuning, you can refer to [this repositary](https://github.com/thevasudevgupta/bigbird).'
 list([{'entity_group': 'ORG', 'score': 0.8053556, 'word': 'HuggingFace Hub', 'start': 36, 'end': 51}, {'entity_group': 'ORG', 'score': 0.6250157, 'word': '##face', 'start': 79, 'end': 83}, {'entity_group': 'ORG', 'score': 0.6084655, 'word': 'co', 'start': 84, 'end': 86}, {'entity_group': 'ORG', 'score': 0.8314017, 'word': 'PyTorch', 'start': 164, 'end': 171}, {'entity_group': 'MISC', 'score': 0.37554535, 'word': '##Bird', 'start': 175, 'end': 179}])
 list([{'entity_group': 'ORG', 'score': 0.8053556, 'word': 'HuggingFace Hub', 'start': 36, 'end': 51}, {'entity_group': 'ORG', 'score': 0.8314017, 'word': 'PyTorch', 'start': 164, 'end': 171}])]
['652' '65.0' '0'
 '--\ntitle: Fine tuning CLIP with Remote Sensing (Satellite) images and captions\nthumbnail: /blog/assets/30_clip_rsicd/clip_schematic.png\nauthors:\n- user: arampacha\n  guest: true\n- user: devv\n  guest: true\n- user: goutham794\n  guest: true\n- user: cataluna84\n  guest: true\n- user: ghosh-r\n  guest: true\n- user: sujitpal\n  guest: true\n---\n\n# Fine tuning CLIP with Remote Sensing (Satellite) images and captions\n\n\n\n## Fine tuning CLIP with Remote Sensing (Satellite) images and captions\n\n<img src="/blog/assets/30_clip_rsicd/clip-rsicd-header-image.png"/>\n\nIn July this year, [Hugging Face](https://huggingface.co/) organized a [Flax/JAX Community Week](https://github.com/huggingface/transformers/blob/master/examples/research_projects/jax-projects/README.md), and invited the community to submit projects to train Hugging Face [transformers](https://github.com/huggingface/transformers) models in the areas of Natural Language Processing (NLP) and Computer Vision (CV).'
 list([{'entity_group': 'MISC', 'score': 0.85994035, 'word': 'Re', 'start': 32, 'end': 34}, {'entity_group': 'MISC', 'score': 0.8372885, 'word': 'Sensing', 'start': 39, 'end': 46}, {'entity_group': 'MISC', 'score': 0.49165985, 'word': 'Satellite', 'start': 48, 'end': 57}, {'entity_group': 'ORG', 'score': 0.687989, 'word': '##rampa', 'start': 154, 'end': 159}, {'entity_group': 'MISC', 'score': 0.8640392, 'word': 'Re', 'start': 360, 'end': 362}, {'entity_group': 'MISC', 'score': 0.81803024, 'word': 'Sensing', 'start': 367, 'end': 374}, {'entity_group': 'MISC', 'score': 0.6347522, 'word': 'Satellite', 'start': 376, 'end': 385}, {'entity_group': 'MISC', 'score': 0.8810949, 'word': 'Re', 'start': 435, 'end': 437}, {'entity_group': 'MISC', 'score': 0.8231667, 'word': 'Sensing', 'start': 442, 'end': 449}, {'entity_group': 'MISC', 'score': 0.6754181, 'word': 'Satellite', 'start': 451, 'end': 460}, {'entity_group': 'ORG', 'score': 0.95634174, 'word': 'Hugging Face', 'start': 572, 'end': 584}, {'entity_group': 'ORG', 'score': 0.95882046, 'word': '##face', 'start': 601, 'end': 605}, {'entity_group': 'ORG', 'score': 0.67607987, 'word': 'co', 'start': 606, 'end': 608}, {'entity_group': 'MISC', 'score': 0.707394, 'word': 'F', 'start': 624, 'end': 625}, {'entity_group': 'ORG', 'score': 0.349994, 'word': 'J', 'start': 629, 'end': 630}, {'entity_group': 'MISC', 'score': 0.72130114, 'word': 'Week', 'start': 643, 'end': 647}, {'entity_group': 'ORG', 'score': 0.84819585, 'word': 'Face', 'start': 819, 'end': 823}, {'entity_group': 'MISC', 'score': 0.9442886, 'word': 'Natural Language Processing', 'start': 907, 'end': 934}, {'entity_group': 'MISC', 'score': 0.55321336, 'word': 'NLP', 'start': 936, 'end': 939}, {'entity_group': 'MISC', 'score': 0.888459, 'word': 'Computer Vision', 'start': 945, 'end': 960}])
 list([{'entity_group': 'MISC', 'score': 0.85994035, 'word': 'Re', 'start': 32, 'end': 34}, {'entity_group': 'MISC', 'score': 0.8372885, 'word': 'Sensing', 'start': 39, 'end': 46}, {'entity_group': 'MISC', 'score': 0.8640392, 'word': 'Re', 'start': 360, 'end': 362}, {'entity_group': 'MISC', 'score': 0.81803024, 'word': 'Sensing', 'start': 367, 'end': 374}, {'entity_group': 'MISC', 'score': 0.8810949, 'word': 'Re', 'start': 435, 'end': 437}, {'entity_group': 'MISC', 'score': 0.8231667, 'word': 'Sensing', 'start': 442, 'end': 449}, {'entity_group': 'ORG', 'score': 0.95634174, 'word': 'Hugging Face', 'start': 572, 'end': 584}, {'entity_group': 'ORG', 'score': 0.95882046, 'word': '##face', 'start': 601, 'end': 605}, {'entity_group': 'ORG', 'score': 0.84819585, 'word': 'Face', 'start': 819, 'end': 823}, {'entity_group': 'MISC', 'score': 0.9442886, 'word': 'Natural Language Processing', 'start': 907, 'end': 934}, {'entity_group': 'MISC', 'score': 0.888459, 'word': 'Computer Vision', 'start': 945, 'end': 960}])]
['653' '65.0' '1'
 'Participants used Tensor Processing Units (TPUs) with [Flax](https://github.com/google/flax) and [JAX](https://github.com/google/jax). JAX is a linear algebra library (like `numpy`) that can do automatic differentiation ([Autograd](https://github.com/hips/autograd)) and compile down to [XLA](https://www.tensorflow.org/xla), and Flax is a neural network library and ecosystem for JAX. TPU compute time was provided free by [Google Cloud](https://cloud.google.com/), who co-sponsored the event.\n\nOver the next two weeks, teams participated in lectures from Hugging Face and Google, trained one or more models using JAX/Flax, shared them with the community, and provided a  [Hugging Face Spaces](https://huggingface.co/spaces) demo showcasing the capabilities of their model. Approximately 100 teams participated in the event, and it resulted in 170 models and 36 demos.'
 list([{'entity_group': 'MISC', 'score': 0.39486927, 'word': 'Ten', 'start': 18, 'end': 21}, {'entity_group': 'ORG', 'score': 0.56791234, 'word': 'Process', 'start': 25, 'end': 32}, {'entity_group': 'MISC', 'score': 0.6787681, 'word': 'Units', 'start': 36, 'end': 41}, {'entity_group': 'ORG', 'score': 0.6677669, 'word': 'Flax', 'start': 55, 'end': 59}, {'entity_group': 'ORG', 'score': 0.7092092, 'word': 'J', 'start': 98, 'end': 99}, {'entity_group': 'ORG', 'score': 0.5338786, 'word': '##X', 'start': 100, 'end': 101}, {'entity_group': 'ORG', 'score': 0.8957761, 'word': 'JAX', 'start': 135, 'end': 138}, {'entity_group': 'ORG', 'score': 0.49151248, 'word': 'X', 'start': 288, 'end': 289}, {'entity_group': 'ORG', 'score': 0.9707502, 'word': 'Flax', 'start': 330, 'end': 334}, {'entity_group': 'ORG', 'score': 0.8700256, 'word': 'JAX', 'start': 381, 'end': 384}, {'entity_group': 'ORG', 'score': 0.9976225, 'word': 'Google Cloud', 'start': 425, 'end': 437}, {'entity_group': 'ORG', 'score': 0.9394806, 'word': 'Hugging Face', 'start': 557, 'end': 569}, {'entity_group': 'ORG', 'score': 0.99766904, 'word': 'Google', 'start': 574, 'end': 580}, {'entity_group': 'ORG', 'score': 0.496076, 'word': 'F', 'start': 619, 'end': 620}, {'entity_group': 'ORG', 'score': 0.57777727, 'word': 'Hugging Face Spaces', 'start': 674, 'end': 693}, {'entity_group': 'ORG', 'score': 0.86273015, 'word': '##face', 'start': 710, 'end': 714}])
 list([{'entity_group': 'ORG', 'score': 0.8957761, 'word': 'JAX', 'start': 135, 'end': 138}, {'entity_group': 'ORG', 'score': 0.9707502, 'word': 'Flax', 'start': 330, 'end': 334}, {'entity_group': 'ORG', 'score': 0.8700256, 'word': 'JAX', 'start': 381, 'end': 384}, {'entity_group': 'ORG', 'score': 0.9976225, 'word': 'Google Cloud', 'start': 425, 'end': 437}, {'entity_group': 'ORG', 'score': 0.9394806, 'word': 'Hugging Face', 'start': 557, 'end': 569}, {'entity_group': 'ORG', 'score': 0.99766904, 'word': 'Google', 'start': 574, 'end': 580}, {'entity_group': 'ORG', 'score': 0.86273015, 'word': '##face', 'start': 710, 'end': 714}])]
['654' '65.0' '2'
 'Our team, like probably many others, is a distributed one, spanning 12 time zones. Our common thread is that we all belong to the [TWIML Slack Channel](https://twimlai.slack.com/), where we came together based on a shared interest in Artificial Intelligence (AI) and Machine Learning (ML) topics.'
 list([{'entity_group': 'ORG', 'score': 0.9293952, 'word': 'TWIML Slack Channel', 'start': 131, 'end': 150}, {'entity_group': 'ORG', 'score': 0.7136613, 'word': '##mlai', 'start': 163, 'end': 167}, {'entity_group': 'MISC', 'score': 0.86234266, 'word': 'Artificial Intelligence', 'start': 234, 'end': 257}, {'entity_group': 'MISC', 'score': 0.9775493, 'word': 'AI', 'start': 259, 'end': 261}, {'entity_group': 'MISC', 'score': 0.95652294, 'word': 'Machine Learning', 'start': 267, 'end': 283}, {'entity_group': 'MISC', 'score': 0.6586469, 'word': 'ML', 'start': 285, 'end': 287}])
 list([{'entity_group': 'ORG', 'score': 0.9293952, 'word': 'TWIML Slack Channel', 'start': 131, 'end': 150}, {'entity_group': 'MISC', 'score': 0.86234266, 'word': 'Artificial Intelligence', 'start': 234, 'end': 257}, {'entity_group': 'MISC', 'score': 0.9775493, 'word': 'AI', 'start': 259, 'end': 261}, {'entity_group': 'MISC', 'score': 0.95652294, 'word': 'Machine Learning', 'start': 267, 'end': 283}])]
['655' '65.0' '3'
 'We fine-tuned the [CLIP Network from OpenAI](https://openai.comclip/) with satellite images and captions from the [RSICD dataset](https://github.com/201528014227051/RSICD_optimal). The CLIP network learns visual concepts by being trained with image and caption pairs in a self-supervised manner, by using text paired with images found across the Internet. During inference, the model can predict the most relevant image given a text description or the most relevant text description given an image. CLIP is powerful enough to be used in zero-shot manner on everyday images. However, we felt that satellite images were sufficiently different from everyday images that it would be useful to fine-tune CLIP with them. Our intuition turned out to be correct, as the evaluation results (described below) shows. In this post, we describe details of our training and evaluation process, and our plans for future work on this project.'
 list([{'entity_group': 'ORG', 'score': 0.99548745, 'word': 'CLIP Network', 'start': 19, 'end': 31}, {'entity_group': 'ORG', 'score': 0.9642132, 'word': 'OpenAI', 'start': 37, 'end': 43}, {'entity_group': 'ORG', 'score': 0.63603866, 'word': '##ai', 'start': 57, 'end': 59}, {'entity_group': 'ORG', 'score': 0.76001555, 'word': 'RSICD', 'start': 115, 'end': 120}, {'entity_group': 'ORG', 'score': 0.94116133, 'word': 'CLIP', 'start': 185, 'end': 189}, {'entity_group': 'MISC', 'score': 0.78245103, 'word': 'Internet', 'start': 346, 'end': 354}, {'entity_group': 'MISC', 'score': 0.6844182, 'word': 'CL', 'start': 499, 'end': 501}])
 list([{'entity_group': 'ORG', 'score': 0.99548745, 'word': 'CLIP Network', 'start': 19, 'end': 31}, {'entity_group': 'ORG', 'score': 0.9642132, 'word': 'OpenAI', 'start': 37, 'end': 43}, {'entity_group': 'ORG', 'score': 0.94116133, 'word': 'CLIP', 'start': 185, 'end': 189}])]
['656' '65.0' '4'
 'The goal of our project was to provide a useful service and demonstrate how to use CLIP for practical use cases. Our model can be used by applications to search through large collections of satellite images using textual queries. Such queries could describe the image in totality (for example, beach, mountain, airport, baseball field, etc) or search or mention specific geographic or man-made features within these images. CLIP can similarly be fine-tuned for other domains as well, as shown by the [medclip-demo team](https://huggingface.co/spaces/flax-community/medclip-demo) for medical images.'
 list([{'entity_group': 'MISC', 'score': 0.712986, 'word': 'CL', 'start': 83, 'end': 85}, {'entity_group': 'MISC', 'score': 0.5836454, 'word': 'C', 'start': 424, 'end': 425}])
 list([])]
['657' '65.0' '5'
 'The ability to search through large collections of images using text queries is an immensely powerful feature, and can be used as much for social good as for malign purposes. Possible applications include national defense and anti-terrorism activities, the ability to spot and address effects of climate change before they become unmanageable, etc. Unfortunately, this power can also be misused, such as for military and police surveillance by authoritarian nation-states, so it does raise some ethical questions as well.\n\nYou can read about the project on our [project page](https://github.com/arampacha/CLIP-rsicd), download our [trained model](https://huggingface.co/flax-community/clip-rsicd-v2) to use for inference on your own data, or see it in action on our [demo](https://huggingface.co/spaces/sujitpal/clip-rsicd-demo).\n\n\n### Training\n\n#### Dataset'
 list([{'entity_group': 'ORG', 'score': 0.59230256, 'word': '##ram', 'start': 596, 'end': 599}])
 list([])]
['658' '65.0' '6'
 '### Training\n\n#### Dataset\n\nWe fine-tuned the CLIP model primarily with the [RSICD dataset](https://github.com/201528014227051/RSICD_optimal). This dataset consists of about 10,000 images collected from Google Earth, Baidu Map, MapABC, and Tianditu. It is provided freely to the research community to advance remote sensing captioning via [Exploring Models and Data for Remote Sensing Image Caption Generation](https://arxiv.org/abs/1712.0783) (Lu et al, 2017). The images are (224, 224) RGB images at various resolutions, and each image has up to 5 captions associated with it.\n\n<img src="/blog/assets/30_clip_rsicd/rsicd-images-sampling.png"/>\n<center><i>Some examples of images from the RSICD dataset</i></center>'
 list([{'entity_group': 'MISC', 'score': 0.52208287, 'word': 'CL', 'start': 46, 'end': 48}, {'entity_group': 'ORG', 'score': 0.5230503, 'word': '##IP', 'start': 48, 'end': 50}, {'entity_group': 'ORG', 'score': 0.6905256, 'word': 'RSICD', 'start': 77, 'end': 82}, {'entity_group': 'ORG', 'score': 0.47564498, 'word': 'RS', 'start': 127, 'end': 129}, {'entity_group': 'MISC', 'score': 0.67621243, 'word': 'Google Earth', 'start': 203, 'end': 215}, {'entity_group': 'MISC', 'score': 0.5738395, 'word': 'Bai', 'start': 217, 'end': 220}, {'entity_group': 'ORG', 'score': 0.81042254, 'word': '##du Map', 'start': 220, 'end': 226}, {'entity_group': 'ORG', 'score': 0.92382556, 'word': 'MapABC', 'start': 228, 'end': 234}, {'entity_group': 'ORG', 'score': 0.9336358, 'word': 'T', 'start': 240, 'end': 241}, {'entity_group': 'MISC', 'score': 0.51368105, 'word': '##iandit', 'start': 241, 'end': 247}, {'entity_group': 'ORG', 'score': 0.85405964, 'word': '##u', 'start': 247, 'end': 248}, {'entity_group': 'PER', 'score': 0.9891423, 'word': 'Lu', 'start': 445, 'end': 447}, {'entity_group': 'ORG', 'score': 0.76703525, 'word': 'RSICD', 'start': 690, 'end': 695}])
 list([{'entity_group': 'ORG', 'score': 0.81042254, 'word': '##du Map', 'start': 220, 'end': 226}, {'entity_group': 'ORG', 'score': 0.92382556, 'word': 'MapABC', 'start': 228, 'end': 234}, {'entity_group': 'ORG', 'score': 0.9336358, 'word': 'T', 'start': 240, 'end': 241}, {'entity_group': 'ORG', 'score': 0.85405964, 'word': '##u', 'start': 247, 'end': 248}, {'entity_group': 'PER', 'score': 0.9891423, 'word': 'Lu', 'start': 445, 'end': 447}])]
['659' '65.0' '7'
 'In addition, we used the [UCM Dataset](https://mega.nz/folder/wCpSzSoS#RXzIlrv--TDt3ENZdKN8JA) and the [Sydney dataset](https://mega.nz/folder/pG4yTYYA#4c4buNFLibryZnlujsrwEQ) for training, The UCM dataset is based on the UC Merced Land Use dataset. It consists of 2100 images belonging to 21 classes (100 images per class), and each image has 5 captions. The Sydney dataset contains images of Sydney, Australia from Google Earth. It contains 613 images belonging to 7 classes. Images are (500, 500) RGB and provides 5 captions for each image. We used these additional datasets because we were not sure if the RSICD dataset would be large enough to fine-tune CLIP.\n\n\n#### Model'
 list([{'entity_group': 'ORG', 'score': 0.96043813, 'word': 'UCM', 'start': 26, 'end': 29}, {'entity_group': 'MISC', 'score': 0.6566328, 'word': 'Dataset', 'start': 30, 'end': 37}, {'entity_group': 'LOC', 'score': 0.9814387, 'word': 'Sydney', 'start': 104, 'end': 110}, {'entity_group': 'ORG', 'score': 0.98537827, 'word': 'UCM', 'start': 194, 'end': 197}, {'entity_group': 'ORG', 'score': 0.7192782, 'word': 'UC Merced', 'start': 222, 'end': 231}, {'entity_group': 'MISC', 'score': 0.41427916, 'word': 'Use', 'start': 237, 'end': 240}, {'entity_group': 'LOC', 'score': 0.9978811, 'word': 'Sydney', 'start': 360, 'end': 366}, {'entity_group': 'LOC', 'score': 0.9995931, 'word': 'Sydney', 'start': 394, 'end': 400}, {'entity_group': 'LOC', 'score': 0.9996517, 'word': 'Australia', 'start': 402, 'end': 411}, {'entity_group': 'MISC', 'score': 0.9003153, 'word': 'Google Earth', 'start': 417, 'end': 429}, {'entity_group': 'ORG', 'score': 0.8239996, 'word': 'RSICD', 'start': 610, 'end': 615}])
 list([{'entity_group': 'ORG', 'score': 0.96043813, 'word': 'UCM', 'start': 26, 'end': 29}, {'entity_group': 'LOC', 'score': 0.9814387, 'word': 'Sydney', 'start': 104, 'end': 110}, {'entity_group': 'ORG', 'score': 0.98537827, 'word': 'UCM', 'start': 194, 'end': 197}, {'entity_group': 'LOC', 'score': 0.9978811, 'word': 'Sydney', 'start': 360, 'end': 366}, {'entity_group': 'LOC', 'score': 0.9995931, 'word': 'Sydney', 'start': 394, 'end': 400}, {'entity_group': 'LOC', 'score': 0.9996517, 'word': 'Australia', 'start': 402, 'end': 411}, {'entity_group': 'MISC', 'score': 0.9003153, 'word': 'Google Earth', 'start': 417, 'end': 429}, {'entity_group': 'ORG', 'score': 0.8239996, 'word': 'RSICD', 'start': 610, 'end': 615}])]
['660' '65.0' '8'
 '#### Model\n\nOur model is just the fine-tuned version of the original CLIP model shown below. Inputs to the model are a batch of captions and a batch of images passed through the CLIP text encoder and image encoder respectively. The training process uses [contrastive learning](https://towardsdatascience.com/understanding-contrastive-learning-d5b19fd96607) to learn a joint embedding representation of image and captions. In this embedding space, images and their respective captions are pushed close together, as are similar images and similar captions. Conversely, images and captions for different images, or dissimilar images and captions, are likely to be pushed further apart.\n\n<img src="/blog/assets/30_clip_rsicd/clip_schematic.png"/>\n<center><i>CLIP Training and Inference (Image Credit: CLIP: Connecting Text and Images (https://openai.comclip/))</i></center>\n\n\n#### Data Augmentation'
 list([{'entity_group': 'MISC', 'score': 0.76789296, 'word': 'CL', 'start': 69, 'end': 71}, {'entity_group': 'MISC', 'score': 0.5816643, 'word': 'C', 'start': 178, 'end': 179}, {'entity_group': 'ORG', 'score': 0.46065605, 'word': '##LIP', 'start': 179, 'end': 182}, {'entity_group': 'MISC', 'score': 0.5590049, 'word': 'CL', 'start': 754, 'end': 756}])
 list([])]
['661' '65.0' '9'
 "#### Data Augmentation\n\nIn order to regularize our dataset and prevent overfitting due to the size of the dataset, we used both image and text augmentation.\n\nImage augmentation was done inline using built-in transforms from Pytorch's [Torchvision](https://pytorch.org/vision/stable/index.html) package. The transformations used were Random Cropping, Random Resizing and Cropping, Color Jitter, and Random Horizontal and Vertical flipping.\n\nWe augmented the text with backtranslation to generate captions for images with less than 5 unique captions per image. The [Marian MT]((https://huggingface.co/transformers/model_doc/marian.html)) family of models from Hugging Face was used to translate the existing captions into French, Spanish, Italian, and Portuguese and back to English to fill out the captions for these images.\n\nAs shown in these loss plots below, image augmentation reduced overfitting significantly, and text and image augmentation reduced overfitting even further."
 list([{'entity_group': 'ORG', 'score': 0.9923141, 'word': 'Pytorch', 'start': 224, 'end': 231}, {'entity_group': 'ORG', 'score': 0.9891394, 'word': 'Torchvision', 'start': 235, 'end': 246}, {'entity_group': 'ORG', 'score': 0.9802287, 'word': 'pytorch', 'start': 256, 'end': 263}, {'entity_group': 'ORG', 'score': 0.6542516, 'word': 'org', 'start': 264, 'end': 267}, {'entity_group': 'ORG', 'score': 0.83666325, 'word': 'Marian M', 'start': 564, 'end': 572}, {'entity_group': 'ORG', 'score': 0.6993495, 'word': '##face', 'start': 591, 'end': 595}, {'entity_group': 'ORG', 'score': 0.923316, 'word': 'Hugging Face', 'start': 658, 'end': 670}, {'entity_group': 'MISC', 'score': 0.9973133, 'word': 'French', 'start': 720, 'end': 726}, {'entity_group': 'MISC', 'score': 0.9801459, 'word': 'Spanish', 'start': 728, 'end': 735}, {'entity_group': 'MISC', 'score': 0.9934896, 'word': 'Italian', 'start': 737, 'end': 744}, {'entity_group': 'MISC', 'score': 0.9849449, 'word': 'Portuguese', 'start': 750, 'end': 760}, {'entity_group': 'MISC', 'score': 0.9961093, 'word': 'English', 'start': 773, 'end': 780}])
 list([{'entity_group': 'ORG', 'score': 0.9923141, 'word': 'Pytorch', 'start': 224, 'end': 231}, {'entity_group': 'ORG', 'score': 0.9891394, 'word': 'Torchvision', 'start': 235, 'end': 246}, {'entity_group': 'ORG', 'score': 0.9802287, 'word': 'pytorch', 'start': 256, 'end': 263}, {'entity_group': 'ORG', 'score': 0.83666325, 'word': 'Marian M', 'start': 564, 'end': 572}, {'entity_group': 'ORG', 'score': 0.923316, 'word': 'Hugging Face', 'start': 658, 'end': 670}, {'entity_group': 'MISC', 'score': 0.9973133, 'word': 'French', 'start': 720, 'end': 726}, {'entity_group': 'MISC', 'score': 0.9801459, 'word': 'Spanish', 'start': 728, 'end': 735}, {'entity_group': 'MISC', 'score': 0.9934896, 'word': 'Italian', 'start': 737, 'end': 744}, {'entity_group': 'MISC', 'score': 0.9849449, 'word': 'Portuguese', 'start': 750, 'end': 760}, {'entity_group': 'MISC', 'score': 0.9961093, 'word': 'English', 'start': 773, 'end': 780}])]
['662' '65.0' '10'
 '<img src="/blog/assets/30_clip_rsicd/image-augment-loss.png"/>\n<img src="/blog/assets/30_clip_rsicd/image-text-aug-loss.png"/>\n<center><i>Evaluation and Training loss plots comparing (top) no augmentation vs image augmentation, and (bottom) image augmentation vs text+image augmentation</i></center>\n\n\n### Evaluation\n\n#### Metrics\n\nA subset of the RSICD test set was used for evaluation. We found 30 categories of images in this subset. The evaluation was done by comparing each image with a set of 30 caption sentences of the form `"An aerial photograph of {category}"`. The model produced a ranked list of the 30 captions, from most relevant to least relevant. Categories corresponding to captions with the top k scores (for k=1, 3, 5, and 10) were compared with the category provided via the image file name. The scores are averaged over the entire set of images used for evaluation and reported for various values of k, as shown below.'
 list([{'entity_group': 'ORG', 'score': 0.8825014, 'word': 'RSICD', 'start': 348, 'end': 353}])
 list([{'entity_group': 'ORG', 'score': 0.8825014, 'word': 'RSICD', 'start': 348, 'end': 353}])]
['663' '65.0' '11'
 'The `baseline` model represents the pre-trained `openai/clip-vit-base-path32` CLIP model. This model was fine-tuned with captions and images from the RSICD dataset, which resulted in a significant performance boost, as shown below.\n\nOur best model was trained with image and text augmentation, with batch size 1024 (128 on each of the 8 TPU cores), and the Adam optimizer with learning rate 5e-6. We trained our second base model with the same hyperparameters, except that we used the Adafactor optimizer with learning rate 1e-4. You can download either model from their model repos linked to in the table below.'
 list([{'entity_group': 'ORG', 'score': 0.7825939, 'word': 'RSICD', 'start': 150, 'end': 155}, {'entity_group': 'ORG', 'score': 0.39346775, 'word': 'Adam', 'start': 357, 'end': 361}, {'entity_group': 'ORG', 'score': 0.74182326, 'word': 'Adafactor', 'start': 485, 'end': 494}])
 list([])]
['664' '65.0' '12'
 '| Model-name                               | k=1   | k=3   | k=5   | k=10  |\n| ---------------------------------------- | ----- | ----- | ----- | ----- |\n| baseline                                 | 0.572 | 0.745 | 0.837 | 0.939 |\n| bs128x8-lr1e-4-augs/ckpt-2               | 0.819 | 0.950 | 0.974 | 0.994 |\n| bs128x8-lr1e-4-imgaugs/ckpt-2            | 0.812 | 0.942 | 0.970 | 0.991 |\n| [bs128x8-lr1e-4-imgaugs-textaugs/ckpt-4](https://huggingface.co/flax-community/clip-rsicd)<sup>2</sup>   | 0.843 | 0.958 | 0.977 | 0.993 |\n| bs128x8-lr5e-5-imgaugs-textaugs/ckpt-8   | 0.831 | 0.959 | 0.977 | 0.994 |\n| bs128x8-lr5e-5-imgaugs/ckpt-4            | 0.746 | 0.906 | 0.956 | 0.989 |\n| bs128x8-lr5e-5-imgaugs-textaugs-2/ckpt-4 | 0.811 | 0.945 | 0.972 | 0.993 |\n| bs128x8-lr5e-5-imgaugs-textaugs-3/ckpt-5 | 0.823 | 0.946 | 0.971 | 0.992 |\n| bs128x8-lr5e-5-wd02/ckpt-4               | 0.820 | 0.946 | 0.965 | 0.990 |'
 list([]) list([])]
['665' '65.0' '13'
 '| bs128x8-lr5e-5-wd02/ckpt-4               | 0.820 | 0.946 | 0.965 | 0.990 |\n| [bs128x8-lr5e-6-adam/ckpt-1](https://huggingface.co/flax-community/clip-rsicd-v2)<sup>1</sup> | **0.883** | **0.968** | **0.982** | **0.998** |'
 list([]) list([])]
['666' '65.0' '14'
 '_1 - our best model, 2 - our second best model_\n\n\n#### Demo\n\nYou can access the [CLIP-RSICD Demo](https://huggingface.co/spaces/sujitpal/clip-rsicd-demo) here. It uses our fine-tuned CLIP model to provide the following functionality:\n\n* Text to Image search\n* Image to Image search\n* Find text feature in image\n\nThe first two functionalities use the RSICD test set as its image corpus. They are encoded using our best fine-tuned CLIP model and stored in a [NMSLib](https://github.com/nmslib/nmslib) index which allows Approximate Nearest Neighbor based retrieval. For text-to-image and image-to-image search respectively, the query text or image are encoded with our model and matched against the image vectors in the corpus. For the third functionality, we divide the incoming image into patches and encode them, encode the queried text feature, match the text vector with each image patch vector, and return the probability of finding the feature in each patch.\n\n### Future Work'
 list([{'entity_group': 'MISC', 'score': 0.8606578, 'word': 'C', 'start': 81, 'end': 82}, {'entity_group': 'MISC', 'score': 0.5464232, 'word': 'RSIC', 'start': 86, 'end': 90}, {'entity_group': 'MISC', 'score': 0.5802425, 'word': 'CL', 'start': 183, 'end': 185}, {'entity_group': 'ORG', 'score': 0.6361465, 'word': 'RSICD', 'start': 350, 'end': 355}, {'entity_group': 'MISC', 'score': 0.48776847, 'word': 'CL', 'start': 429, 'end': 431}])
 list([{'entity_group': 'MISC', 'score': 0.8606578, 'word': 'C', 'start': 81, 'end': 82}])]
['667' '65.0' '15'
 '### Future Work\n\nWe are grateful that we have been given an opportunity to further refine our model. Some ideas we have for future work are as follows:\n\n1. Construct a sequence to sequence model using a CLIP encoder and a GPT-3 decoder and train it for image captioning.\n2. Fine-tune the model on more image caption pairs from other datasets and investigate if we can improve its performance.\n3. Investigate how fine-tuning affects the performance of model on non-RSICD image caption pairs.\n4. Investigate the capability of the fine-tuned model to classify outside the categories it has been fine-tuned on.\n5. Evaluate the model using other criteria such as image classification.'
 list([{'entity_group': 'MISC', 'score': 0.7999687, 'word': 'CL', 'start': 203, 'end': 205}, {'entity_group': 'MISC', 'score': 0.51904684, 'word': 'RS', 'start': 464, 'end': 466}])
 list([])]
['668' '66.0' '0'
 '!---\nCopyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the "License");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an "AS IS" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n# 🤗 Transformers Notebooks\n\nYou can find here a list of the official notebooks provided by Hugging Face.\n\nAlso, we would like to list here interesting content created by the community.\nIf you wrote some notebook(s) leveraging 🤗 Transformers and would like to be listed here, please open a\nPull Request so it can be included under the Community notebooks.\n\n\n## Hugging Face\'s notebooks 🤗'
 list([{'entity_group': 'ORG', 'score': 0.99446714, 'word': 'HuggingFace Team', 'start': 24, 'end': 40}, {'entity_group': 'MISC', 'score': 0.9970442, 'word': 'Apache License', 'start': 83, 'end': 97}, {'entity_group': 'MISC', 'score': 0.50934136, 'word': '2', 'start': 107, 'end': 108}, {'entity_group': 'MISC', 'score': 0.99378586, 'word': 'License', 'start': 117, 'end': 124}, {'entity_group': 'MISC', 'score': 0.992211, 'word': 'License', 'start': 184, 'end': 191}, {'entity_group': 'MISC', 'score': 0.99036825, 'word': 'License', 'start': 222, 'end': 229}, {'entity_group': 'ORG', 'score': 0.7821653, 'word': '##pache', 'start': 250, 'end': 255}, {'entity_group': 'MISC', 'score': 0.56575626, 'word': '##IC', 'start': 270, 'end': 272}, {'entity_group': 'MISC', 'score': 0.986476, 'word': 'License', 'start': 372, 'end': 379}, {'entity_group': 'MISC', 'score': 0.9920853, 'word': 'License', 'start': 497, 'end': 504}, {'entity_group': 'MISC', 'score': 0.9927598, 'word': 'License', 'start': 579, 'end': 586}, {'entity_group': 'MISC', 'score': 0.5735179, 'word': 'Transformers Note', 'start': 597, 'end': 614}, {'entity_group': 'ORG', 'score': 0.9586411, 'word': 'Hugging Face', 'start': 684, 'end': 696}, {'entity_group': 'ORG', 'score': 0.86658823, 'word': 'Transformers', 'start': 821, 'end': 833}, {'entity_group': 'ORG', 'score': 0.91387194, 'word': 'Hugging Face', 'start': 953, 'end': 965}])
 list([{'entity_group': 'ORG', 'score': 0.99446714, 'word': 'HuggingFace Team', 'start': 24, 'end': 40}, {'entity_group': 'MISC', 'score': 0.9970442, 'word': 'Apache License', 'start': 83, 'end': 97}, {'entity_group': 'MISC', 'score': 0.99378586, 'word': 'License', 'start': 117, 'end': 124}, {'entity_group': 'MISC', 'score': 0.992211, 'word': 'License', 'start': 184, 'end': 191}, {'entity_group': 'MISC', 'score': 0.99036825, 'word': 'License', 'start': 222, 'end': 229}, {'entity_group': 'MISC', 'score': 0.986476, 'word': 'License', 'start': 372, 'end': 379}, {'entity_group': 'MISC', 'score': 0.9920853, 'word': 'License', 'start': 497, 'end': 504}, {'entity_group': 'MISC', 'score': 0.9927598, 'word': 'License', 'start': 579, 'end': 586}, {'entity_group': 'ORG', 'score': 0.9586411, 'word': 'Hugging Face', 'start': 684, 'end': 696}, {'entity_group': 'ORG', 'score': 0.86658823, 'word': 'Transformers', 'start': 821, 'end': 833}, {'entity_group': 'ORG', 'score': 0.91387194, 'word': 'Hugging Face', 'start': 953, 'end': 965}])]
['669' '66.0' '1'
 "## Hugging Face's notebooks 🤗\n\n### Documentation notebooks\n\nYou can open any page of the documentation as a notebook in Colab (there is a button directly on said pages) but they are also listed here if you need them:"
 list([{'entity_group': 'PER', 'score': 0.79119575, 'word': 'Face', 'start': 11, 'end': 15}, {'entity_group': 'ORG', 'score': 0.8585509, 'word': 'Colab', 'start': 120, 'end': 125}])
 list([{'entity_group': 'ORG', 'score': 0.8585509, 'word': 'Colab', 'start': 120, 'end': 125}])]
['670' '66.0' '2'
 '| Notebook     |      Description      |   |   |\n|:----------|:-------------|:-------------|------:|\n| [Quicktour of the library](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)  | A presentation of the various APIs in Transformers |[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/en/transformers_doc/quicktour.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.48366687, 'word': 'Transformers', 'start': 259, 'end': 271}, {'entity_group': 'ORG', 'score': 0.88392, 'word': 'AWS Studio', 'start': 472, 'end': 482}])
 list([{'entity_group': 'ORG', 'score': 0.88392, 'word': 'AWS Studio', 'start': 472, 'end': 482}])]
['671' '66.0' '3'
 '| [Summary of the tasks](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)  | How to run the models of the Transformers library task by task |[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.8553111, 'word': 'Transformers', 'start': 148, 'end': 160}, {'entity_group': 'ORG', 'score': 0.9389539, 'word': 'AWS Studio', 'start': 385, 'end': 395}])
 list([{'entity_group': 'ORG', 'score': 0.8553111, 'word': 'Transformers', 'start': 148, 'end': 160}, {'entity_group': 'ORG', 'score': 0.9389539, 'word': 'AWS Studio', 'start': 385, 'end': 395}])]
['672' '66.0' '4'
 '| [Preprocessing data](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)  | How to use a tokenizer to preprocess your data |[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.43655348, 'word': 'Cola', 'start': 177, 'end': 181}, {'entity_group': 'ORG', 'score': 0.88931257, 'word': 'AWS Studio', 'start': 369, 'end': 379}])
 list([{'entity_group': 'ORG', 'score': 0.88931257, 'word': 'AWS Studio', 'start': 369, 'end': 379}])]
['673' '66.0' '5'
 '| [Fine-tuning a pretrained model](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)  | How to use the Trainer to fine-tune a pretrained model |[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.6274847, 'word': 'Train', 'start': 140, 'end': 145}, {'entity_group': 'ORG', 'score': 0.8914167, 'word': 'AWS Studio', 'start': 379, 'end': 389}])
 list([{'entity_group': 'ORG', 'score': 0.8914167, 'word': 'AWS Studio', 'start': 379, 'end': 389}])]
['674' '66.0' '6'
 '| [Summary of the tokenizers](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)  | The differences between the tokenizers algorithm |[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tokenizer_summary.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.44601166, 'word': 'Cola', 'start': 190, 'end': 194}, {'entity_group': 'ORG', 'score': 0.92298746, 'word': 'AWS Studio', 'start': 386, 'end': 396}])
 list([{'entity_group': 'ORG', 'score': 0.92298746, 'word': 'AWS Studio', 'start': 386, 'end': 396}])]
['675' '66.0' '7'
 '| [Multilingual models](https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)  | How to use the multilingual models of the library |[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/multilingual.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.885812, 'word': 'AWS Studio', 'start': 371, 'end': 381}])
 list([{'entity_group': 'ORG', 'score': 0.885812, 'word': 'AWS Studio', 'start': 371, 'end': 381}])]
['676' '66.0' '8'
 '### PyTorch Examples\n\n#### Natural Language Processing[[pytorch-nlp]]'
 list([{'entity_group': 'ORG', 'score': 0.5081449, 'word': 'PyT', 'start': 4, 'end': 7}, {'entity_group': 'MISC', 'score': 0.60686433, 'word': 'Natural Language', 'start': 27, 'end': 43}, {'entity_group': 'ORG', 'score': 0.73845875, 'word': 'Processing', 'start': 44, 'end': 54}])
 list([])]
['677' '66.0' '9'
 '| Notebook     |      Description      |   |   |\n|:----------|:-------------|:-------------|------:|\n| [Train your tokenizer](https://github.com/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)  | How to train and use your very own tokenizer  |[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.78479606, 'word': 'AWS Studio', 'start': 459, 'end': 469}])
 list([])]
['678' '66.0' '10'
 '| [Train your language model](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)   | How to easily start using transformers  |[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.9299555, 'word': 'AWS Studio', 'start': 382, 'end': 392}])
 list([{'entity_group': 'ORG', 'score': 0.9299555, 'word': 'AWS Studio', 'start': 382, 'end': 392}])]
['679' '66.0' '11'
 '| [How to fine-tune a model on text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on any GLUE task. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.46275643, 'word': 'Cola', 'start': 236, 'end': 240}, {'entity_group': 'ORG', 'score': 0.9331217, 'word': 'AWS Studio', 'start': 423, 'end': 433}])
 list([{'entity_group': 'ORG', 'score': 0.9331217, 'word': 'AWS Studio', 'start': 423, 'end': 433}])]
['680' '66.0' '12'
 '| [How to fine-tune a model on language modeling](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on a causal or masked LM task. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)|'
 list([{'entity_group': 'MISC', 'score': 0.56504667, 'word': 'L', 'start': 223, 'end': 224}, {'entity_group': 'ORG', 'score': 0.4949861, 'word': 'Colab', 'start': 245, 'end': 250}, {'entity_group': 'ORG', 'score': 0.92997885, 'word': 'AWS Studio', 'start': 430, 'end': 440}])
 list([{'entity_group': 'ORG', 'score': 0.92997885, 'word': 'AWS Studio', 'start': 430, 'end': 440}])]
['681' '66.0' '13'
 '| [How to fine-tune a model on token classification](https://github.com/huggingface/notebooks/blob/main/examples/token_classification.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on a token classification task (NER, PoS). | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.5058051, 'word': 'Colab', 'start': 263, 'end': 268}, {'entity_group': 'ORG', 'score': 0.89810467, 'word': 'AWS Studio', 'start': 451, 'end': 461}])
 list([{'entity_group': 'ORG', 'score': 0.89810467, 'word': 'AWS Studio', 'start': 451, 'end': 461}])]
['682' '66.0' '14'
 '| [How to fine-tune a model on question answering](https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on SQUAD. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.8997875, 'word': 'AWS Studio', 'start': 412, 'end': 422}])
 list([{'entity_group': 'ORG', 'score': 0.8997875, 'word': 'AWS Studio', 'start': 412, 'end': 422}])]
['683' '66.0' '15'
 '| [How to fine-tune a model on multiple choice](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on SWAG. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.40245023, 'word': 'S', 'start': 200, 'end': 201}, {'entity_group': 'ORG', 'score': 0.88785654, 'word': 'AWS Studio', 'start': 402, 'end': 412}])
 list([{'entity_group': 'ORG', 'score': 0.88785654, 'word': 'AWS Studio', 'start': 402, 'end': 412}])]
['684' '66.0' '16'
 '| [How to fine-tune a model on translation](https://github.com/huggingface/notebooks/blob/main/examples/translation.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on WMT. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/translation.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.8838947, 'word': 'AWS Studio', 'start': 389, 'end': 399}])
 list([{'entity_group': 'ORG', 'score': 0.8838947, 'word': 'AWS Studio', 'start': 389, 'end': 399}])]
['685' '66.0' '17'
 '| [How to fine-tune a model on summarization](https://github.com/huggingface/notebooks/blob/main/examples/summarization.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on XSUM. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.76446486, 'word': 'XSUM', 'start': 196, 'end': 200}, {'entity_group': 'ORG', 'score': 0.899898, 'word': 'AWS Studio', 'start': 396, 'end': 406}])
 list([{'entity_group': 'ORG', 'score': 0.899898, 'word': 'AWS Studio', 'start': 396, 'end': 406}])]
['686' '66.0' '18'
 '| [How to train a language model from scratch](https://github.com/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)| Highlight all the steps to effectively train Transformer model on custom data | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb)|'
 list([{'entity_group': 'MISC', 'score': 0.44710043, 'word': 'Transformer', 'start': 172, 'end': 183}, {'entity_group': 'ORG', 'score': 0.8884452, 'word': 'AWS Studio', 'start': 397, 'end': 407}])
 list([{'entity_group': 'ORG', 'score': 0.8884452, 'word': 'AWS Studio', 'start': 397, 'end': 407}])]
['687' '66.0' '19'
 '| [How to generate text](https://github.com/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)| How to use different decoding methods for language generation with transformers | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.79563695, 'word': 'AWS Studio', 'start': 383, 'end': 393}])
 list([])]
['688' '66.0' '20'
 '| [How to generate text (with constraints)](https://github.com/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)| How to guide language generation with user-provided constraints | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/blog/blob/main/notebooks/53_constrained_beam_search.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.85365033, 'word': 'AWS Studio', 'start': 402, 'end': 412}])
 list([{'entity_group': 'ORG', 'score': 0.85365033, 'word': 'AWS Studio', 'start': 402, 'end': 412}])]
['689' '66.0' '21'
 '| [Reformer](https://github.com/huggingface/blog/blob/main/notebooks/03_reformer.ipynb)| How Reformer pushes the limits of language modeling | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/patrickvonplaten/blog/blob/main/notebooks/03_reformer.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/patrickvonplaten/blog/blob/main/notebooks/03_reformer.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.700331, 'word': 'Reformer', 'start': 93, 'end': 101}, {'entity_group': 'ORG', 'score': 0.8910586, 'word': 'AWS Studio', 'start': 334, 'end': 344}])
 list([{'entity_group': 'ORG', 'score': 0.8910586, 'word': 'AWS Studio', 'start': 334, 'end': 344}])]
['690' '66.0' '22' '#### Computer Vision[[pytorch-cv]]'
 list([{'entity_group': 'ORG', 'score': 0.9465182, 'word': 'Computer Vision', 'start': 5, 'end': 20}])
 list([{'entity_group': 'ORG', 'score': 0.9465182, 'word': 'Computer Vision', 'start': 5, 'end': 20}])]
['691' '66.0' '23'
 '| Notebook                                                                                                                                                                   | Description                                                                                                            |                                                                                                                                                                                                            |   |'
 list([]) list([])]
['692' '66.0' '24'
 '|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------:|'
 list([]) list([])]
['693' '66.0' '25'
 '| [How to fine-tune a model on image classification (Torchvision)](https://github.com/huggingface/notebooks/blob/main/examples/image_classification.ipynb)                   | Show how to preprocess the data using Torchvision and fine-tune any pretrained Vision model on Image Classification    | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)                 | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.9179616, 'word': 'Torchvision', 'start': 53, 'end': 64}, {'entity_group': 'ORG', 'score': 0.7422991, 'word': 'Torchvision', 'start': 213, 'end': 224}, {'entity_group': 'ORG', 'score': 0.74092346, 'word': 'Vision', 'start': 254, 'end': 260}, {'entity_group': 'MISC', 'score': 0.84266776, 'word': 'Image Classification', 'start': 270, 'end': 290}, {'entity_group': 'ORG', 'score': 0.4716395, 'word': 'Cola', 'start': 307, 'end': 311}, {'entity_group': 'ORG', 'score': 0.88663054, 'word': 'AWS Studio', 'start': 512, 'end': 522}])
 list([{'entity_group': 'ORG', 'score': 0.9179616, 'word': 'Torchvision', 'start': 53, 'end': 64}, {'entity_group': 'MISC', 'score': 0.84266776, 'word': 'Image Classification', 'start': 270, 'end': 290}, {'entity_group': 'ORG', 'score': 0.88663054, 'word': 'AWS Studio', 'start': 512, 'end': 522}])]
['694' '66.0' '26'
 '| [How to fine-tune a model on image classification (Albumentations)](https://github.com/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb) | Show how to preprocess the data using Albumentations and fine-tune any pretrained Vision model on Image Classification | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)  | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.47457138, 'word': 'Vision', 'start': 257, 'end': 263}, {'entity_group': 'MISC', 'score': 0.8735299, 'word': 'Image Classification', 'start': 273, 'end': 293}, {'entity_group': 'ORG', 'score': 0.8860581, 'word': 'AWS Studio', 'start': 512, 'end': 522}])
 list([{'entity_group': 'MISC', 'score': 0.8735299, 'word': 'Image Classification', 'start': 273, 'end': 293}, {'entity_group': 'ORG', 'score': 0.8860581, 'word': 'AWS Studio', 'start': 512, 'end': 522}])]
['695' '66.0' '27'
 '| [How to fine-tune a model on image classification (Kornia)](https://github.com/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)                 | Show how to preprocess the data using Kornia and fine-tune any pretrained Vision model on Image Classification         | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)          | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb)|'
 list([{'entity_group': 'MISC', 'score': 0.9169386, 'word': 'Ko', 'start': 53, 'end': 55}, {'entity_group': 'ORG', 'score': 0.37995008, 'word': '##rn', 'start': 55, 'end': 57}, {'entity_group': 'MISC', 'score': 0.80021125, 'word': '##ia', 'start': 57, 'end': 59}, {'entity_group': 'MISC', 'score': 0.9349374, 'word': 'Ko', 'start': 213, 'end': 215}, {'entity_group': 'ORG', 'score': 0.5480176, 'word': '##rn', 'start': 215, 'end': 217}, {'entity_group': 'MISC', 'score': 0.6440651, 'word': '##ia', 'start': 217, 'end': 219}, {'entity_group': 'ORG', 'score': 0.5729322, 'word': 'Vision', 'start': 249, 'end': 255}, {'entity_group': 'MISC', 'score': 0.73581505, 'word': 'Image Classification', 'start': 265, 'end': 285}, {'entity_group': 'ORG', 'score': 0.9055229, 'word': 'AWS Studio', 'start': 512, 'end': 522}])
 list([{'entity_group': 'MISC', 'score': 0.9169386, 'word': 'Ko', 'start': 53, 'end': 55}, {'entity_group': 'MISC', 'score': 0.80021125, 'word': '##ia', 'start': 57, 'end': 59}, {'entity_group': 'MISC', 'score': 0.9349374, 'word': 'Ko', 'start': 213, 'end': 215}, {'entity_group': 'ORG', 'score': 0.9055229, 'word': 'AWS Studio', 'start': 512, 'end': 522}])]
['696' '66.0' '28'
 '| [How to perform zero-shot object detection with OWL-ViT](https://github.com/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)          | Show how to perform zero-shot object detection on images with text queries                                             | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/zeroshot_object_detection_with_owlvit.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.70171237, 'word': 'O', 'start': 50, 'end': 51}, {'entity_group': 'ORG', 'score': 0.5494543, 'word': 'V', 'start': 54, 'end': 55}, {'entity_group': 'ORG', 'score': 0.49990034, 'word': 'Colab', 'start': 307, 'end': 312}, {'entity_group': 'ORG', 'score': 0.90208894, 'word': 'AWS Studio', 'start': 512, 'end': 522}])
 list([{'entity_group': 'ORG', 'score': 0.90208894, 'word': 'AWS Studio', 'start': 512, 'end': 522}])]
['697' '66.0' '29'
 '| [How to fine-tune an image captioning model](https://github.com/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)                                      | Show how to fine-tune BLIP for image captioning on a custom dataset                                                    | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)                | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_captioning_blip.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.79064775, 'word': 'BLIP', 'start': 197, 'end': 201}, {'entity_group': 'ORG', 'score': 0.54003733, 'word': 'Colab', 'start': 307, 'end': 312}, {'entity_group': 'ORG', 'score': 0.9362095, 'word': 'AWS Studio', 'start': 512, 'end': 522}])
 list([{'entity_group': 'ORG', 'score': 0.9362095, 'word': 'AWS Studio', 'start': 512, 'end': 522}])]
['698' '66.0' '30'
 '| [How to build an image similarity system with Transformers](https://github.com/huggingface/notebooks/blob/main/examples/image_similarity.ipynb)                            | Show how to build an image similarity system                                                                           | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_similarity.ipynb)                     | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_similarity.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.9957373, 'word': 'Transformers', 'start': 48, 'end': 60}, {'entity_group': 'ORG', 'score': 0.9094127, 'word': 'AWS Studio', 'start': 512, 'end': 522}])
 list([{'entity_group': 'ORG', 'score': 0.9957373, 'word': 'Transformers', 'start': 48, 'end': 60}, {'entity_group': 'ORG', 'score': 0.9094127, 'word': 'AWS Studio', 'start': 512, 'end': 522}])]
['699' '66.0' '31'
 '| [How to fine-tune a SegFormer model on semantic segmentation](https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb)                     | Show how to preprocess the data and fine-tune a pretrained SegFormer model on Semantic Segmentation                    | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb)                | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb)|'
 list([{'entity_group': 'MISC', 'score': 0.72617114, 'word': 'Seg', 'start': 22, 'end': 25}, {'entity_group': 'ORG', 'score': 0.6126835, 'word': '##Former', 'start': 25, 'end': 31}, {'entity_group': 'MISC', 'score': 0.7382361, 'word': 'Seg', 'start': 234, 'end': 237}, {'entity_group': 'ORG', 'score': 0.78233945, 'word': '##Form', 'start': 237, 'end': 241}, {'entity_group': 'ORG', 'score': 0.8944626, 'word': 'AWS Studio', 'start': 512, 'end': 522}])
 list([{'entity_group': 'ORG', 'score': 0.8944626, 'word': 'AWS Studio', 'start': 512, 'end': 522}])]
['700' '66.0' '32'
 '| [How to fine-tune a VideoMAE model on video classification](https://github.com/huggingface/notebooks/blob/main/examples/video_classification.ipynb)          | Show how to preprocess the data and fine-tune a pretrained VideoMAE model on Video Classification                      | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/video_classification.ipynb)                | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/video_classification.ipynb)|'
 list([{'entity_group': 'MISC', 'score': 0.7163842, 'word': 'VideoMAE', 'start': 22, 'end': 30}, {'entity_group': 'MISC', 'score': 0.8109338, 'word': 'VideoMA', 'start': 220, 'end': 227}, {'entity_group': 'MISC', 'score': 0.61940056, 'word': 'Classification', 'start': 244, 'end': 258}, {'entity_group': 'ORG', 'score': 0.8988647, 'word': 'AWS Studio', 'start': 497, 'end': 507}])
 list([{'entity_group': 'MISC', 'score': 0.8109338, 'word': 'VideoMA', 'start': 220, 'end': 227}, {'entity_group': 'ORG', 'score': 0.8988647, 'word': 'AWS Studio', 'start': 497, 'end': 507}])]
['701' '66.0' '33' '#### Audio[[pytorch-audio]]' list([]) list([])]
['702' '66.0' '34'
 '| Notebook     |      Description      |   |   |\n|:----------|:-------------|:-------------|------:|\n| [How to fine-tune a speech recognition model in English](https://github.com/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb)| Show how to preprocess the data and fine-tune a pretrained Speech model on TIMIT | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb)|'
 list([{'entity_group': 'MISC', 'score': 0.9973254, 'word': 'English', 'start': 151, 'end': 158}, {'entity_group': 'ORG', 'score': 0.7411842, 'word': 'TIMIT', 'start': 322, 'end': 327}, {'entity_group': 'ORG', 'score': 0.38342622, 'word': 'Cola', 'start': 341, 'end': 345}, {'entity_group': 'ORG', 'score': 0.86743027, 'word': 'AWS Studio', 'start': 527, 'end': 537}])
 list([{'entity_group': 'MISC', 'score': 0.9973254, 'word': 'English', 'start': 151, 'end': 158}, {'entity_group': 'ORG', 'score': 0.86743027, 'word': 'AWS Studio', 'start': 527, 'end': 537}])]
['703' '66.0' '35'
 '| [How to fine-tune a speech recognition model in any language](https://github.com/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb)| Show how to preprocess the data and fine-tune a multi-lingually pretrained speech model on Common Voice | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.85712814, 'word': 'Common Voice', 'start': 256, 'end': 268}, {'entity_group': 'ORG', 'score': 0.9188411, 'word': 'AWS Studio', 'start': 482, 'end': 492}])
 list([{'entity_group': 'ORG', 'score': 0.85712814, 'word': 'Common Voice', 'start': 256, 'end': 268}, {'entity_group': 'ORG', 'score': 0.9188411, 'word': 'AWS Studio', 'start': 482, 'end': 492}])]
['704' '66.0' '36'
 '| [How to fine-tune a model on audio classification](https://github.com/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)| Show how to preprocess the data and fine-tune a pretrained Speech model on Keyword Spotting | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb)|'
 list([{'entity_group': 'MISC', 'score': 0.59689534, 'word': 'Speech', 'start': 201, 'end': 207}, {'entity_group': 'ORG', 'score': 0.91103953, 'word': 'AWS Studio', 'start': 435, 'end': 445}])
 list([{'entity_group': 'ORG', 'score': 0.91103953, 'word': 'AWS Studio', 'start': 435, 'end': 445}])]
['705' '66.0' '37' '#### Biological Sequences[[pytorch-bio]]' list([])
 list([])]
['706' '66.0' '38'
 '| Notebook     | Description                                                                             |   |   |\n|:----------|:----------------------------------------------------------------------------------------|:-------------|------:|\n| [How to fine-tune a pre-trained protein model](https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb) | See how to tokenize proteins and fine-tune a large pre-trained protein "language" model | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb) | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb) |'
 list([{'entity_group': 'ORG', 'score': 0.42997882, 'word': 'Cola', 'start': 487, 'end': 491}, {'entity_group': 'ORG', 'score': 0.7559414, 'word': 'AWS Studio', 'start': 681, 'end': 691}])
 list([])]
['707' '66.0' '39'
 '| [How to generate protein folds](https://github.com/huggingface/notebooks/blob/main/examples/protein_folding.ipynb) | See how to go from protein sequence to a full protein model and PDB file                | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_folding.ipynb) | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_folding.ipynb) |'
 list([{'entity_group': 'ORG', 'score': 0.90172154, 'word': 'AWS Studio', 'start': 404, 'end': 414}])
 list([{'entity_group': 'ORG', 'score': 0.90172154, 'word': 'AWS Studio', 'start': 404, 'end': 414}])]
['708' '66.0' '40'
 '| [How to fine-tune a Nucleotide Transformer model](https://github.com/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling.ipynb) | See how to tokenize DNA and fine-tune a large pre-trained DNA "language" model | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling.ipynb) | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling.ipynb) |'
 list([{'entity_group': 'MISC', 'score': 0.8196486, 'word': 'N', 'start': 22, 'end': 23}, {'entity_group': 'MISC', 'score': 0.6005184, 'word': '##former', 'start': 38, 'end': 44}, {'entity_group': 'MISC', 'score': 0.53652585, 'word': 'DNA', 'start': 187, 'end': 190}, {'entity_group': 'MISC', 'score': 0.889741, 'word': 'DNA', 'start': 225, 'end': 228}, {'entity_group': 'ORG', 'score': 0.48206264, 'word': 'Colab', 'start': 259, 'end': 264}, {'entity_group': 'ORG', 'score': 0.8955614, 'word': 'AWS Studio', 'start': 473, 'end': 483}])
 list([{'entity_group': 'MISC', 'score': 0.8196486, 'word': 'N', 'start': 22, 'end': 23}, {'entity_group': 'MISC', 'score': 0.889741, 'word': 'DNA', 'start': 225, 'end': 228}, {'entity_group': 'ORG', 'score': 0.8955614, 'word': 'AWS Studio', 'start': 473, 'end': 483}])]
['709' '66.0' '41'
 '| [Fine-tune a Nucleotide Transformer model with LoRA](https://github.com/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling_with_peft.ipynb) | Train even larger DNA models in a memory-efficient way | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling_with_peft.ipynb) | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/nucleotide_transformer_dna_sequence_modelling_with_peft.ipynb) |'
 list([{'entity_group': 'MISC', 'score': 0.7275653, 'word': 'N', 'start': 15, 'end': 16}, {'entity_group': 'MISC', 'score': 0.5538274, 'word': '##former', 'start': 31, 'end': 37}, {'entity_group': 'ORG', 'score': 0.93800133, 'word': 'LoRA', 'start': 49, 'end': 53}, {'entity_group': 'ORG', 'score': 0.65313494, 'word': 'Colab', 'start': 248, 'end': 253}, {'entity_group': 'ORG', 'score': 0.9020653, 'word': 'AWS Studio', 'start': 472, 'end': 482}])
 list([{'entity_group': 'ORG', 'score': 0.93800133, 'word': 'LoRA', 'start': 49, 'end': 53}, {'entity_group': 'ORG', 'score': 0.9020653, 'word': 'AWS Studio', 'start': 472, 'end': 482}])]
['710' '66.0' '42'
 '#### Other modalities[[pytorch-other]]\n\n| Notebook     | Description                                                                             |   |   |\n|:----------|:----------------------------------------------------------------------------------------|:-------------|------:|\n| [Probabilistic Time Series Forecasting](https://github.com/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb) | See how to train Time Series Transformer on a custom dataset                            | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb) | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/time-series-transformers.ipynb) |\n\n#### Utility notebooks[[pytorch-utility]]'
 list([{'entity_group': 'MISC', 'score': 0.7773757, 'word': 'Series', 'start': 440, 'end': 446}, {'entity_group': 'ORG', 'score': 0.50932163, 'word': '##former', 'start': 452, 'end': 458}, {'entity_group': 'ORG', 'score': 0.8959629, 'word': 'AWS Studio', 'start': 712, 'end': 722}])
 list([{'entity_group': 'ORG', 'score': 0.8959629, 'word': 'AWS Studio', 'start': 712, 'end': 722}])]
['711' '66.0' '43'
 '#### Utility notebooks[[pytorch-utility]]\n\n| Notebook     |      Description      |   |   |\n|:----------|:-------------|:-------------|------:|\n| [How to export model to ONNX](https://github.com/huggingface/notebooks/blob/main/examples/onnx-export.ipynb)| Highlight how to export and run inference workloads through ONNX |\n| [How to use Benchmarks](https://github.com/huggingface/notebooks/blob/main/examples/benchmark.ipynb)| How to benchmark models with transformers | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/benchmark.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/benchmark.ipynb)|\n\n### TensorFlow Examples\n\n#### Natural Language Processing[[tensorflow-nlp]]'
 list([{'entity_group': 'ORG', 'score': 0.91828203, 'word': 'ONNX', 'start': 170, 'end': 174}, {'entity_group': 'ORG', 'score': 0.88436025, 'word': 'ONNX', 'start': 316, 'end': 320}, {'entity_group': 'ORG', 'score': 0.9016421, 'word': 'AWS Studio', 'start': 659, 'end': 669}, {'entity_group': 'MISC', 'score': 0.65748405, 'word': 'Natural Language', 'start': 855, 'end': 871}])
 list([{'entity_group': 'ORG', 'score': 0.91828203, 'word': 'ONNX', 'start': 170, 'end': 174}, {'entity_group': 'ORG', 'score': 0.88436025, 'word': 'ONNX', 'start': 316, 'end': 320}, {'entity_group': 'ORG', 'score': 0.9016421, 'word': 'AWS Studio', 'start': 659, 'end': 669}])]
['712' '66.0' '44'
 '| Notebook     |      Description      |   |   |\n|:----------|:-------------|:-------------|------:|\n| [Train your tokenizer](https://github.com/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)  | How to train and use your very own tokenizer  |[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tokenizer_training.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.78479606, 'word': 'AWS Studio', 'start': 459, 'end': 469}])
 list([])]
['713' '66.0' '45'
 '| [Train your language model](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch-tf.ipynb)   | How to easily start using transformers  |[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch-tf.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling_from_scratch-tf.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.8555569, 'word': 'AWS Studio', 'start': 388, 'end': 398}])
 list([{'entity_group': 'ORG', 'score': 0.8555569, 'word': 'AWS Studio', 'start': 388, 'end': 398}])]
['714' '66.0' '46'
 '| [How to fine-tune a model on text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on any GLUE task. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.49635926, 'word': 'Colab', 'start': 239, 'end': 244}, {'entity_group': 'ORG', 'score': 0.919955, 'word': 'AWS Studio', 'start': 429, 'end': 439}])
 list([{'entity_group': 'ORG', 'score': 0.919955, 'word': 'AWS Studio', 'start': 429, 'end': 439}])]
['715' '66.0' '47'
 '| [How to fine-tune a model on language modeling](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on a causal or masked LM task. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)|'
 list([{'entity_group': 'MISC', 'score': 0.6508798, 'word': 'L', 'start': 226, 'end': 227}, {'entity_group': 'ORG', 'score': 0.6003265, 'word': 'Colab', 'start': 248, 'end': 253}, {'entity_group': 'ORG', 'score': 0.8996549, 'word': 'AWS Studio', 'start': 436, 'end': 446}])
 list([{'entity_group': 'ORG', 'score': 0.8996549, 'word': 'AWS Studio', 'start': 436, 'end': 446}])]
['716' '66.0' '48'
 '| [How to fine-tune a model on token classification](https://github.com/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on a token classification task (NER, PoS). | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.51584697, 'word': 'Cola', 'start': 266, 'end': 270}, {'entity_group': 'ORG', 'score': 0.9135186, 'word': 'AWS Studio', 'start': 457, 'end': 467}])
 list([{'entity_group': 'ORG', 'score': 0.9135186, 'word': 'AWS Studio', 'start': 457, 'end': 467}])]
['717' '66.0' '49'
 '| [How to fine-tune a model on question answering](https://github.com/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on SQUAD. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.45125708, 'word': 'Colab', 'start': 229, 'end': 234}, {'entity_group': 'ORG', 'score': 0.8956136, 'word': 'AWS Studio', 'start': 418, 'end': 428}])
 list([{'entity_group': 'ORG', 'score': 0.8956136, 'word': 'AWS Studio', 'start': 418, 'end': 428}])]
['718' '66.0' '50'
 '| [How to fine-tune a model on multiple choice](https://github.com/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on SWAG. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.47589684, 'word': 'S', 'start': 203, 'end': 204}, {'entity_group': 'ORG', 'score': 0.44173753, 'word': 'Cola', 'start': 222, 'end': 226}, {'entity_group': 'ORG', 'score': 0.86549157, 'word': 'AWS Studio', 'start': 408, 'end': 418}])
 list([{'entity_group': 'ORG', 'score': 0.86549157, 'word': 'AWS Studio', 'start': 408, 'end': 418}])]
['719' '66.0' '51'
 '| [How to fine-tune a model on translation](https://github.com/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on WMT. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/translation-tf.ipynb)|'
 list([{'entity_group': 'MISC', 'score': 0.41219166, 'word': 'W', 'start': 195, 'end': 196}, {'entity_group': 'ORG', 'score': 0.9110059, 'word': 'AWS Studio', 'start': 395, 'end': 405}])
 list([{'entity_group': 'ORG', 'score': 0.9110059, 'word': 'AWS Studio', 'start': 395, 'end': 405}])]
['720' '66.0' '52'
 '| [How to fine-tune a model on summarization](https://github.com/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)| Show how to preprocess the data and fine-tune a pretrained model on XSUM. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization-tf.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.7762051, 'word': 'XSUM', 'start': 199, 'end': 203}, {'entity_group': 'ORG', 'score': 0.44882128, 'word': 'Colab', 'start': 218, 'end': 223}, {'entity_group': 'ORG', 'score': 0.8971916, 'word': 'AWS Studio', 'start': 402, 'end': 412}])
 list([{'entity_group': 'ORG', 'score': 0.8971916, 'word': 'AWS Studio', 'start': 402, 'end': 412}])]
['721' '66.0' '53' '#### Computer Vision[[tensorflow-cv]]'
 list([{'entity_group': 'ORG', 'score': 0.8336967, 'word': 'Computer Vision', 'start': 5, 'end': 20}])
 list([{'entity_group': 'ORG', 'score': 0.8336967, 'word': 'Computer Vision', 'start': 5, 'end': 20}])]
['722' '66.0' '54'
 '| Notebook                                                                                                                                                 | Description                                                                                         |   |   |\n|:---------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------|:-------------|------:|'
 list([]) list([])]
['723' '66.0' '55'
 '| [How to fine-tune a model on image classification](https://github.com/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)            | Show how to preprocess the data and fine-tune any pretrained Vision model on Image Classification   | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/image_classification-tf.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.53944963, 'word': 'Vision', 'start': 218, 'end': 224}, {'entity_group': 'MISC', 'score': 0.82238716, 'word': 'Image Classification', 'start': 234, 'end': 254}, {'entity_group': 'ORG', 'score': 0.5234797, 'word': 'Cola', 'start': 270, 'end': 274}, {'entity_group': 'ORG', 'score': 0.90104085, 'word': 'AWS Studio', 'start': 461, 'end': 471}])
 list([{'entity_group': 'MISC', 'score': 0.82238716, 'word': 'Image Classification', 'start': 234, 'end': 254}, {'entity_group': 'ORG', 'score': 0.90104085, 'word': 'AWS Studio', 'start': 461, 'end': 471}])]
['724' '66.0' '56'
 '| [How to fine-tune a SegFormer model on semantic segmentation](https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb) | Show how to preprocess the data and fine-tune a pretrained SegFormer model on Semantic Segmentation | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)|'
 list([{'entity_group': 'MISC', 'score': 0.6337799, 'word': 'Seg', 'start': 22, 'end': 25}, {'entity_group': 'ORG', 'score': 0.7537067, 'word': '##Former', 'start': 25, 'end': 31}, {'entity_group': 'MISC', 'score': 0.6589864, 'word': 'Seg', 'start': 217, 'end': 220}, {'entity_group': 'ORG', 'score': 0.8311336, 'word': '##Form', 'start': 220, 'end': 224}, {'entity_group': 'ORG', 'score': 0.4467917, 'word': 'Cola', 'start': 271, 'end': 275}, {'entity_group': 'ORG', 'score': 0.9168406, 'word': 'AWS Studio', 'start': 463, 'end': 473}])
 list([{'entity_group': 'ORG', 'score': 0.8311336, 'word': '##Form', 'start': 220, 'end': 224}, {'entity_group': 'ORG', 'score': 0.9168406, 'word': 'AWS Studio', 'start': 463, 'end': 473}])]
['725' '66.0' '57'
 '#### Biological Sequences[[tensorflow-bio]]\n\n| Notebook     |      Description      |   |   |\n|:----------|:-------------|:-------------|------:|\n| [How to fine-tune a pre-trained protein model](https://github.com/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb) | See how to tokenize proteins and fine-tune a large pre-trained protein "language" model | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb) | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/protein_language_modeling-tf.ipynb) |\n\n#### Utility notebooks[[tensorflow-utility]]'
 list([{'entity_group': 'ORG', 'score': 0.6448813, 'word': 'Colab', 'start': 394, 'end': 399}, {'entity_group': 'ORG', 'score': 0.9142909, 'word': 'AWS Studio', 'start': 591, 'end': 601}])
 list([{'entity_group': 'ORG', 'score': 0.9142909, 'word': 'AWS Studio', 'start': 591, 'end': 601}])]
['726' '66.0' '58'
 "#### Utility notebooks[[tensorflow-utility]]\n\n| Notebook     |      Description      |   |                                                                                                                                                                                      |\n|:----------|:-------------|:-------------|------:|\n| [How to train TF/Keras models on TPU](https://github.com/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb) | See how to train at high speed on Google's TPU hardware | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb) | [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/tpu_training-tf.ipynb) |\n\n### Optimum notebooks"
 list([{'entity_group': 'ORG', 'score': 0.6477932, 'word': '##F / Keras', 'start': 343, 'end': 350}, {'entity_group': 'ORG', 'score': 0.9964114, 'word': 'Google', 'start': 485, 'end': 491}, {'entity_group': 'ORG', 'score': 0.38329178, 'word': 'Cola', 'start': 520, 'end': 524}, {'entity_group': 'ORG', 'score': 0.9018483, 'word': 'AWS Studio', 'start': 704, 'end': 714}])
 list([{'entity_group': 'ORG', 'score': 0.9964114, 'word': 'Google', 'start': 485, 'end': 491}, {'entity_group': 'ORG', 'score': 0.9018483, 'word': 'AWS Studio', 'start': 704, 'end': 714}])]
['727' '66.0' '59'
 '### Optimum notebooks\n\n🤗  [Optimum](https://github.com/huggingface/optimum) is an extension of 🤗 Transformers, providing a set of performance optimization tools enabling maximum efficiency to train and run models on targeted hardwares.'
 list([{'entity_group': 'ORG', 'score': 0.81885976, 'word': '🤗 Transformers', 'start': 95, 'end': 109}])
 list([{'entity_group': 'ORG', 'score': 0.81885976, 'word': '🤗 Transformers', 'start': 95, 'end': 109}])]
['728' '66.0' '60'
 '| Notebook     |      Description      |   |   |\n|:----------|:-------------|:-------------|------:|\n| [How to quantize a model with ONNX Runtime for text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb)| Show how to apply static and dynamic quantization on a model using [ONNX Runtime](https://github.com/microsoft/onnxruntime) for any GLUE task. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.49199453, 'word': 'Cola', 'start': 432, 'end': 436}, {'entity_group': 'ORG', 'score': 0.9265413, 'word': 'AWS Studio', 'start': 636, 'end': 646}])
 list([{'entity_group': 'ORG', 'score': 0.9265413, 'word': 'AWS Studio', 'start': 636, 'end': 646}])]
['729' '66.0' '61'
 '| [How to quantize a model with Intel Neural Compressor for text classification](https://github.com/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb)| Show how to apply static, dynamic and aware training quantization on a model using [Intel Neural Compressor (INC)](https://github.com/intel/neural-compressor) for any GLUE task. | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.9780102, 'word': 'Intel Neural Compressor', 'start': 32, 'end': 55}, {'entity_group': 'ORG', 'score': 0.9769186, 'word': 'Intel Neural Compressor', 'start': 270, 'end': 293}, {'entity_group': 'ORG', 'score': 0.94020045, 'word': 'INC', 'start': 295, 'end': 298}, {'entity_group': 'ORG', 'score': 0.4583484, 'word': 'Cola', 'start': 377, 'end': 381}, {'entity_group': 'ORG', 'score': 0.9529767, 'word': 'AWS Studio', 'start': 581, 'end': 591}])
 list([{'entity_group': 'ORG', 'score': 0.9780102, 'word': 'Intel Neural Compressor', 'start': 32, 'end': 55}, {'entity_group': 'ORG', 'score': 0.9769186, 'word': 'Intel Neural Compressor', 'start': 270, 'end': 293}, {'entity_group': 'ORG', 'score': 0.94020045, 'word': 'INC', 'start': 295, 'end': 298}, {'entity_group': 'ORG', 'score': 0.9529767, 'word': 'AWS Studio', 'start': 581, 'end': 591}])]
['730' '66.0' '62'
 '| [How to fine-tune a model on text classification with ONNX Runtime](https://github.com/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb)| Show how to preprocess the data and fine-tune a model on any GLUE task using [ONNX Runtime](https://github.com/microsoft/onnxruntime). | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.9263968, 'word': 'AWS Studio', 'start': 501, 'end': 511}])
 list([{'entity_group': 'ORG', 'score': 0.9263968, 'word': 'AWS Studio', 'start': 501, 'end': 511}])]
['731' '66.0' '63'
 '| [How to fine-tune a model on summarization with ONNX Runtime](https://github.com/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb)| Show how to preprocess the data and fine-tune a model on XSUM using [ONNX Runtime](https://github.com/microsoft/onnxruntime). | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb)| [![Open in AWS Studio](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb)|'
 list([{'entity_group': 'ORG', 'score': 0.543594, 'word': 'ON', 'start': 50, 'end': 52}, {'entity_group': 'MISC', 'score': 0.52808654, 'word': 'X', 'start': 207, 'end': 208}, {'entity_group': 'ORG', 'score': 0.52459955, 'word': '##SU', 'start': 208, 'end': 210}, {'entity_group': 'ORG', 'score': 0.5274404, 'word': 'ON', 'start': 219, 'end': 221}, {'entity_group': 'ORG', 'score': 0.90381575, 'word': 'AWS Studio', 'start': 474, 'end': 484}])
 list([{'entity_group': 'ORG', 'score': 0.90381575, 'word': 'AWS Studio', 'start': 474, 'end': 484}])]
['732' '66.0' '64'
 '## Community notebooks:\n\nMore notebooks developed by the community are available [here](https://hf.co/docs/transformers/community#community-notebooks).'
 list([]) list([])]
['733' '67.0' '0'
 '--\ntitle: "Multivariate Probabilistic Time Series Forecasting with Informer" \nthumbnail: /blog/assets/134_informer/thumbnail.png\nauthors:\n- user: elisim\n  guest: true\n- user: nielsr\n- user: kashif\n---\n\n# Multivariate Probabilistic Time Series Forecasting with Informer\n\n\n<script async defer src="https://unpkg.com/medium-zoom-element@0/dist/medium-zoom-element.min.js"></script>\n\n<a target="_blank" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multivariate_informer.ipynb">\n    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>\n</a>\n\n## Introduction'
 list([{'entity_group': 'ORG', 'score': 0.9853177, 'word': 'Informer', 'start': 67, 'end': 75}, {'entity_group': 'ORG', 'score': 0.98661894, 'word': 'Informer', 'start': 260, 'end': 268}])
 list([{'entity_group': 'ORG', 'score': 0.9853177, 'word': 'Informer', 'start': 67, 'end': 75}, {'entity_group': 'ORG', 'score': 0.98661894, 'word': 'Informer', 'start': 260, 'end': 268}])]
['734' '67.0' '1'
 "## Introduction\n\nA few months ago we introduced the [Time Series Transformer](https://huggingface.co/blog/time-series-transformers), which is the vanilla Transformer ([Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)) applied to forecasting, and showed an example for the **univariate** probabilistic forecasting task (i.e. predicting each time series' 1-d distribution individually). In this post we introduce the _Informer_ model ([Zhou, Haoyi, et al., 2021](https://arxiv.org/abs/2012.07436)), AAAI21 best paper which is [now available](https://huggingface.co/docs/transformers/main/en/model_doc/informer) in 🤗 Transformers. We will show how to use the Informer model for the **multivariate** probabilistic forecasting task, i.e., predicting the distribution of a future **vector** of time-series target values. Note that this will also work for the vanilla Time Series Transformer model.\n\n##  Multivariate Probabilistic Time Series Forecasting"
 list([{'entity_group': 'MISC', 'score': 0.9251822, 'word': 'Time Series Transformer', 'start': 53, 'end': 76}, {'entity_group': 'ORG', 'score': 0.51654255, 'word': '##face', 'start': 93, 'end': 97}, {'entity_group': 'ORG', 'score': 0.53885514, 'word': 'co', 'start': 98, 'end': 100}, {'entity_group': 'MISC', 'score': 0.9740139, 'word': 'Transformer', 'start': 154, 'end': 165}, {'entity_group': 'PER', 'score': 0.81519735, 'word': 'Vaswani', 'start': 168, 'end': 175}, {'entity_group': 'MISC', 'score': 0.96744263, 'word': 'Informer', 'start': 423, 'end': 431}, {'entity_group': 'PER', 'score': 0.9935514, 'word': 'Zhou', 'start': 441, 'end': 445}, {'entity_group': 'PER', 'score': 0.9489382, 'word': 'Haoyi', 'start': 447, 'end': 452}, {'entity_group': 'ORG', 'score': 0.91039914, 'word': 'Transformers', 'start': 621, 'end': 633}, {'entity_group': 'MISC', 'score': 0.97073394, 'word': 'Informer', 'start': 663, 'end': 671}, {'entity_group': 'MISC', 'score': 0.9454659, 'word': 'Time Series Transformer', 'start': 868, 'end': 891}])
 list([{'entity_group': 'MISC', 'score': 0.9251822, 'word': 'Time Series Transformer', 'start': 53, 'end': 76}, {'entity_group': 'MISC', 'score': 0.9740139, 'word': 'Transformer', 'start': 154, 'end': 165}, {'entity_group': 'PER', 'score': 0.81519735, 'word': 'Vaswani', 'start': 168, 'end': 175}, {'entity_group': 'MISC', 'score': 0.96744263, 'word': 'Informer', 'start': 423, 'end': 431}, {'entity_group': 'PER', 'score': 0.9935514, 'word': 'Zhou', 'start': 441, 'end': 445}, {'entity_group': 'PER', 'score': 0.9489382, 'word': 'Haoyi', 'start': 447, 'end': 452}, {'entity_group': 'ORG', 'score': 0.91039914, 'word': 'Transformers', 'start': 621, 'end': 633}, {'entity_group': 'MISC', 'score': 0.97073394, 'word': 'Informer', 'start': 663, 'end': 671}, {'entity_group': 'MISC', 'score': 0.9454659, 'word': 'Time Series Transformer', 'start': 868, 'end': 891}])]
['735' '67.0' '2'
 '##  Multivariate Probabilistic Time Series Forecasting\n\nAs far as the modeling aspect of probabilistic forecasting is concerned, the Transformer/Informer will require no change when dealing with multivariate time series. In both the univariate and multivariate setting, the model will receive a sequence of vectors and thus the only change is on the output or emission side.\n\nModeling the full joint conditional distribution of high dimensional data can get computationally expensive and thus methods resort to some approximation of the distribution, the easiest being to model the data as an independent distribution from the same family, or some low-rank approximation to the full covariance, etc. Here we will just resort to the independent (or diagonal) emissions which are supported for the families of distributions we have implemented [here](https://huggingface.co/docs/transformers/main/en/internal/time_series_utils).\n\n## Informer - Under The Hood'
 list([{'entity_group': 'MISC', 'score': 0.748794, 'word': 'Under The Hood', 'start': 942, 'end': 956}])
 list([])]
['736' '67.0' '3'
 "## Informer - Under The Hood\n\nBased on the vanilla Transformer ([Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)), Informer employs two major improvements. To understand these improvements, let's recall the drawbacks of the vanilla Transformer:"
 list([{'entity_group': 'MISC', 'score': 0.9860086, 'word': 'Informer', 'start': 3, 'end': 11}, {'entity_group': 'MISC', 'score': 0.68609184, 'word': 'Under The', 'start': 14, 'end': 23}, {'entity_group': 'MISC', 'score': 0.9936347, 'word': 'Transformer', 'start': 51, 'end': 62}, {'entity_group': 'PER', 'score': 0.85873944, 'word': 'Vaswani', 'start': 65, 'end': 72}, {'entity_group': 'MISC', 'score': 0.9910544, 'word': 'Informer', 'start': 123, 'end': 131}, {'entity_group': 'MISC', 'score': 0.9883313, 'word': 'Transformer', 'start': 240, 'end': 251}])
 list([{'entity_group': 'MISC', 'score': 0.9860086, 'word': 'Informer', 'start': 3, 'end': 11}, {'entity_group': 'MISC', 'score': 0.9936347, 'word': 'Transformer', 'start': 51, 'end': 62}, {'entity_group': 'PER', 'score': 0.85873944, 'word': 'Vaswani', 'start': 65, 'end': 72}, {'entity_group': 'MISC', 'score': 0.9910544, 'word': 'Informer', 'start': 123, 'end': 131}, {'entity_group': 'MISC', 'score': 0.9883313, 'word': 'Transformer', 'start': 240, 'end': 251}])]
['737' '67.0' '4'
 "1. **Quadratic computation of canonical self-attention:** The vanilla Transformer has a computational complexity of \\\\(O(T^2 D)\\\\) where \\\\(T\\\\) is the time series length and \\\\(D\\\\) is the dimension of the hidden states. For long sequence time-series forecasting (also known as the _LSTF problem_), this might be really computationally expensive. To solve this problem, Informer employs a new self-attention mechanism called _ProbSparse_ attention, which has \\\\(O(T \\log T)\\\\) time and space complexity.\n1. **Memory bottleneck when stacking layers:** When stacking \\\\(N\\\\) encoder/decoder layers, the vanilla Transformer has a memory usage of \\\\(O(N T^2)\\\\), which limits the model's capacity for long sequences. Informer uses a _Distilling_ operation, for reducing the input size between layers into its half slice. By doing so, it reduces the whole memory usage to be \\\\(O(N\\cdot T \\log T)\\\\)."
 list([{'entity_group': 'MISC', 'score': 0.57036996, 'word': 'Transformer', 'start': 70, 'end': 81}, {'entity_group': 'ORG', 'score': 0.40886703, 'word': 'L', 'start': 284, 'end': 285}, {'entity_group': 'ORG', 'score': 0.9948183, 'word': 'Informer', 'start': 371, 'end': 379}, {'entity_group': 'MISC', 'score': 0.79002875, 'word': 'Trans', 'start': 610, 'end': 615}, {'entity_group': 'ORG', 'score': 0.5328424, 'word': '##former', 'start': 615, 'end': 621}, {'entity_group': 'ORG', 'score': 0.9932134, 'word': 'Informer', 'start': 714, 'end': 722}])
 list([{'entity_group': 'ORG', 'score': 0.9948183, 'word': 'Informer', 'start': 371, 'end': 379}, {'entity_group': 'ORG', 'score': 0.9932134, 'word': 'Informer', 'start': 714, 'end': 722}])]
['738' '67.0' '5'
 'As you can see, the motivation for the Informer model is similar to Longformer ([Beltagy et el., 2020](https://arxiv.org/abs/2004.05150)), Sparse Transformer ([Child et al., 2019](https://arxiv.org/abs/1904.10509)) and other NLP papers for reducing the quadratic complexity of the self-attention mechanism **when the input sequence is long**. Now, let\'s dive into _ProbSparse_ attention and the _Distilling_ operation with code examples. \n\n### ProbSparse Attention\n\nThe main idea of ProbSparse is that the canonical self-attention scores form a long-tail distribution, where the "active" queries lie in the "head" scores and "lazy" queries lie in the "tail" area. By "active" query we mean a query \\\\(q_i\\\\) such that the dot-product \\\\(\\langle q_i,k_i \\rangle\\\\) **contributes** to the major attention, whereas a "lazy" query forms a dot-product which generates **trivial** attention. Here, \\\\(q_i\\\\) and \\\\(k_i\\\\) are the \\\\(i\\\\)-th rows in \\\\(Q\\\\) and \\\\(K\\\\) attention matrices respectively.'
 list([{'entity_group': 'MISC', 'score': 0.94495606, 'word': 'Informer', 'start': 39, 'end': 47}, {'entity_group': 'MISC', 'score': 0.95611143, 'word': 'Longformer', 'start': 68, 'end': 78}, {'entity_group': 'PER', 'score': 0.7538908, 'word': 'Beltagy', 'start': 81, 'end': 88}, {'entity_group': 'MISC', 'score': 0.95095044, 'word': 'Spa', 'start': 139, 'end': 142}, {'entity_group': 'MISC', 'score': 0.8076887, 'word': 'Transformer', 'start': 146, 'end': 157}, {'entity_group': 'PER', 'score': 0.99310476, 'word': 'Child', 'start': 160, 'end': 165}, {'entity_group': 'ORG', 'score': 0.94003534, 'word': 'NLP', 'start': 225, 'end': 228}, {'entity_group': 'ORG', 'score': 0.37275323, 'word': '##se', 'start': 491, 'end': 493}])
 list([{'entity_group': 'MISC', 'score': 0.94495606, 'word': 'Informer', 'start': 39, 'end': 47}, {'entity_group': 'MISC', 'score': 0.95611143, 'word': 'Longformer', 'start': 68, 'end': 78}, {'entity_group': 'MISC', 'score': 0.95095044, 'word': 'Spa', 'start': 139, 'end': 142}, {'entity_group': 'MISC', 'score': 0.8076887, 'word': 'Transformer', 'start': 146, 'end': 157}, {'entity_group': 'PER', 'score': 0.99310476, 'word': 'Child', 'start': 160, 'end': 165}, {'entity_group': 'ORG', 'score': 0.94003534, 'word': 'NLP', 'start': 225, 'end': 228}])]
['739' '67.0' '6'
 '| ![informer_full_vs_sparse_attention](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/informer_full_vs_sparse_attention.png) |\n|:--:|\n| Vanilla self attention vs ProbSparse attention from [Autoformer (Wu, Haixu, et al., 2021)](https://wuhaixu2016.github.io/pdf/NeurIPS2021_Autoformer.pdf) |\n\nGiven the idea of "active" and "lazy" queries, the ProbSparse attention selects the "active" queries, and creates a reduced query matrix \\\\(Q_{reduced}\\\\) which is used to calculate the attention weights in \\\\(O(T \\log T)\\\\). Let\'s see this more in detail with a code example. \n    \nRecall the canonical self-attention formula:\n\n$$\n\\textrm{Attention}(Q, K, V) = \\textrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}} )V\n$$'
 list([{'entity_group': 'ORG', 'score': 0.754914, 'word': 'Autoformer', 'start': 234, 'end': 244}, {'entity_group': 'PER', 'score': 0.99246454, 'word': 'Wu', 'start': 246, 'end': 248}, {'entity_group': 'PER', 'score': 0.8253216, 'word': 'Haixu', 'start': 250, 'end': 255}, {'entity_group': 'ORG', 'score': 0.7989411, 'word': 'N', 'start': 306, 'end': 307}, {'entity_group': 'ORG', 'score': 0.6668652, 'word': '##IP', 'start': 310, 'end': 312}, {'entity_group': 'ORG', 'score': 0.50451195, 'word': 'Autoformer', 'start': 318, 'end': 328}, {'entity_group': 'ORG', 'score': 0.86212736, 'word': '##se', 'start': 396, 'end': 398}])
 list([{'entity_group': 'PER', 'score': 0.99246454, 'word': 'Wu', 'start': 246, 'end': 248}, {'entity_group': 'PER', 'score': 0.8253216, 'word': 'Haixu', 'start': 250, 'end': 255}, {'entity_group': 'ORG', 'score': 0.86212736, 'word': '##se', 'start': 396, 'end': 398}])]
['740' '67.0' '7'
 '$$\n\\textrm{Attention}(Q, K, V) = \\textrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}} )V\n$$\n\nWhere \\\\(Q\\in \\mathbb{R}^{L_Q \\times d}\\\\), \\\\(K\\in \\mathbb{R}^{L_K \\times d}\\\\) and \\\\(V\\in \\mathbb{R}^{L_V \\times d}\\\\). Note that in practice, the input length of queries and keys are typically equivalent in the self-attention computation, i.e. \\\\(L_Q = L_K = T\\\\) where \\\\(T\\\\) is the time series length. Therefore, the \\\\(QK^T\\\\) multiplication takes \\\\(O(T^2 \\cdot d)\\\\) computational complexity. In ProbSparse attention, our goal is to create a new \\\\(Q_{reduce}\\\\) matrix and define:\n\n$$\n\\textrm{ProbSparseAttention}(Q, K, V) = \\textrm{softmax}(\\frac{Q_{reduce}K^T}{\\sqrt{d_k}} )V\n$$'
 list([{'entity_group': 'LOC', 'score': 0.61580473, 'word': 'R', 'start': 103, 'end': 104}, {'entity_group': 'LOC', 'score': 0.46112683, 'word': 'R', 'start': 141, 'end': 142}, {'entity_group': 'ORG', 'score': 0.5773202, 'word': '##se', 'start': 495, 'end': 497}])
 list([])]
['741' '67.0' '8'
 '$$\n\\textrm{ProbSparseAttention}(Q, K, V) = \\textrm{softmax}(\\frac{Q_{reduce}K^T}{\\sqrt{d_k}} )V\n$$\n\nwhere the \\\\(Q_{reduce}\\\\) matrix only selects the Top  \\\\(u\\\\) "active" queries. Here, \\\\(u = c \\cdot \\log L_Q\\\\) and \\\\(c\\\\) called the _sampling factor_ hyperparameter for the ProbSparse attention. Since \\\\(Q_{reduce}\\\\) selects only the Top \\\\(u\\\\) queries, its size is \\\\(c\\cdot \\log L_Q \\times d\\\\), so the multiplication \\\\(Q_{reduce}K^T\\\\) takes only \\\\(O(L_K \\log L_Q) = O(T \\log T)\\\\).\n\nThis is good! But how can we select the \\\\(u\\\\) "active" queries to create \\\\(Q_{reduce}\\\\)? Let\'s define the _Query Sparsity Measurement_.'
 list([]) list([])]
['742' '67.0' '9'
 '#### Query Sparsity Measurement\nQuery Sparsity Measurement \\\\(M(q_i, K)\\\\) is used for selecting the \\\\(u\\\\) "active" queries \\\\(q_i\\\\) in \\\\(Q\\\\) to create \\\\(Q_{reduce}\\\\). In theory, the dominant \\\\(\\langle q_i,k_i \\rangle\\\\) pairs encourage the "active" \\\\(q_i\\\\)\'s probability distribution **away** from the uniform distribution as can be seen in the figure below. Hence, the [KL divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between the actual queries distribution and the uniform distribution is used to define the sparsity measurement. \n\n| ![informer_probsparse](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/informer_probsparse.png) | \n|:--:|\n| The illustration of ProbSparse Attention from official [repository](https://github.com/zhouhaoyi/Informer2020)|\n\n\nIn practice, the measurement is defined as:\n\n$$\nM(q_i, K) = \\max_j \\frac{q_ik_j^T}{\\sqrt{d}}-\\frac{1}{L_k} \\sum_{j=1}^{L_k}\\frac{q_ik_j^T}{\\sqrt{d}}\n$$'
 list([{'entity_group': 'PER', 'score': 0.7127522, 'word': 'Ku', 'start': 427, 'end': 429}])
 list([])]
['743' '67.0' '10'
 'The important thing to understand here is when \\\\(M(q_i, K)\\\\) is larger, the query \\\\(q_i\\\\) should be in \\\\(Q_{reduce}\\\\) and vice versa.\n\nBut how can we calculate the term \\\\(q_ik_j^T\\\\) in non-quadratic time? Recall that most of the dot-product \\\\(\\langle q_i,k_i \\rangle\\\\) generate either way the trivial attention (i.e. long-tail distribution property), so it is enough to randomly sample a subset of keys from \\\\(K\\\\), which will be called `K_sample` in the code.\n\nNow, we are ready to see the code of `probsparse_attention`:\n    \n```python\nfrom torch import nn\nimport math\n\n\ndef probsparse_attention(query_states, key_states, value_states, sampling_factor=5):\n    """\n    Compute the probsparse self-attention.\n    Input shape: Batch x Time x Channel'
 list([]) list([])]
['744' '67.0' '11'
 'Note the additional `sampling_factor` input.\n    """\n    # get input sizes with logs\n    L_K = key_states.size(1)\n    L_Q = query_states.size(1)\n    log_L_K = np.ceil(np.log1p(L_K)).astype("int").item()\n    log_L_Q = np.ceil(np.log1p(L_Q)).astype("int").item()\n\n    # calculate a subset of samples to slice from K and create Q_K_sample\n    U_part = min(sampling_factor * L_Q * log_L_K, L_K)\n\n    # create Q_K_sample (the q_i * k_j^T term in the sparsity measurement)\n    index_sample = torch.randint(0, L_K, (U_part,))\n    K_sample = key_states[:, index_sample, :]\n    Q_K_sample = torch.bmm(query_states, K_sample.transpose(1, 2))\n\n    # calculate the query sparsity measurement with Q_K_sample\n    M = Q_K_sample.max(dim=-1)[0] - torch.div(Q_K_sample.sum(dim=-1), L_K)\n\n    # calculate u to find the Top-u queries under the sparsity measurement\n    u = min(sampling_factor * log_L_Q, L_Q)\n    M_top = M.topk(u, sorted=False)[1]'
 list([]) list([])]
['745' '67.0' '12'
 '# calculate Q_reduce as query_states[:, M_top]\n    dim_for_slice = torch.arange(query_states.size(0)).unsqueeze(-1)\n    Q_reduce = query_states[dim_for_slice, M_top]  # size: c*log_L_Q x channel\n\n    # and now, same as the canonical\n    d_k = query_states.size(-1)\n    attn_scores = torch.bmm(Q_reduce, key_states.transpose(-2, -1))  # Q_reduce x K^T\n    attn_scores = attn_scores / math.sqrt(d_k)\n    attn_probs = nn.functional.softmax(attn_scores, dim=-1)\n    attn_output = torch.bmm(attn_probs, value_states)\n\n    return attn_output, attn_scores'
 list([]) list([])]
['746' '67.0' '13'
 '```\nNote that in the implementation, \\\\(U_{part}\\\\) contain \\\\(L_Q\\\\) in the calculation, for stability issues (see [this disccusion](https://discuss.huggingface.co/t/probsparse-attention-in-informer/34428) for more information).\n\nWe did it! Please be aware that this is only a partial implementation of the `probsparse_attention`, and the full implementation can be found in 🤗 Transformers.\n\n### Distilling\n\nBecause of the ProbSparse self-attention, the encoder’s feature map has some redundancy that can be removed. Therefore,\nthe distilling operation is used to reduce the input size between encoder layers into its half slice, thus in theory removing this redundancy. In practice, Informer\'s "distilling" operation just adds 1D convolution layers with max pooling between each of the encoder layers. Let \\\\(X_n\\\\) be the output of the \\\\(n\\\\)-th encoder layer, the distilling operation is then defined as:\n\n\n$$\nX_{n+1} = \\textrm{MaxPool} ( \\textrm{ELU}(\\textrm{Conv1d}(X_n))\n$$'
 list([{'entity_group': 'ORG', 'score': 0.96537524, 'word': 'Transformers', 'start': 378, 'end': 390}, {'entity_group': 'ORG', 'score': 0.99599165, 'word': 'Informer', 'start': 685, 'end': 693}])
 list([{'entity_group': 'ORG', 'score': 0.96537524, 'word': 'Transformers', 'start': 378, 'end': 390}, {'entity_group': 'ORG', 'score': 0.99599165, 'word': 'Informer', 'start': 685, 'end': 693}])]
['747' '67.0' '14'
 "$$\nX_{n+1} = \\textrm{MaxPool} ( \\textrm{ELU}(\\textrm{Conv1d}(X_n))\n$$\n\n\nLet's see this in code:\n    \n```python\nfrom torch import nn\n\n# ConvLayer is a class with forward pass applying ELU and MaxPool1d\ndef informer_encoder_forward(x_input, num_encoder_layers=3, distil=True):\n    # Initialize the convolution layers\n    if distil:\n        conv_layers = nn.ModuleList([ConvLayer() for _ in range(num_encoder_layers - 1)])\n        conv_layers.append(None)\n    else:\n        conv_layers = [None] * num_encoder_layers\n    \n    # Apply conv_layer between each encoder_layer\n    for encoder_layer, conv_layer in zip(encoder_layers, conv_layers):\n        output = encoder_layer(x_input)\n        if conv_layer is not None:\n            output = conv_layer(loutput)\n    \n    return output"
 list([{'entity_group': 'ORG', 'score': 0.802382, 'word': '##Lay', 'start': 139, 'end': 142}, {'entity_group': 'ORG', 'score': 0.5533903, 'word': '##L', 'start': 371, 'end': 372}])
 list([{'entity_group': 'ORG', 'score': 0.802382, 'word': '##Lay', 'start': 139, 'end': 142}])]
['748' '67.0' '15'
 "```\n    \nBy reducing the input of each layer by two, we get a memory usage of \\\\(O(N\\cdot T \\log T)\\\\) instead of \\\\(O(N\\cdot T^2)\\\\) where \\\\(N\\\\) is the number of encoder/decoder layers. This is what we wanted!\n    \nThe Informer model in [now available](https://huggingface.co/docs/transformers/main/en/model_doc/informer) in the 🤗 Transformers library, and simply called `InformerModel`. In the sections below, we will show how to train this model on a custom multivariate time-series dataset.\n\n\n## Set-up Environment\n\nFirst, let's install the necessary libraries: 🤗 Transformers, 🤗 Datasets, 🤗 Evaluate, 🤗 Accelerate and [GluonTS](https://github.com/awslabs/gluonts).\n\nAs we will show, GluonTS will be used for transforming the data to create features as well as for creating appropriate training, validation and test batches.\n\n\n```python\n!pip install -q transformers datasets evaluate accelerate gluonts ujson"
 list([{'entity_group': 'MISC', 'score': 0.9926289, 'word': 'Informer', 'start': 222, 'end': 230}, {'entity_group': 'ORG', 'score': 0.96013176, 'word': 'Transformers', 'start': 334, 'end': 346}, {'entity_group': 'MISC', 'score': 0.95540965, 'word': 'Informer', 'start': 375, 'end': 383}, {'entity_group': 'ORG', 'score': 0.5365882, 'word': '##Mode', 'start': 383, 'end': 387}, {'entity_group': 'MISC', 'score': 0.7964419, 'word': '##l', 'start': 387, 'end': 388}, {'entity_group': 'ORG', 'score': 0.81859994, 'word': 'Environment First', 'start': 509, 'end': 527}, {'entity_group': 'ORG', 'score': 0.9296659, 'word': 'Transformers', 'start': 570, 'end': 582}, {'entity_group': 'ORG', 'score': 0.8472106, 'word': 'G', 'start': 626, 'end': 627}, {'entity_group': 'ORG', 'score': 0.39603668, 'word': 'G', 'start': 690, 'end': 691}])
 list([{'entity_group': 'MISC', 'score': 0.9926289, 'word': 'Informer', 'start': 222, 'end': 230}, {'entity_group': 'ORG', 'score': 0.96013176, 'word': 'Transformers', 'start': 334, 'end': 346}, {'entity_group': 'MISC', 'score': 0.95540965, 'word': 'Informer', 'start': 375, 'end': 383}, {'entity_group': 'ORG', 'score': 0.81859994, 'word': 'Environment First', 'start': 509, 'end': 527}, {'entity_group': 'ORG', 'score': 0.9296659, 'word': 'Transformers', 'start': 570, 'end': 582}, {'entity_group': 'ORG', 'score': 0.8472106, 'word': 'G', 'start': 626, 'end': 627}])]
['749' '67.0' '16'
 '```\n\n## Load Dataset\n\nIn this blog post, we\'ll use the `traffic_hourly` dataset, which is available on the [Hugging Face Hub](https://huggingface.co/datasets/monash_tsf). This dataset contains the San Francisco Traffic dataset used by [Lai et al. (2017)](https://arxiv.org/abs/1703.07015). It contains 862 hourly time series showing the road occupancy rates in the range \\\\([0, 1]\\\\) on the San Francisco Bay area freeways from 2015 to 2016.\n\nThis dataset is part of the [Monash Time Series Forecasting](https://forecastingdata.org/) repository, a collection of time series datasets from a number of domains. It can be viewed as the [GLUE benchmark](https://gluebenchmark.com/) of time series forecasting.\n\n\n```python\nfrom datasets import load_dataset\n\ndataset = load_dataset("monash_tsf", "traffic_hourly")'
 list([{'entity_group': 'ORG', 'score': 0.86717635, 'word': 'Hugging Face Hub', 'start': 108, 'end': 124}, {'entity_group': 'ORG', 'score': 0.92718226, 'word': '##face', 'start': 141, 'end': 145}, {'entity_group': 'ORG', 'score': 0.7623295, 'word': 'co', 'start': 146, 'end': 148}, {'entity_group': 'LOC', 'score': 0.7489222, 'word': 'San Francisco', 'start': 197, 'end': 210}, {'entity_group': 'MISC', 'score': 0.6634263, 'word': 'Traffic', 'start': 211, 'end': 218}, {'entity_group': 'PER', 'score': 0.99642414, 'word': 'Lai', 'start': 236, 'end': 239}, {'entity_group': 'LOC', 'score': 0.992311, 'word': 'San Francisco Bay', 'start': 391, 'end': 408}, {'entity_group': 'ORG', 'score': 0.77119267, 'word': 'Monash', 'start': 472, 'end': 478}, {'entity_group': 'MISC', 'score': 0.7612392, 'word': 'Time Series', 'start': 479, 'end': 490}, {'entity_group': 'ORG', 'score': 0.5791098, 'word': 'For', 'start': 491, 'end': 494}, {'entity_group': 'MISC', 'score': 0.7709763, 'word': 'G', 'start': 634, 'end': 635}])
 list([{'entity_group': 'ORG', 'score': 0.86717635, 'word': 'Hugging Face Hub', 'start': 108, 'end': 124}, {'entity_group': 'ORG', 'score': 0.92718226, 'word': '##face', 'start': 141, 'end': 145}, {'entity_group': 'PER', 'score': 0.99642414, 'word': 'Lai', 'start': 236, 'end': 239}, {'entity_group': 'LOC', 'score': 0.992311, 'word': 'San Francisco Bay', 'start': 391, 'end': 408}])]
['750' '67.0' '17'
 '```\n\nAs can be seen, the dataset contains 3 splits: train, validation and test.\n\n\n```python\ndataset\n\n>>> DatasetDict({\n        train: Dataset({\n            features: [\'start\', \'target\', \'feat_static_cat\', \'feat_dynamic_real\', \'item_id\'],\n            num_rows: 862\n        })\n        test: Dataset({\n            features: [\'start\', \'target\', \'feat_static_cat\', \'feat_dynamic_real\', \'item_id\'],\n            num_rows: 862\n        })\n        validation: Dataset({\n            features: [\'start\', \'target\', \'feat_static_cat\', \'feat_dynamic_real\', \'item_id\'],\n            num_rows: 862\n        })\n    })\n```\n\nEach example contains a few keys, of which `start` and `target` are the most important ones. Let us have a look at the first time series in the dataset:\n\n\n```python\ntrain_example = dataset["train"][0]\ntrain_example.keys()\n\n>>> dict_keys([\'start\', \'target\', \'feat_static_cat\', \'feat_dynamic_real\', \'item_id\'])'
 list([]) list([])]
['751' '67.0' '18'
 '```\n\nThe `start` simply indicates the start of the time series (as a datetime), and the `target` contains the actual values of the time series.\n\nThe `start` will be useful to add time related features to the time series values, as extra input to the model (such as "month of year"). Since we know the frequency of the data is `hourly`, we know for instance that the second value has the timestamp `2015-01-01 01:00:01`, `2015-01-01 02:00:01`, etc.\n\n\n```python\nprint(train_example["start"])\nprint(len(train_example["target"]))\n\n>>> 2015-01-01 00:00:01\n    17448'
 list([]) list([])]
['752' '67.0' '19'
 '```\n\nThe validation set contains the same data as the training set, just for a `prediction_length` longer amount of time. This allows us to validate the model\'s predictions against the ground truth.\n\nThe test set is again one `prediction_length` longer data compared to the validation set (or some multiple of `prediction_length` longer data compared to the training set for testing on multiple rolling windows).\n\n\n```python\nvalidation_example = dataset["validation"][0]\nvalidation_example.keys()\n\n>>> dict_keys([\'start\', \'target\', \'feat_static_cat\', \'feat_dynamic_real\', \'item_id\'])\n```\n\nThe initial values are exactly the same as the corresponding training example. However, this example has `prediction_length=48` (48 hours, or 2 days) additional values compared to the training example. Let us verify it.\n\n\n```python\nfreq = "1H"\nprediction_length = 48\n\nassert len(train_example["target"]) + prediction_length == len(\n    dataset["validation"][0]["target"]\n)'
 list([]) list([])]
['753' '67.0' '20'
 '```\n\nLet\'s visualize this:\n\n\n```python\nimport matplotlib.pyplot as plt\n\nnum_of_samples = 150\n\nfigure, axes = plt.subplots()\naxes.plot(train_example["target"][-num_of_samples:], color="blue")\naxes.plot(\n    validation_example["target"][-num_of_samples - prediction_length :],\n    color="red",\n    alpha=0.5,\n)\n\nplt.show()\n```\n    \n![png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/output_22_0.png)\n    \n\nLet\'s split up the data:\n\n\n```python\ntrain_dataset = dataset["train"]\ntest_dataset = dataset["test"]'
 list([]) list([])]
['754' '67.0' '21'
 '```\n\n## Update `start` to `pd.Period`\n\nThe first thing we\'ll do is convert the `start` feature of each time series to a pandas `Period` index using the data\'s `freq`:\n\n\n```python\nfrom functools import lru_cache\n\nimport pandas as pd\nimport numpy as np\n\n\n@lru_cache(10_000)\ndef convert_to_pandas_period(date, freq):\n    return pd.Period(date, freq)\n\n\ndef transform_start_field(batch, freq):\n    batch["start"] = [convert_to_pandas_period(date, freq) for date in batch["start"]]\n    return batch\n```\n\nWe now use `datasets`\' [`set_transform`](https://huggingface.co/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.set_transform) functionality to do this on-the-fly in place:\n\n\n```python\nfrom functools import partial\n\ntrain_dataset.set_transform(partial(transform_start_field, freq=freq))\ntest_dataset.set_transform(partial(transform_start_field, freq=freq))'
 list([]) list([])]
['755' '67.0' '22'
 "```\n\nNow, let's convert the dataset into a multivariate time series using the `MultivariateGrouper` from GluonTS. This grouper will convert the individual 1-dimensional time series into a single 2D matrix.\n\n\n```python\nfrom gluonts.dataset.multivariate_grouper import MultivariateGrouper\n\nnum_of_variates = len(train_dataset)\n\ntrain_grouper = MultivariateGrouper(max_target_dim=num_of_variates)\ntest_grouper = MultivariateGrouper(\n    max_target_dim=num_of_variates,\n    num_test_dates=len(test_dataset) // num_of_variates, # number of rolling test windows\n)\n\nmulti_variate_train_dataset = train_grouper(train_dataset)\nmulti_variate_test_dataset = test_grouper(test_dataset)"
 list([{'entity_group': 'MISC', 'score': 0.3323331, 'word': 'Multi', 'start': 79, 'end': 84}, {'entity_group': 'ORG', 'score': 0.53596383, 'word': '##G', 'start': 91, 'end': 92}, {'entity_group': 'ORG', 'score': 0.9182247, 'word': 'GluonTS', 'start': 105, 'end': 112}, {'entity_group': 'ORG', 'score': 0.57865417, 'word': '##G', 'start': 279, 'end': 280}, {'entity_group': 'ORG', 'score': 0.53976464, 'word': '##G', 'start': 354, 'end': 355}, {'entity_group': 'ORG', 'score': 0.5626135, 'word': '##G', 'start': 421, 'end': 422}])
 list([{'entity_group': 'ORG', 'score': 0.9182247, 'word': 'GluonTS', 'start': 105, 'end': 112}])]
['756' '67.0' '23'
 '```\n\nNote that the target is now 2-dimensional, where the first dimension is the number of variates (number of time series) and the second is the time series values (time dimension): \n\n\n```python\nmulti_variate_train_example = multi_variate_train_dataset[0]\nprint("multi_variate_train_example["target"].shape =", multi_variate_train_example["target"].shape)\n\n>>> multi_variate_train_example["target"].shape = (862, 17448)'
 list([]) list([])]
['757' '67.0' '24'
 "```\n\n## Define the Model\n\nNext, let's instantiate a model. The model will be trained from scratch, hence we won't use the `from_pretrained` method here, but rather randomly initialize the model from a [`config`](https://huggingface.co/docs/transformers/main/en/model_doc/informer#transformers.InformerConfig)."
 list([]) list([])]
['758' '67.0' '25'
 'We specify a couple of additional parameters to the model:\n- `prediction_length` (in our case, `48` hours): this is the horizon that the decoder of the Informer will learn to predict for;\n- `context_length`: the model will set the `context_length` (input of the encoder) equal to the `prediction_length`, if no `context_length` is specified;\n- `lags` for a given frequency: these specify an efficient "look back" mechanism, where we concatenate values from the past to the current values as additional features, e.g. for a `Daily` frequency we might consider a look back of `[1, 7, 30, ...]` or for `Minute` data we might consider `[1, 30, 60, 60*24, ...]` etc.;\n- the number of time features: in our case, this will be `5` as we\'ll add `HourOfDay`, `DayOfWeek`, ..., and `Age` features (see below).\n\nLet us check the default lags provided by GluonTS for the given frequency ("hourly"):\n\n\n```python\nfrom gluonts.time_feature import get_lags_for_frequency'
 list([{'entity_group': 'MISC', 'score': 0.43734366, 'word': 'Informer', 'start': 152, 'end': 160}, {'entity_group': 'MISC', 'score': 0.572114, 'word': 'Age', 'start': 773, 'end': 776}, {'entity_group': 'ORG', 'score': 0.9297702, 'word': 'GluonTS', 'start': 843, 'end': 850}])
 list([{'entity_group': 'ORG', 'score': 0.9297702, 'word': 'GluonTS', 'start': 843, 'end': 850}])]
['759' '67.0' '26'
 '```python\nfrom gluonts.time_feature import get_lags_for_frequency\n\nlags_sequence = get_lags_for_frequency(freq)\nprint(lags_sequence)\n\n>>> [1, 2, 3, 4, 5, 6, 7, 23, 24, 25, 47, 48, 49, 71, 72, 73, 95, 96, 97, 119, 120, \n     121, 143, 144, 145, 167, 168, 169, 335, 336, 337, 503, 504, 505, 671, 672, 673, 719, 720, 721]'
 list([]) list([])]
['760' '67.0' '27'
 '```\n\nThis means that this would look back up to 721 hours (~30 days) for each time step, as additional features. However, the resulting feature vector would end up being of size `len(lags_sequence)*num_of_variates` which for our case will be 34480! This is not going to work so we will use our own sensible lags.\n\nLet us also check the default time features which GluonTS provides us:\n\n\n```python\nfrom gluonts.time_feature import time_features_from_frequency_str\n\ntime_features = time_features_from_frequency_str(freq)\nprint(time_features)\n\n>>> [<function hour_of_day at 0x7f3809539240>, <function day_of_week at 0x7f3809539360>, <function day_of_month at 0x7f3809539480>, <function day_of_year at 0x7f38095395a0>]'
 list([{'entity_group': 'ORG', 'score': 0.9198456, 'word': 'GluonTS', 'start': 364, 'end': 371}])
 list([{'entity_group': 'ORG', 'score': 0.9198456, 'word': 'GluonTS', 'start': 364, 'end': 371}])]
['761' '67.0' '28'
 '```\n\nIn this case, there are four additional features, namely "hour of day", "day of week", "day of month" and "day of year". This means that for each time step, we\'ll add these features as a scalar values. For example, consider the timestamp `2015-01-01 01:00:01`. The four additional features will be:\n\n\n```python\nfrom pandas.core.arrays.period import period_array\n\ntimestamp = pd.Period("2015-01-01 01:00:01", freq=freq)\ntimestamp_as_index = pd.PeriodIndex(data=period_array([timestamp]))\nadditional_features = [\n    (time_feature.__name__, time_feature(timestamp_as_index))\n    for time_feature in time_features\n]\nprint(dict(additional_features))\n\n>>> {\'hour_of_day\': array([-0.45652174]), \'day_of_week\': array([0.]), \'day_of_month\': array([-0.5]), \'day_of_year\': array([-0.5])}'
 list([]) list([])]
['762' '67.0' '29'
 '```\n\nNote that hours and days are encoded as values between `[-0.5, 0.5]` from GluonTS. For more information about `time_features`, please see [this](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/time_feature/_base.py). Besides those 4 features, we\'ll also add an "age" feature as we\'ll see later on in the data transformations.\n\nWe now have everything to define the model:\n\n\n```python\nfrom transformers import InformerConfig, InformerForPrediction'
 list([{'entity_group': 'ORG', 'score': 0.71968514, 'word': 'GluonTS', 'start': 79, 'end': 86}, {'entity_group': 'ORG', 'score': 0.79266477, 'word': 'InformerC', 'start': 421, 'end': 430}, {'entity_group': 'ORG', 'score': 0.47237733, 'word': '##g', 'start': 434, 'end': 435}, {'entity_group': 'ORG', 'score': 0.7341258, 'word': 'InformerForP', 'start': 437, 'end': 449}, {'entity_group': 'ORG', 'score': 0.829566, 'word': '##ion', 'start': 455, 'end': 458}])
 list([{'entity_group': 'ORG', 'score': 0.829566, 'word': '##ion', 'start': 455, 'end': 458}])]
['763' '67.0' '30'
 '```python\nfrom transformers import InformerConfig, InformerForPrediction\n\nconfig = InformerConfig(\n    # in the multivariate setting, input_size is the number of variates in the time series per time step\n    input_size=num_of_variates,\n    # prediction length:\n    prediction_length=prediction_length,\n    # context length:\n    context_length=prediction_length * 2,\n    # lags value copied from 1 week before:\n    lags_sequence=[1, 24 * 7],\n    # we\'ll add 5 time features ("hour_of_day", ..., and "age"):\n    num_time_features=len(time_features) + 1,\n    \n    # informer params:\n    dropout=0.1,\n    encoder_layers=6,\n    decoder_layers=4,\n    # project input from num_of_variates*len(lags_sequence)+num_time_features to:\n    d_model=64,\n)\n\nmodel = InformerForPrediction(config)'
 list([{'entity_group': 'ORG', 'score': 0.6174986, 'word': 'In', 'start': 51, 'end': 53}, {'entity_group': 'ORG', 'score': 0.7462249, 'word': '##F', 'start': 59, 'end': 60}])
 list([])]
['764' '67.0' '31'
 "```\n\nBy default, the model uses a diagonal Student-t distribution (but this is [configurable](https://huggingface.co/docs/transformers/main/en/internal/time_series_utils)):\n\n\n```python\nmodel.config.distribution_output\n\n>>> 'student_t'"
 list([{'entity_group': 'MISC', 'score': 0.97600776, 'word': 'Student', 'start': 43, 'end': 50}, {'entity_group': 'MISC', 'score': 0.8450224, 'word': 't', 'start': 51, 'end': 52}])
 list([{'entity_group': 'MISC', 'score': 0.97600776, 'word': 'Student', 'start': 43, 'end': 50}, {'entity_group': 'MISC', 'score': 0.8450224, 'word': 't', 'start': 51, 'end': 52}])]
['765' '67.0' '32'
 "```\n\n## Define Transformations\n\nNext, we define the transformations for the data, in particular for the creation of the time features (based on the dataset or universal ones).\n\nAgain, we'll use the GluonTS library for this. We define a `Chain` of transformations (which is a bit comparable to `torchvision.transforms.Compose` for images). It allows us to combine several transformations into a single pipeline.\n\n\n```python\nfrom gluonts.time_feature import TimeFeature\nfrom gluonts.dataset.field_names import FieldName\nfrom gluonts.transform import (\n    AddAgeFeature,\n    AddObservedValuesIndicator,\n    AddTimeFeatures,\n    AsNumpyArray,\n    Chain,\n    ExpectedNumInstanceSampler,\n    InstanceSplitter,\n    RemoveFields,\n    SelectFields,\n    SetField,\n    TestSplitSampler,\n    Transformation,\n    ValidationSplitSampler,\n    VstackFeatures,\n    RenameFields,\n)"
 list([{'entity_group': 'ORG', 'score': 0.759596, 'word': 'G', 'start': 198, 'end': 199}, {'entity_group': 'ORG', 'score': 0.67856336, 'word': '##onTS', 'start': 201, 'end': 205}, {'entity_group': 'MISC', 'score': 0.82115585, 'word': 'Chain', 'start': 237, 'end': 242}, {'entity_group': 'ORG', 'score': 0.6471414, 'word': '##vision', 'start': 299, 'end': 305}])
 list([{'entity_group': 'MISC', 'score': 0.82115585, 'word': 'Chain', 'start': 237, 'end': 242}])]
['766' '67.0' '33'
 '```\n\nThe transformations below are annotated with comments, to explain what they do. At a high level, we will iterate over the individual time series of our dataset and add/remove fields or features:\n\n\n```python\nfrom transformers import PretrainedConfig\n\n\ndef create_transformation(freq: str, config: PretrainedConfig) -> Transformation:\n    # create list of fields to remove later\n    remove_field_names = []\n    if config.num_static_real_features == 0:\n        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n    if config.num_dynamic_real_features == 0:\n        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n    if config.num_static_categorical_features == 0:\n        remove_field_names.append(FieldName.FEAT_STATIC_CAT)'
 list([{'entity_group': 'MISC', 'score': 0.71556246, 'word': 'D', 'start': 612, 'end': 613}])
 list([])]
['767' '67.0' '34'
 'return Chain(\n        # step 1: remove static/dynamic fields if not specified\n        [RemoveFields(field_names=remove_field_names)]\n        # step 2: convert the data to NumPy (potentially not needed)\n        + (\n            [\n                AsNumpyArray(\n                    field=FieldName.FEAT_STATIC_CAT,\n                    expected_ndim=1,\n                    dtype=int,\n                )\n            ]\n            if config.num_static_categorical_features > 0\n            else []\n        )\n        + (\n            [\n                AsNumpyArray(\n                    field=FieldName.FEAT_STATIC_REAL,\n                    expected_ndim=1,\n                )\n            ]\n            if config.num_static_real_features > 0\n            else []\n        )\n        + [\n            AsNumpyArray(\n                field=FieldName.TARGET,\n                # we expect an extra dim for the multivariate case:\n                expected_ndim=1 if config.input_size == 1 else 2,\n            ),'
 list([{'entity_group': 'ORG', 'score': 0.6652652, 'word': '##A', 'start': 251, 'end': 252}, {'entity_group': 'ORG', 'score': 0.6822674, 'word': '##A', 'start': 548, 'end': 549}, {'entity_group': 'ORG', 'score': 0.7644295, 'word': '##A', 'start': 790, 'end': 791}])
 list([])]
['768' '67.0' '35'
 "expected_ndim=1 if config.input_size == 1 else 2,\n            ),\n            # step 3: handle the NaN's by filling in the target with zero\n            # and return the mask (which is in the observed values)\n            # true for observed values, false for nan's\n            # the decoder uses this mask (no loss is incurred for unobserved values)\n            # see loss_weights inside the xxxForPrediction model\n            AddObservedValuesIndicator(\n                target_field=FieldName.TARGET,\n                output_field=FieldName.OBSERVED_VALUES,\n            ),\n            # step 4: add temporal features based on freq of the dataset\n            # these serve as positional encodings\n            AddTimeFeatures(\n                start_field=FieldName.START,\n                target_field=FieldName.TARGET,\n                output_field=FieldName.FEAT_TIME,\n                time_features=time_features_from_frequency_str(freq),"
 list([]) list([])]
['769' '67.0' '36'
 'time_features=time_features_from_frequency_str(freq),\n                pred_length=config.prediction_length,\n            ),\n            # step 5: add another temporal feature (just a single number)\n            # tells the model where in the life the value of the time series is\n            # sort of running counter\n            AddAgeFeature(\n                target_field=FieldName.TARGET,\n                output_field=FieldName.FEAT_AGE,\n                pred_length=config.prediction_length,\n                log_scale=True,\n            ),\n            # step 6: vertically stack all the temporal features into the key FEAT_TIME\n            VstackFeatures(\n                output_field=FieldName.FEAT_TIME,\n                input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n                + (\n                    [FieldName.FEAT_DYNAMIC_REAL]\n                    if config.num_dynamic_real_features > 0\n                    else []\n                ),\n            ),'
 list([]) list([])]
['770' '67.0' '37'
 'else []\n                ),\n            ),\n            # step 7: rename to match HuggingFace names\n            RenameFields(\n                mapping={\n                    FieldName.FEAT_STATIC_CAT: "static_categorical_features",\n                    FieldName.FEAT_STATIC_REAL: "static_real_features",\n                    FieldName.FEAT_TIME: "time_features",\n                    FieldName.TARGET: "values",\n                    FieldName.OBSERVED_VALUES: "observed_mask",\n                }\n            ),\n        ]\n    )'
 list([{'entity_group': 'MISC', 'score': 0.54148704, 'word': 'Hu', 'start': 80, 'end': 82}])
 list([])]
['771' '67.0' '38'
 '```\n\n## Define `InstanceSplitter`\n\nFor training/validation/testing we next create an `InstanceSplitter` which is used to sample windows from the dataset (as, remember, we can\'t pass the entire history of values to the model due to time- and memory constraints).\n\nThe instance splitter samples random `context_length` sized and subsequent `prediction_length` sized windows from the data, and appends a `past_` or `future_` key to any temporal keys in `time_series_fields` for the respective windows. The instance splitter can be configured into three different modes:\n1. `mode="train"`: Here we sample the context and prediction length windows randomly from the dataset given to it (the training dataset)\n2. `mode="validation"`: Here we sample the very last context length window and prediction window from the dataset given to it (for the back-testing or validation likelihood calculations)\n3. `mode="test"`: Here we sample the very last context length window only (for the prediction use case)'
 list([{'entity_group': 'MISC', 'score': 0.78275234, 'word': 'In', 'start': 86, 'end': 88}])
 list([])]
['772' '67.0' '39'
 '```python\nfrom gluonts.transform.sampler import InstanceSampler\nfrom typing import Optional\n\n\ndef create_instance_splitter(\n    config: PretrainedConfig,\n    mode: str,\n    train_sampler: Optional[InstanceSampler] = None,\n    validation_sampler: Optional[InstanceSampler] = None,\n) -> Transformation:\n    assert mode in ["train", "validation", "test"]\n\n    instance_sampler = {\n        "train": train_sampler\n        or ExpectedNumInstanceSampler(\n            num_instances=1.0, min_future=config.prediction_length\n        ),\n        "validation": validation_sampler\n        or ValidationSplitSampler(min_future=config.prediction_length),\n        "test": TestSplitSampler(),\n    }[mode]'
 list([]) list([])]
['773' '67.0' '40'
 'return InstanceSplitter(\n        target_field="values",\n        is_pad_field=FieldName.IS_PAD,\n        start_field=FieldName.START,\n        forecast_start_field=FieldName.FORECAST_START,\n        instance_sampler=instance_sampler,\n        past_length=config.context_length + max(config.lags_sequence),\n        future_length=config.prediction_length,\n        time_series_fields=["time_features", "observed_mask"],\n    )'
 list([]) list([])]
['774' '67.0' '41'
 '```\n\n## Create DataLoaders\n\nNext, it\'s time to create the DataLoaders, which allow us to have batches of (input, output) pairs - or in other words (`past_values`, `future_values`).\n\n\n```python\nfrom typing import Iterable\n\nimport torch\nfrom gluonts.itertools import Cached, Cyclic\nfrom gluonts.dataset.loader import as_stacked_batches\n\n\ndef create_train_dataloader(\n    config: PretrainedConfig,\n    freq,\n    data,\n    batch_size: int,\n    num_batches_per_epoch: int,\n    shuffle_buffer_length: Optional[int] = None,\n    cache_data: bool = True,\n    **kwargs,\n) -> Iterable:\n    PREDICTION_INPUT_NAMES = [\n        "past_time_features",\n        "past_values",\n        "past_observed_mask",\n        "future_time_features",\n    ]\n    if config.num_static_categorical_features > 0:\n        PREDICTION_INPUT_NAMES.append("static_categorical_features")\n\n    if config.num_static_real_features > 0:\n        PREDICTION_INPUT_NAMES.append("static_real_features")'
 list([]) list([])]
['775' '67.0' '42'
 'TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [\n        "future_values",\n        "future_observed_mask",\n    ]\n\n    transformation = create_transformation(freq, config)\n    transformed_data = transformation.apply(data, is_train=True)\n    if cache_data:\n        transformed_data = Cached(transformed_data)\n\n    # we initialize a Training instance\n    instance_splitter = create_instance_splitter(config, "train")'
 list([]) list([])]
['776' '67.0' '43'
 '# the instance splitter will sample a window of\n    # context length + lags + prediction length (from all the possible transformed time series, 1 in our case)\n    # randomly from within the target time series and return an iterator.\n    stream = Cyclic(transformed_data).stream()\n    training_instances = instance_splitter.apply(stream)\n    \n    return as_stacked_batches(\n        training_instances,\n        batch_size=batch_size,\n        shuffle_buffer_length=shuffle_buffer_length,\n        field_names=TRAINING_INPUT_NAMES,\n        output_type=torch.tensor,\n        num_batches_per_epoch=num_batches_per_epoch,\n    )'
 list([]) list([])]
['777' '67.0' '44'
 '```\n\n\n```python\ndef create_backtest_dataloader(\n    config: PretrainedConfig,\n    freq,\n    data,\n    batch_size: int,\n    **kwargs,\n):\n    PREDICTION_INPUT_NAMES = [\n        "past_time_features",\n        "past_values",\n        "past_observed_mask",\n        "future_time_features",\n    ]\n    if config.num_static_categorical_features > 0:\n        PREDICTION_INPUT_NAMES.append("static_categorical_features")\n\n    if config.num_static_real_features > 0:\n        PREDICTION_INPUT_NAMES.append("static_real_features")\n\n    transformation = create_transformation(freq, config)\n    transformed_data = transformation.apply(data)\n\n    # we create a Validation Instance splitter which will sample the very last\n    # context window seen during training only for the encoder.\n    instance_sampler = create_instance_splitter(config, "validation")'
 list([]) list([])]
['778' '67.0' '45'
 '# we apply the transformations in train mode\n    testing_instances = instance_sampler.apply(transformed_data, is_train=True)\n    \n    return as_stacked_batches(\n        testing_instances,\n        batch_size=batch_size,\n        output_type=torch.tensor,\n        field_names=PREDICTION_INPUT_NAMES,\n    )\n\ndef create_test_dataloader(\n    config: PretrainedConfig,\n    freq,\n    data,\n    batch_size: int,\n    **kwargs,\n):\n    PREDICTION_INPUT_NAMES = [\n        "past_time_features",\n        "past_values",\n        "past_observed_mask",\n        "future_time_features",\n    ]\n    if config.num_static_categorical_features > 0:\n        PREDICTION_INPUT_NAMES.append("static_categorical_features")\n\n    if config.num_static_real_features > 0:\n        PREDICTION_INPUT_NAMES.append("static_real_features")\n\n    transformation = create_transformation(freq, config)\n    transformed_data = transformation.apply(data, is_train=False)'
 list([]) list([])]
['779' '67.0' '46'
 '# We create a test Instance splitter to sample the very last\n    # context window from the dataset provided.\n    instance_sampler = create_instance_splitter(config, "test")\n\n    # We apply the transformations in test mode\n    testing_instances = instance_sampler.apply(transformed_data, is_train=False)\n    \n    return as_stacked_batches(\n        testing_instances,\n        batch_size=batch_size,\n        output_type=torch.tensor,\n        field_names=PREDICTION_INPUT_NAMES,\n    )'
 list([]) list([])]
['780' '67.0' '47'
 "```\n\n\n```python\ntrain_dataloader = create_train_dataloader(\n    config=config,\n    freq=freq,\n    data=multi_variate_train_dataset,\n    batch_size=256,\n    num_batches_per_epoch=100,\n    num_workers=2,\n)\n\ntest_dataloader = create_backtest_dataloader(\n    config=config,\n    freq=freq,\n    data=multi_variate_test_dataset,\n    batch_size=32,\n)\n```\n\nLet's check the first batch:\n\n\n```python\nbatch = next(iter(train_dataloader))\nfor k, v in batch.items():\n    print(k, v.shape, v.type())\n\n>>> past_time_features torch.Size([256, 264, 5]) torch.FloatTensor\n    past_values torch.Size([256, 264, 862]) torch.FloatTensor\n    past_observed_mask torch.Size([256, 264, 862]) torch.FloatTensor\n    future_time_features torch.Size([256, 48, 5]) torch.FloatTensor\n    future_values torch.Size([256, 48, 862]) torch.FloatTensor\n    future_observed_mask torch.Size([256, 48, 862]) torch.FloatTensor"
 list([{'entity_group': 'ORG', 'score': 0.94529134, 'word': 'F', 'start': 541, 'end': 542}, {'entity_group': 'ORG', 'score': 0.7888219, 'word': '##Tensor', 'start': 546, 'end': 552}, {'entity_group': 'ORG', 'score': 0.934982, 'word': 'F', 'start': 603, 'end': 604}, {'entity_group': 'ORG', 'score': 0.8194947, 'word': '##Tensor', 'start': 608, 'end': 614}, {'entity_group': 'ORG', 'score': 0.93583137, 'word': 'F', 'start': 672, 'end': 673}, {'entity_group': 'ORG', 'score': 0.8493169, 'word': '##Tensor', 'start': 677, 'end': 683}, {'entity_group': 'ORG', 'score': 0.93050927, 'word': 'F', 'start': 740, 'end': 741}, {'entity_group': 'ORG', 'score': 0.7761552, 'word': '##Tensor', 'start': 745, 'end': 751}, {'entity_group': 'ORG', 'score': 0.91592896, 'word': 'F', 'start': 803, 'end': 804}, {'entity_group': 'ORG', 'score': 0.6968333, 'word': '##Tensor', 'start': 808, 'end': 814}, {'entity_group': 'ORG', 'score': 0.93139416, 'word': 'F', 'start': 873, 'end': 874}, {'entity_group': 'ORG', 'score': 0.74113756, 'word': '##Tensor', 'start': 878, 'end': 884}])
 list([{'entity_group': 'ORG', 'score': 0.94529134, 'word': 'F', 'start': 541, 'end': 542}, {'entity_group': 'ORG', 'score': 0.934982, 'word': 'F', 'start': 603, 'end': 604}, {'entity_group': 'ORG', 'score': 0.8194947, 'word': '##Tensor', 'start': 608, 'end': 614}, {'entity_group': 'ORG', 'score': 0.93583137, 'word': 'F', 'start': 672, 'end': 673}, {'entity_group': 'ORG', 'score': 0.8493169, 'word': '##Tensor', 'start': 677, 'end': 683}, {'entity_group': 'ORG', 'score': 0.93050927, 'word': 'F', 'start': 740, 'end': 741}, {'entity_group': 'ORG', 'score': 0.91592896, 'word': 'F', 'start': 803, 'end': 804}, {'entity_group': 'ORG', 'score': 0.93139416, 'word': 'F', 'start': 873, 'end': 874}])]
['781' '67.0' '48'
 "```\n\nAs can be seen, we don't feed `input_ids` and `attention_mask` to the encoder (as would be the case for NLP models), but rather `past_values`, along with `past_observed_mask`, `past_time_features` and `static_real_features`.\n\nThe decoder inputs consist of `future_values`, `future_observed_mask` and `future_time_features`. The `future_values` can be seen as the equivalent of `decoder_input_ids` in NLP.\n\nWe refer to the [docs](https://huggingface.co/docs/transformers/main/en/model_doc/informer#transformers.InformerModel.forward.past_values) for a detailed explanation for each of them.\n\n## Forward Pass\n\nLet's perform a single forward pass with the batch we just created:"
 list([{'entity_group': 'MISC', 'score': 0.9845047, 'word': 'NL', 'start': 109, 'end': 111}, {'entity_group': 'MISC', 'score': 0.9449309, 'word': 'NL', 'start': 405, 'end': 407}, {'entity_group': 'ORG', 'score': 0.5246334, 'word': '##ode', 'start': 524, 'end': 527}])
 list([{'entity_group': 'MISC', 'score': 0.9845047, 'word': 'NL', 'start': 109, 'end': 111}, {'entity_group': 'MISC', 'score': 0.9449309, 'word': 'NL', 'start': 405, 'end': 407}])]
['782' '67.0' '49'
 '## Forward Pass\n\nLet\'s perform a single forward pass with the batch we just created:\n\n\n```python\n# perform forward pass\noutputs = model(\n    past_values=batch["past_values"],\n    past_time_features=batch["past_time_features"],\n    past_observed_mask=batch["past_observed_mask"],\n    static_categorical_features=batch["static_categorical_features"]\n    if config.num_static_categorical_features > 0\n    else None,\n    static_real_features=batch["static_real_features"]\n    if config.num_static_real_features > 0\n    else None,\n    future_values=batch["future_values"],\n    future_time_features=batch["future_time_features"],\n    future_observed_mask=batch["future_observed_mask"],\n    output_hidden_states=True,\n)'
 list([]) list([])]
['783' '67.0' '50'
 '```\n\n\n```python\nprint("Loss:", outputs.loss.item())\n\n>>> Loss: -1071.5718994140625'
 list([]) list([])]
['784' '67.0' '51'
 "```\n\nNote that the model is returning a loss. This is possible as the decoder automatically shifts the `future_values` one position to the right in order to have the labels. This allows computing a loss between the predicted values and the labels. The loss is the negative log-likelihood of the predicted distribution with respect to the ground truth values and tends to negative infinity.\n\nAlso note that the decoder uses a causal mask to not look into the future as the values it needs to predict are in the `future_values` tensor.\n\n## Train the Model\n\nIt's time to train the model! We'll use a standard PyTorch training loop.\n\nWe will use the 🤗 [Accelerate](https://huggingface.co/docs/accelerate/index) library here, which automatically places the model, optimizer and dataloader on the appropriate `device`.\n\n\n```python\nfrom accelerate import Accelerator\nfrom torch.optim import AdamW\n\nepochs = 25\nloss_history = []\n\naccelerator = Accelerator()\ndevice = accelerator.device"
 list([{'entity_group': 'ORG', 'score': 0.9261244, 'word': 'PyTorch', 'start': 606, 'end': 613}, {'entity_group': 'ORG', 'score': 0.49308908, 'word': 'Adam', 'start': 884, 'end': 888}])
 list([{'entity_group': 'ORG', 'score': 0.9261244, 'word': 'PyTorch', 'start': 606, 'end': 613}])]
['785' '67.0' '52'
 'epochs = 25\nloss_history = []\n\naccelerator = Accelerator()\ndevice = accelerator.device\n\nmodel.to(device)\noptimizer = AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)\n\nmodel, optimizer, train_dataloader = accelerator.prepare(\n    model,\n    optimizer,\n    train_dataloader,\n)'
 list([]) list([])]
['786' '67.0' '53'
 'model.train()\nfor epoch in range(epochs):\n    for idx, batch in enumerate(train_dataloader):\n        optimizer.zero_grad()\n        outputs = model(\n            static_categorical_features=batch["static_categorical_features"].to(device)\n            if config.num_static_categorical_features > 0\n            else None,\n            static_real_features=batch["static_real_features"].to(device)\n            if config.num_static_real_features > 0\n            else None,\n            past_time_features=batch["past_time_features"].to(device),\n            past_values=batch["past_values"].to(device),\n            future_time_features=batch["future_time_features"].to(device),\n            future_values=batch["future_values"].to(device),\n            past_observed_mask=batch["past_observed_mask"].to(device),\n            future_observed_mask=batch["future_observed_mask"].to(device),\n        )\n        loss = outputs.loss'
 list([]) list([])]
['787' '67.0' '54'
 '# Backpropagation\n        accelerator.backward(loss)\n        optimizer.step()\n\n        loss_history.append(loss.item())\n        if idx % 100 == 0:\n            print(loss.item())\n\n>>> -1081.978515625\n    ...\n    -2877.723876953125'
 list([]) list([])]
['788' '67.0' '55'
 '```\n\n```python\n# view training\nloss_history = np.array(loss_history).reshape(-1)\nx = range(loss_history.shape[0])\nplt.figure(figsize=(10, 5))\nplt.plot(x, loss_history, label="train")\nplt.title("Loss", fontsize=15)\nplt.legend(loc="upper right")\nplt.xlabel("iteration")\nplt.ylabel("nll")\nplt.show()'
 list([]) list([])]
['789' '67.0' '56'
 "```\n\n![png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/output_62_0.png)\n    \n\n## Inference\n\nAt inference time, it's recommended to use the `generate()` method for autoregressive generation, similar to NLP models.\n\nForecasting involves getting data from the test instance sampler, which will sample the very last `context_length` sized window of values from each time series in the dataset, and pass it to the model. Note that we pass `future_time_features`, which are known ahead of time, to the decoder.\n\nThe model will autoregressively sample a certain number of values from the predicted distribution and pass them back to the decoder to return the prediction outputs:\n\n\n```python\nmodel.eval()\n\nforecasts_ = []"
 list([{'entity_group': 'MISC', 'score': 0.7242949, 'word': 'NLP', 'start': 250, 'end': 253}])
 list([])]
['790' '67.0' '57'
 '```python\nmodel.eval()\n\nforecasts_ = []\n\nfor batch in test_dataloader:\n    outputs = model.generate(\n        static_categorical_features=batch["static_categorical_features"].to(device)\n        if config.num_static_categorical_features > 0\n        else None,\n        static_real_features=batch["static_real_features"].to(device)\n        if config.num_static_real_features > 0\n        else None,\n        past_time_features=batch["past_time_features"].to(device),\n        past_values=batch["past_values"].to(device),\n        future_time_features=batch["future_time_features"].to(device),\n        past_observed_mask=batch["past_observed_mask"].to(device),\n    )\n    forecasts_.append(outputs.sequences.cpu().numpy())'
 list([]) list([])]
['791' '67.0' '58'
 "```\n\nThe model outputs a tensor of shape (`batch_size`, `number of samples`, `prediction length`, `input_size`). \n\nIn this case, we get `100` possible values for the next `48` hours for each of the `862` time series (for each example in the batch which is of size `1` since we only have a single multivariate time series):\n\n\n```python\nforecasts_[0].shape\n\n>>> (1, 100, 48, 862)\n```\n\nWe'll stack them vertically, to get forecasts for all time-series in the test dataset (just in case there are more time series in the test set):\n\n\n```python\nforecasts = np.vstack(forecasts_)\nprint(forecasts.shape)\n\n>>> (1, 100, 48, 862)"
 list([]) list([])]
['792' '67.0' '59'
 '```\n\nWe can evaluate the resulting forecast with respect to the ground truth out of sample values present in the test set. For that, we\'ll use the 🤗 [Evaluate](https://huggingface.co/docs/evaluate/index) library, which includes the [MASE](https://huggingface.co/spaces/evaluate-metric/mase) and [sMAPE](https://huggingface.co/spaces/evaluate-metric/smape) metrics.\n\nWe calculate both metrics for each time series variate in the dataset:\n\n\n```python\nfrom evaluate import load\nfrom gluonts.time_feature import get_seasonality\n\nmase_metric = load("evaluate-metric/mase")\nsmape_metric = load("evaluate-metric/smape")\n\nforecast_median = np.median(forecasts, 1).squeeze(0).T\n\nmase_metrics = []\nsmape_metrics = []'
 list([{'entity_group': 'MISC', 'score': 0.4451054, 'word': '🤗', 'start': 147, 'end': 148}])
 list([])]
['793' '67.0' '60'
 'forecast_median = np.median(forecasts, 1).squeeze(0).T\n\nmase_metrics = []\nsmape_metrics = []\n\nfor item_id, ts in enumerate(test_dataset):\n    training_data = ts["target"][:-prediction_length]\n    ground_truth = ts["target"][-prediction_length:]\n    mase = mase_metric.compute(\n        predictions=forecast_median[item_id],\n        references=np.array(ground_truth),\n        training=np.array(training_data),\n        periodicity=get_seasonality(freq),\n    )\n    mase_metrics.append(mase["mase"])\n\n    smape = smape_metric.compute(\n        predictions=forecast_median[item_id],\n        references=np.array(ground_truth),\n    )\n    smape_metrics.append(smape["smape"])'
 list([]) list([])]
['794' '67.0' '61'
 '```\n\n\n```python\nprint(f"MASE: {np.mean(mase_metrics)}")\n\n>>> MASE: 1.1913437728068093\n\nprint(f"sMAPE: {np.mean(smape_metrics)}")\n\n>>> sMAPE: 0.5322665081607634\n```\n\n\n```python\nplt.scatter(mase_metrics, smape_metrics, alpha=0.2)\nplt.xlabel("MASE")\nplt.ylabel("sMAPE")\nplt.show()'
 list([]) list([])]
['795' '67.0' '62'
 '```\n\n![png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/output_73_0.png)\n    \nTo plot the prediction for any time series variate with respect the ground truth test data we define the following helper:\n\n\n```python\nimport matplotlib.dates as mdates\n\n\ndef plot(ts_index, mv_index):\n    fig, ax = plt.subplots()\n\n    index = pd.period_range(\n        start=multi_variate_test_dataset[ts_index][FieldName.START],\n        periods=len(multi_variate_test_dataset[ts_index][FieldName.TARGET]),\n        freq=multi_variate_test_dataset[ts_index][FieldName.START].freq,\n    ).to_timestamp()\n\n    ax.xaxis.set_minor_locator(mdates.HourLocator())\n\n    ax.plot(\n        index[-2 * prediction_length :],\n        multi_variate_test_dataset[ts_index]["target"][mv_index, -2 * prediction_length :],\n        label="actual",\n    )'
 list([]) list([])]
['796' '67.0' '63'
 'ax.plot(\n        index[-prediction_length:],\n        forecasts[ts_index, ..., mv_index].mean(axis=0),\n        label="mean",\n    )\n    ax.fill_between(\n        index[-prediction_length:],\n        forecasts[ts_index, ..., mv_index].mean(0)\n        - forecasts[ts_index, ..., mv_index].std(axis=0),\n        forecasts[ts_index, ..., mv_index].mean(0)\n        + forecasts[ts_index, ..., mv_index].std(axis=0),\n        alpha=0.2,\n        interpolate=True,\n        label="+/- 1-std",\n    )\n    ax.legend()\n    fig.autofmt_xdate()'
 list([]) list([])]
['797' '67.0' '64' '```\n\nFor example:\n\n\n```python\nplot(0, 344)'
 list([]) list([])]
['798' '67.0' '65'
 '```\n\n![png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/output_77_0.png)\n    \n\n## Conclusion\n\nHow do we compare against other models? The [Monash Time Series Repository](https://forecastingdata.org/#results) has a comparison table of test set MASE metrics which we can add to:\n\n|Dataset | \tSES| \tTheta | \tTBATS| \tETS\t| (DHR-)ARIMA| \tPR|\tCatBoost |\tFFNN\t| DeepAR | \tN-BEATS | \tWaveNet|  Transformer (uni.) | **Informer (mv. our)**| \n|:------------------:|:-----------------:|:--:|:--:|:--:|:--:|:--:|:--:|:---:|:---:|:--:|:--:|:--:|:--:|\n|Traffic Hourly | 1.922\t| 1.922\t| 2.482 |\t2.294|\t2.535|\t1.281|\t1.571\t|0.892|\t0.825\t|1.100|\t1.066\t| **0.821** | 1.191 |'
 list([{'entity_group': 'ORG', 'score': 0.96660876, 'word': 'Monash Time Series Repository', 'start': 187, 'end': 216}, {'entity_group': 'ORG', 'score': 0.6141875, 'word': '##data', 'start': 237, 'end': 241}, {'entity_group': 'ORG', 'score': 0.8487821, 'word': 'ARIMA', 'start': 373, 'end': 378}, {'entity_group': 'ORG', 'score': 0.83203083, 'word': 'Cat', 'start': 385, 'end': 388}, {'entity_group': 'ORG', 'score': 0.91198003, 'word': 'DeepAR', 'start': 403, 'end': 409}, {'entity_group': 'ORG', 'score': 0.962098, 'word': 'WaveNet', 'start': 424, 'end': 431}])
 list([{'entity_group': 'ORG', 'score': 0.96660876, 'word': 'Monash Time Series Repository', 'start': 187, 'end': 216}, {'entity_group': 'ORG', 'score': 0.8487821, 'word': 'ARIMA', 'start': 373, 'end': 378}, {'entity_group': 'ORG', 'score': 0.83203083, 'word': 'Cat', 'start': 385, 'end': 388}, {'entity_group': 'ORG', 'score': 0.91198003, 'word': 'DeepAR', 'start': 403, 'end': 409}, {'entity_group': 'ORG', 'score': 0.962098, 'word': 'WaveNet', 'start': 424, 'end': 431}])]
['799' '67.0' '66'
 'As can be seen, and perhaps surprising to some, the multivariate forecasts are typically _worse_ than the univariate ones, the reason being the difficulty in estimating the cross-series correlations/relationships. The additional variance added by the estimates often harms the resulting forecasts or the model learns spurious correlations. We refer to [this paper](https://openreview.net/forum?id=GpW327gxLTF) for further reading. Multivariate models tend to work well when trained on a lot of data.\n\nSo the vanilla Transformer still performs best here! In the future, we hope to better benchmark these models in a central place to ease reproducing the results of several papers. Stay tuned for more!\n\n## Resources\n\nWe recommend to check out the [Informer docs](https://huggingface.co/docs/transformers/main/en/model_doc/informer) and the [example notebook](https://github.com/huggingface/notebooks/blob/main/examples/multivariate_informer.ipynb) linked at the top of this blog post.'
 list([{'entity_group': 'MISC', 'score': 0.76244277, 'word': 'Transformer', 'start': 516, 'end': 527}])
 list([])]
['800' '68.0' '0'
 'SE-ResNet\n\n**SE ResNet** is a variant of a [ResNet](https://www.paperswithcode.com/method/resnet) that employs [squeeze-and-excitation blocks](https://paperswithcode.com/method/squeeze-and-excitation-block) to enable the network to perform dynamic channel-wise feature recalibration.\n\n## How do I use this model on an image?\nTo load a pretrained model:\n\n```python\nimport timm\nmodel = timm.create_model(\'seresnet152d\', pretrained=True)\nmodel.eval()\n```\n\nTo load and preprocess the image:\n```python \nimport urllib\nfrom PIL import Image\nfrom timm.data import resolve_data_config\nfrom timm.data.transforms_factory import create_transform\n\nconfig = resolve_data_config({}, model=model)\ntransform = create_transform(**config)\n\nurl, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")\nurllib.request.urlretrieve(url, filename)\nimg = Image.open(filename).convert(\'RGB\')\ntensor = transform(img).unsqueeze(0) # transform and add batch dimension'
 list([{'entity_group': 'ORG', 'score': 0.67936337, 'word': 'SE', 'start': 0, 'end': 2}, {'entity_group': 'ORG', 'score': 0.9179382, 'word': 'ResNet', 'start': 3, 'end': 9}, {'entity_group': 'ORG', 'score': 0.8738982, 'word': 'ResNet', 'start': 16, 'end': 22}, {'entity_group': 'ORG', 'score': 0.79713005, 'word': 'ResNet', 'start': 44, 'end': 50}, {'entity_group': 'ORG', 'score': 0.9631733, 'word': 'PIL', 'start': 517, 'end': 520}])
 list([{'entity_group': 'ORG', 'score': 0.9179382, 'word': 'ResNet', 'start': 3, 'end': 9}, {'entity_group': 'ORG', 'score': 0.8738982, 'word': 'ResNet', 'start': 16, 'end': 22}, {'entity_group': 'ORG', 'score': 0.9631733, 'word': 'PIL', 'start': 517, 'end': 520}])]
['801' '68.0' '1'
 '```\n\nTo get the model predictions:\n```python\nimport torch\nwith torch.no_grad():\n    out = model(tensor)\nprobabilities = torch.nn.functional.softmax(out[0], dim=0)\nprint(probabilities.shape)\n# prints: torch.Size([1000])\n```\n\nTo get the top-5 predictions class names:\n```python\n# Get imagenet class mappings\nurl, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")\nurllib.request.urlretrieve(url, filename) \nwith open("imagenet_classes.txt", "r") as f:\n    categories = [s.strip() for s in f.readlines()]\n\n# Print top categories per image\ntop5_prob, top5_catid = torch.topk(probabilities, 5)\nfor i in range(top5_prob.size(0)):\n    print(categories[top5_catid[i]], top5_prob[i].item())\n# prints class names and probabilities like:\n# [(\'Samoyed\', 0.6425196528434753), (\'Pomeranian\', 0.04062102362513542), (\'keeshond\', 0.03186424449086189), (\'white wolf\', 0.01739676296710968), (\'Eskimo dog\', 0.011717947199940681)]'
 list([{'entity_group': 'MISC', 'score': 0.7729581, 'word': 'Sam', 'start': 794, 'end': 797}, {'entity_group': 'MISC', 'score': 0.96149033, 'word': 'Pomeranian', 'start': 827, 'end': 837}])
 list([{'entity_group': 'MISC', 'score': 0.96149033, 'word': 'Pomeranian', 'start': 827, 'end': 837}])]
['802' '68.0' '2'
 "```\n\nReplace the model name with the variant you want to use, e.g. `seresnet152d`. You can find the IDs in the model summaries at the top of this page.\n\nTo extract image features with this model, follow the [timm feature extraction examples](https://rwightman.github.io/pytorch-image-models/feature_extraction/), just change the name of the model you want to use.\n\n## How do I finetune this model?\nYou can finetune any of the pre-trained models just by changing the classifier (the last layer).\n```python\nmodel = timm.create_model('seresnet152d', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)"
 list([]) list([])]
['803' '68.0' '3'
 "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscript](https://github.com/rwightman/pytorch-image-models/blob/master/train.py) to use your dataset.\n\n## How do I train this model?\n\nYou can follow the [timm recipe scripts](https://rwightman.github.io/pytorch-image-models/scripts/) for training a new model afresh.\n\n## Citation\n\n```BibTeX\n@misc{hu2019squeezeandexcitation,\n      title={Squeeze-and-Excitation Networks}, \n      author={Jie Hu and Li Shen and Samuel Albanie and Gang Sun and Enhua Wu},\n      year={2019},\n      eprint={1709.01507},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}"
 list([{'entity_group': 'ORG', 'score': 0.62729836, 'word': 'S', 'start': 434, 'end': 435}, {'entity_group': 'ORG', 'score': 0.7227711, 'word': 'and', 'start': 442, 'end': 445}, {'entity_group': 'ORG', 'score': 0.7903504, 'word': 'Ex', 'start': 446, 'end': 448}, {'entity_group': 'ORG', 'score': 0.8038436, 'word': 'Networks', 'start': 457, 'end': 465}, {'entity_group': 'PER', 'score': 0.9969161, 'word': 'Jie Hu', 'start': 483, 'end': 489}, {'entity_group': 'PER', 'score': 0.9935948, 'word': 'Li Shen', 'start': 494, 'end': 501}, {'entity_group': 'PER', 'score': 0.9985771, 'word': 'Samuel Albanie', 'start': 506, 'end': 520}, {'entity_group': 'PER', 'score': 0.99488723, 'word': 'Gang Sun', 'start': 525, 'end': 533}, {'entity_group': 'PER', 'score': 0.9978757, 'word': 'Enhua Wu', 'start': 538, 'end': 546}])
 list([{'entity_group': 'ORG', 'score': 0.8038436, 'word': 'Networks', 'start': 457, 'end': 465}, {'entity_group': 'PER', 'score': 0.9969161, 'word': 'Jie Hu', 'start': 483, 'end': 489}, {'entity_group': 'PER', 'score': 0.9935948, 'word': 'Li Shen', 'start': 494, 'end': 501}, {'entity_group': 'PER', 'score': 0.9985771, 'word': 'Samuel Albanie', 'start': 506, 'end': 520}, {'entity_group': 'PER', 'score': 0.99488723, 'word': 'Gang Sun', 'start': 525, 'end': 533}, {'entity_group': 'PER', 'score': 0.9978757, 'word': 'Enhua Wu', 'start': 538, 'end': 546}])]
['804' '68.0' '4' '```'
 list([{'entity_group': 'PER', 'score': 0.4322449, 'word': '`', 'start': 0, 'end': 1}, {'entity_group': 'PER', 'score': 0.43227673, 'word': '`', 'start': 1, 'end': 2}, {'entity_group': 'PER', 'score': 0.43234685, 'word': '`', 'start': 2, 'end': 3}])
 list([])]
['805' '68.0' '5'
 "<!--\nType: model-index\nCollections:\n- Name: SE ResNet\n  Paper:\n    Title: Squeeze-and-Excitation Networks\n    URL: https://paperswithcode.com/paper/squeeze-and-excitation-networks\nModels:\n- Name: seresnet152d\n  In Collection: SE ResNet\n  Metadata:\n    FLOPs: 20161904304\n    Parameters: 66840000\n    File Size: 268144497\n    Architecture:\n    - 1x1 Convolution\n    - Batch Normalization\n    - Bottleneck Residual Block\n    - Convolution\n    - Global Average Pooling\n    - Max Pooling\n    - ReLU\n    - Residual Block\n    - Residual Connection\n    - Softmax\n    - Squeeze-and-Excitation Block\n    Tasks:\n    - Image Classification\n    Training Techniques:\n    - Label Smoothing\n    - SGD with Momentum\n    - Weight Decay\n    Training Data:\n    - ImageNet\n    Training Resources: 8x NVIDIA Titan X GPUs\n    ID: seresnet152d\n    LR: 0.6\n    Epochs: 100\n    Layers: 152\n    Dropout: 0.2\n    Crop Pct: '0.94'\n    Momentum: 0.9\n    Batch Size: 1024\n    Image Size: '256'\n    Interpolation: bicubic"
 list([{'entity_group': 'ORG', 'score': 0.95589167, 'word': 'SE ResNet', 'start': 44, 'end': 53}, {'entity_group': 'MISC', 'score': 0.5557758, 'word': 'S', 'start': 74, 'end': 75}, {'entity_group': 'MISC', 'score': 0.56342185, 'word': 'Ex', 'start': 86, 'end': 88}, {'entity_group': 'ORG', 'score': 0.9769513, 'word': 'SE ResNet', 'start': 226, 'end': 235}, {'entity_group': 'ORG', 'score': 0.8746778, 'word': 'ImageNet', 'start': 744, 'end': 752}, {'entity_group': 'MISC', 'score': 0.92138785, 'word': 'NVIDIA Titan X', 'start': 780, 'end': 794}])
 list([{'entity_group': 'ORG', 'score': 0.95589167, 'word': 'SE ResNet', 'start': 44, 'end': 53}, {'entity_group': 'ORG', 'score': 0.9769513, 'word': 'SE ResNet', 'start': 226, 'end': 235}, {'entity_group': 'ORG', 'score': 0.8746778, 'word': 'ImageNet', 'start': 744, 'end': 752}, {'entity_group': 'MISC', 'score': 0.92138785, 'word': 'NVIDIA Titan X', 'start': 780, 'end': 794}])]
['806' '68.0' '6'
 "Momentum: 0.9\n    Batch Size: 1024\n    Image Size: '256'\n    Interpolation: bicubic\n  Code: https://github.com/rwightman/pytorch-image-models/blob/a7f95818e44b281137503bcf4b3e3e94d8ffa52f/timm/models/resnet.py#L1206\n  Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet152d_ra2-04464dd2.pth\n  Results:\n  - Task: Image Classification\n    Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 83.74%\n      Top 5 Accuracy: 96.77%\n- Name: seresnet50\n  In Collection: SE ResNet\n  Metadata:\n    FLOPs: 5285062320\n    Parameters: 28090000\n    File Size: 112621903\n    Architecture:\n    - 1x1 Convolution\n    - Batch Normalization\n    - Bottleneck Residual Block\n    - Convolution\n    - Global Average Pooling\n    - Max Pooling\n    - ReLU\n    - Residual Block\n    - Residual Connection\n    - Softmax\n    - Squeeze-and-Excitation Block\n    Tasks:\n    - Image Classification\n    Training Techniques:\n    - Label Smoothing\n    - SGD with Momentum"
 list([{'entity_group': 'ORG', 'score': 0.537544, 'word': 'gith', 'start': 100, 'end': 104}, {'entity_group': 'ORG', 'score': 0.62534255, 'word': 'ImageNet', 'start': 393, 'end': 401}, {'entity_group': 'ORG', 'score': 0.8713912, 'word': 'SE ResNet', 'start': 509, 'end': 518}, {'entity_group': 'ORG', 'score': 0.6778511, 'word': 'S', 'start': 964, 'end': 965}])
 list([{'entity_group': 'ORG', 'score': 0.8713912, 'word': 'SE ResNet', 'start': 509, 'end': 518}])]
['807' '68.0' '7'
 "- Image Classification\n    Training Techniques:\n    - Label Smoothing\n    - SGD with Momentum\n    - Weight Decay\n    Training Data:\n    - ImageNet\n    Training Resources: 8x NVIDIA Titan X GPUs\n    ID: seresnet50\n    LR: 0.6\n    Epochs: 100\n    Layers: 50\n    Dropout: 0.2\n    Crop Pct: '0.875'\n    Momentum: 0.9\n    Batch Size: 1024\n    Image Size: '224'\n    Interpolation: bicubic\n  Code: https://github.com/rwightman/pytorch-image-models/blob/a7f95818e44b281137503bcf4b3e3e94d8ffa52f/timm/models/resnet.py#L1180\n  Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet50_ra_224-8efdb4bb.pth\n  Results:\n  - Task: Image Classification\n    Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 80.26%\n      Top 5 Accuracy: 95.07%\n-->"
 list([{'entity_group': 'ORG', 'score': 0.8469714, 'word': 'S', 'start': 76, 'end': 77}, {'entity_group': 'ORG', 'score': 0.835671, 'word': 'ImageNet', 'start': 138, 'end': 146}, {'entity_group': 'MISC', 'score': 0.9551334, 'word': 'NVIDIA Titan X', 'start': 174, 'end': 188}, {'entity_group': 'ORG', 'score': 0.827464, 'word': 'ImageNet', 'start': 693, 'end': 701}])
 list([{'entity_group': 'ORG', 'score': 0.8469714, 'word': 'S', 'start': 76, 'end': 77}, {'entity_group': 'ORG', 'score': 0.835671, 'word': 'ImageNet', 'start': 138, 'end': 146}, {'entity_group': 'MISC', 'score': 0.9551334, 'word': 'NVIDIA Titan X', 'start': 174, 'end': 188}, {'entity_group': 'ORG', 'score': 0.827464, 'word': 'ImageNet', 'start': 693, 'end': 701}])]
['808' '69.0' '0'
 '!--Copyright 2023 The HuggingFace Team. All rights reserved.\nLicensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\nspecific language governing permissions and limitations under the License.\n-->\n\n# Kandinsky 2.2\n\nKandinsky 2.2 is created by [Arseniy Shakhmatov](https://github.com/cene555), [Anton Razzhigaev](https://github.com/razzant), [Aleksandr Nikolich](https://github.com/AlexWortega), [Vladimir Arkhipkin](https://github.com/oriBetelgeuse), [Igor Pavlov](https://github.com/boomb0om), [Andrey Kuznetsov](https://github.com/kuznetsoffandrey), and [Denis Dimitrov](https://github.com/denndimitrov).'
 list([{'entity_group': 'ORG', 'score': 0.9909798, 'word': 'HuggingFace Team', 'start': 22, 'end': 38}, {'entity_group': 'MISC', 'score': 0.9971028, 'word': 'Apache License', 'start': 80, 'end': 94}, {'entity_group': 'MISC', 'score': 0.7916298, 'word': '2', 'start': 104, 'end': 105}, {'entity_group': 'MISC', 'score': 0.65964997, 'word': '0', 'start': 106, 'end': 107}, {'entity_group': 'MISC', 'score': 0.994858, 'word': 'License', 'start': 114, 'end': 121}, {'entity_group': 'MISC', 'score': 0.992101, 'word': 'License', 'start': 181, 'end': 188}, {'entity_group': 'MISC', 'score': 0.9850839, 'word': 'License', 'start': 219, 'end': 226}, {'entity_group': 'ORG', 'score': 0.78684425, 'word': '##pache', 'start': 242, 'end': 247}, {'entity_group': 'MISC', 'score': 0.98390377, 'word': 'License', 'start': 363, 'end': 370}, {'entity_group': 'MISC', 'score': 0.99000084, 'word': 'License', 'start': 488, 'end': 495}, {'entity_group': 'MISC', 'score': 0.99139506, 'word': 'License', 'start': 570, 'end': 577}, {'entity_group': 'MISC', 'score': 0.9468919, 'word': 'Kandinsky 2', 'start': 586, 'end': 597}, {'entity_group': 'MISC', 'score': 0.965055, 'word': 'Kandinsky 2', 'start': 601, 'end': 612}, {'entity_group': 'MISC', 'score': 0.8804393, 'word': '2', 'start': 613, 'end': 614}, {'entity_group': 'PER', 'score': 0.9854495, 'word': 'Arseniy Shakhmatov', 'start': 630, 'end': 648}, {'entity_group': 'PER', 'score': 0.97920674, 'word': 'Anton Razzhigaev', 'start': 680, 'end': 696}, {'entity_group': 'PER', 'score': 0.9986136, 'word': 'Aleksandr Nikolich', 'start': 728, 'end': 746}, {'entity_group': 'ORG', 'score': 0.6257406, 'word': 'AlexWortega', 'start': 767, 'end': 778}, {'entity_group': 'PER', 'score': 0.99707186, 'word': 'Vladimir Arkhipkin', 'start': 782, 'end': 800}, {'entity_group': 'ORG', 'score': 0.586386, 'word': '##Betelgeuse', 'start': 824, 'end': 834}, {'entity_group': 'PER', 'score': 0.9975046, 'word': 'Igor Pavlov', 'start': 838, 'end': 849}, {'entity_group': 'PER', 'score': 0.9857013, 'word': 'Andrey Kuznetsov', 'start': 882, 'end': 898}, {'entity_group': 'PER', 'score': 0.9982041, 'word': 'Denis Dimitrov', 'start': 943, 'end': 957}, {'entity_group': 'PER', 'score': 0.5199748, 'word': '##ndi', 'start': 981, 'end': 984}])
 list([{'entity_group': 'ORG', 'score': 0.9909798, 'word': 'HuggingFace Team', 'start': 22, 'end': 38}, {'entity_group': 'MISC', 'score': 0.9971028, 'word': 'Apache License', 'start': 80, 'end': 94}, {'entity_group': 'MISC', 'score': 0.994858, 'word': 'License', 'start': 114, 'end': 121}, {'entity_group': 'MISC', 'score': 0.992101, 'word': 'License', 'start': 181, 'end': 188}, {'entity_group': 'MISC', 'score': 0.9850839, 'word': 'License', 'start': 219, 'end': 226}, {'entity_group': 'MISC', 'score': 0.98390377, 'word': 'License', 'start': 363, 'end': 370}, {'entity_group': 'MISC', 'score': 0.99000084, 'word': 'License', 'start': 488, 'end': 495}, {'entity_group': 'MISC', 'score': 0.99139506, 'word': 'License', 'start': 570, 'end': 577}, {'entity_group': 'MISC', 'score': 0.9468919, 'word': 'Kandinsky 2', 'start': 586, 'end': 597}, {'entity_group': 'MISC', 'score': 0.965055, 'word': 'Kandinsky 2', 'start': 601, 'end': 612}, {'entity_group': 'MISC', 'score': 0.8804393, 'word': '2', 'start': 613, 'end': 614}, {'entity_group': 'PER', 'score': 0.9854495, 'word': 'Arseniy Shakhmatov', 'start': 630, 'end': 648}, {'entity_group': 'PER', 'score': 0.97920674, 'word': 'Anton Razzhigaev', 'start': 680, 'end': 696}, {'entity_group': 'PER', 'score': 0.9986136, 'word': 'Aleksandr Nikolich', 'start': 728, 'end': 746}, {'entity_group': 'PER', 'score': 0.99707186, 'word': 'Vladimir Arkhipkin', 'start': 782, 'end': 800}, {'entity_group': 'PER', 'score': 0.9975046, 'word': 'Igor Pavlov', 'start': 838, 'end': 849}, {'entity_group': 'PER', 'score': 0.9857013, 'word': 'Andrey Kuznetsov', 'start': 882, 'end': 898}, {'entity_group': 'PER', 'score': 0.9982041, 'word': 'Denis Dimitrov', 'start': 943, 'end': 957}])]
['809' '69.0' '1'
 "The description from it's GitHub page is:\n\n*Kandinsky 2.2 brings substantial improvements upon its predecessor, Kandinsky 2.1, by introducing a new, more powerful image encoder - CLIP-ViT-G and the ControlNet support. The switch to CLIP-ViT-G as the image encoder significantly increases the model's capability to generate more aesthetic pictures and better understand text, thus enhancing the model's overall performance. The addition of the ControlNet mechanism allows the model to effectively control the process of generating images. This leads to more accurate and visually appealing outputs and opens new possibilities for text-guided image manipulation.*\n\nThe original codebase can be found at [ai-forever/Kandinsky-2](https://github.com/ai-forever/Kandinsky-2).\n\n<Tip>\n\nCheck out the [Kandinsky Community](https://huggingface.co/kandinsky-community) organization on the Hub for the official model checkpoints for tasks like text-to-image, image-to-image, and inpainting.\n\n</Tip>\n\n<Tip>"
 list([{'entity_group': 'MISC', 'score': 0.54289794, 'word': 'G', 'start': 26, 'end': 27}, {'entity_group': 'ORG', 'score': 0.56667227, 'word': '##itHub', 'start': 27, 'end': 32}, {'entity_group': 'MISC', 'score': 0.9541554, 'word': 'Kandinsky 2. 2', 'start': 44, 'end': 57}, {'entity_group': 'MISC', 'score': 0.9676645, 'word': 'Kandinsky 2. 1', 'start': 112, 'end': 125}, {'entity_group': 'ORG', 'score': 0.75835294, 'word': 'CLIP', 'start': 179, 'end': 183}, {'entity_group': 'ORG', 'score': 0.8217151, 'word': 'V', 'start': 184, 'end': 185}, {'entity_group': 'ORG', 'score': 0.6224768, 'word': 'G', 'start': 188, 'end': 189}, {'entity_group': 'ORG', 'score': 0.79017174, 'word': 'Control', 'start': 198, 'end': 205}, {'entity_group': 'MISC', 'score': 0.79222465, 'word': '##Net', 'start': 205, 'end': 208}, {'entity_group': 'ORG', 'score': 0.6428427, 'word': 'CLIP', 'start': 232, 'end': 236}, {'entity_group': 'ORG', 'score': 0.8291756, 'word': 'V', 'start': 237, 'end': 238}, {'entity_group': 'ORG', 'score': 0.597071, 'word': 'G', 'start': 241, 'end': 242}, {'entity_group': 'ORG', 'score': 0.8061388, 'word': 'Control', 'start': 443, 'end': 450}, {'entity_group': 'MISC', 'score': 0.5203467, 'word': '##Net', 'start': 450, 'end': 453}, {'entity_group': 'MISC', 'score': 0.8110884, 'word': 'Kandinsky', 'start': 713, 'end': 722}, {'entity_group': 'MISC', 'score': 0.79923606, 'word': '2', 'start': 723, 'end': 724}, {'entity_group': 'MISC', 'score': 0.6192414, 'word': 'Kandinsky', 'start': 756, 'end': 765}, {'entity_group': 'MISC', 'score': 0.47847208, 'word': '2', 'start': 766, 'end': 767}, {'entity_group': 'ORG', 'score': 0.99427474, 'word': 'Kandinsky Community', 'start': 793, 'end': 812}, {'entity_group': 'ORG', 'score': 0.51138234, 'word': '##face', 'start': 829, 'end': 833}, {'entity_group': 'ORG', 'score': 0.64078933, 'word': 'kandinsky', 'start': 837, 'end': 846}, {'entity_group': 'MISC', 'score': 0.39462298, 'word': 'Hub', 'start': 878, 'end': 881}])
 list([{'entity_group': 'MISC', 'score': 0.9541554, 'word': 'Kandinsky 2. 2', 'start': 44, 'end': 57}, {'entity_group': 'MISC', 'score': 0.9676645, 'word': 'Kandinsky 2. 1', 'start': 112, 'end': 125}, {'entity_group': 'ORG', 'score': 0.8217151, 'word': 'V', 'start': 184, 'end': 185}, {'entity_group': 'ORG', 'score': 0.8291756, 'word': 'V', 'start': 237, 'end': 238}, {'entity_group': 'ORG', 'score': 0.8061388, 'word': 'Control', 'start': 443, 'end': 450}, {'entity_group': 'MISC', 'score': 0.8110884, 'word': 'Kandinsky', 'start': 713, 'end': 722}, {'entity_group': 'ORG', 'score': 0.99427474, 'word': 'Kandinsky Community', 'start': 793, 'end': 812}])]
['810' '69.0' '2'
 '</Tip>\n\n<Tip>\n\nMake sure to check out the schedulers [guide](../../using-diffusers/schedulers) to learn how to explore the tradeoff between scheduler speed and quality, and see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines) section to learn how to efficiently load the same components into multiple pipelines.\n\n</Tip>\n\n## KandinskyV22PriorPipeline\n\n[[autodoc]] KandinskyV22PriorPipeline\n\t- all\n\t- __call__\n\t- interpolate\n\n## KandinskyV22Pipeline\n\n[[autodoc]] KandinskyV22Pipeline\n\t- all\n\t- __call__\n\n## KandinskyV22CombinedPipeline\n\n[[autodoc]] KandinskyV22CombinedPipeline\n\t- all\n\t- __call__\n\n## KandinskyV22ControlnetPipeline\n\n[[autodoc]] KandinskyV22ControlnetPipeline\n\t- all\n\t- __call__\n\n## KandinskyV22PriorEmb2EmbPipeline\n\n[[autodoc]] KandinskyV22PriorEmb2EmbPipeline\n\t- all\n\t- __call__\n\t- interpolate\n\n## KandinskyV22Img2ImgPipeline\n\n[[autodoc]] KandinskyV22Img2ImgPipeline\n\t- all\n\t- __call__\n\n## KandinskyV22Img2ImgCombinedPipeline'
 list([{'entity_group': 'MISC', 'score': 0.68346596, 'word': 'Ka', 'start': 380, 'end': 382}, {'entity_group': 'ORG', 'score': 0.32697904, 'word': '##ndi', 'start': 382, 'end': 385}, {'entity_group': 'MISC', 'score': 0.5915242, 'word': '##nsky', 'start': 385, 'end': 389}, {'entity_group': 'MISC', 'score': 0.55219877, 'word': 'Ka', 'start': 419, 'end': 421}, {'entity_group': 'ORG', 'score': 0.3459854, 'word': '##ndi', 'start': 421, 'end': 424}, {'entity_group': 'MISC', 'score': 0.59627414, 'word': '##nsky', 'start': 424, 'end': 428}, {'entity_group': 'MISC', 'score': 0.49428722, 'word': 'Ka', 'start': 483, 'end': 485}, {'entity_group': 'ORG', 'score': 0.3958313, 'word': '##ndi', 'start': 485, 'end': 488}, {'entity_group': 'MISC', 'score': 0.4908695, 'word': 'Ka', 'start': 517, 'end': 519}, {'entity_group': 'MISC', 'score': 0.53519803, 'word': '##nsky', 'start': 522, 'end': 526}, {'entity_group': 'MISC', 'score': 0.4925379, 'word': 'Ka', 'start': 603, 'end': 605}, {'entity_group': 'ORG', 'score': 0.36956948, 'word': '##ndi', 'start': 605, 'end': 608}, {'entity_group': 'MISC', 'score': 0.5011811, 'word': '##nsky', 'start': 608, 'end': 612}, {'entity_group': 'MISC', 'score': 0.4232667, 'word': 'Ka', 'start': 655, 'end': 657}, {'entity_group': 'ORG', 'score': 0.33796707, 'word': '##ndi', 'start': 657, 'end': 660}, {'entity_group': 'MISC', 'score': 0.6017613, 'word': '##nsky', 'start': 660, 'end': 664}, {'entity_group': 'MISC', 'score': 0.3709038, 'word': 'Ka', 'start': 699, 'end': 701}, {'entity_group': 'ORG', 'score': 0.35916358, 'word': '##ndi', 'start': 701, 'end': 704}, {'entity_group': 'MISC', 'score': 0.6098011, 'word': '##nsky', 'start': 704, 'end': 708}, {'entity_group': 'MISC', 'score': 0.3743412, 'word': 'Ka', 'start': 753, 'end': 755}, {'entity_group': 'ORG', 'score': 0.36553407, 'word': '##ndi', 'start': 755, 'end': 758}, {'entity_group': 'MISC', 'score': 0.4111827, 'word': '##nsky', 'start': 758, 'end': 762}, {'entity_group': 'MISC', 'score': 0.5847838, 'word': 'Ka', 'start': 870, 'end': 872}, {'entity_group': 'ORG', 'score': 0.35976067, 'word': '##ndi', 'start': 872, 'end': 875}, {'entity_group': 'MISC', 'score': 0.45437533, 'word': '##nsky', 'start': 875, 'end': 879}, {'entity_group': 'MISC', 'score': 0.4664266, 'word': '##nsky', 'start': 916, 'end': 920}, {'entity_group': 'MISC', 'score': 0.44615826, 'word': 'Ka', 'start': 962, 'end': 964}])
 list([])]
['811' '69.0' '3'
 '[[autodoc]] KandinskyV22Img2ImgPipeline\n\t- all\n\t- __call__\n\n## KandinskyV22Img2ImgCombinedPipeline\n\n[[autodoc]] KandinskyV22Img2ImgCombinedPipeline\n\t- all\n\t- __call__\n\n## KandinskyV22ControlnetImg2ImgPipeline\n\n[[autodoc]] KandinskyV22ControlnetImg2ImgPipeline\n\t- all\n\t- __call__\n\n## KandinskyV22InpaintPipeline\n\n[[autodoc]] KandinskyV22InpaintPipeline\n\t- all\n\t- __call__\n\n## KandinskyV22InpaintCombinedPipeline\n\n[[autodoc]] KandinskyV22InpaintCombinedPipeline\n\t- all\n\t- __call__'
 list([{'entity_group': 'MISC', 'score': 0.48171383, 'word': 'Ka', 'start': 12, 'end': 14}, {'entity_group': 'ORG', 'score': 0.5898584, 'word': '##ndi', 'start': 14, 'end': 17}, {'entity_group': 'MISC', 'score': 0.68314666, 'word': '##nsky', 'start': 17, 'end': 21}, {'entity_group': 'MISC', 'score': 0.60730475, 'word': 'Ka', 'start': 63, 'end': 65}, {'entity_group': 'ORG', 'score': 0.5339891, 'word': '##ndi', 'start': 65, 'end': 68}, {'entity_group': 'MISC', 'score': 0.7574862, 'word': '##nsky', 'start': 68, 'end': 72}, {'entity_group': 'ORG', 'score': 0.50715923, 'word': 'Kandi', 'start': 112, 'end': 117}, {'entity_group': 'MISC', 'score': 0.74472207, 'word': '##nsky', 'start': 117, 'end': 121}, {'entity_group': 'MISC', 'score': 0.5944357, 'word': 'Ka', 'start': 171, 'end': 173}, {'entity_group': 'ORG', 'score': 0.51642025, 'word': '##ndi', 'start': 173, 'end': 176}, {'entity_group': 'MISC', 'score': 0.7527841, 'word': '##nsky', 'start': 176, 'end': 180}, {'entity_group': 'MISC', 'score': 0.5307822, 'word': 'Ka', 'start': 222, 'end': 224}, {'entity_group': 'ORG', 'score': 0.4506976, 'word': '##ndi', 'start': 224, 'end': 227}, {'entity_group': 'MISC', 'score': 0.6951899, 'word': '##nsky', 'start': 227, 'end': 231}, {'entity_group': 'MISC', 'score': 0.68523926, 'word': 'Ka', 'start': 283, 'end': 285}, {'entity_group': 'ORG', 'score': 0.46478692, 'word': '##ndi', 'start': 285, 'end': 288}, {'entity_group': 'MISC', 'score': 0.79812855, 'word': '##nsky', 'start': 288, 'end': 292}, {'entity_group': 'MISC', 'score': 0.47901645, 'word': 'Ka', 'start': 324, 'end': 326}, {'entity_group': 'ORG', 'score': 0.49120274, 'word': '##ndi', 'start': 326, 'end': 329}, {'entity_group': 'MISC', 'score': 0.73489845, 'word': '##nsky', 'start': 329, 'end': 333}, {'entity_group': 'MISC', 'score': 0.5695976, 'word': 'Ka', 'start': 375, 'end': 377}, {'entity_group': 'ORG', 'score': 0.45428628, 'word': '##ndi', 'start': 377, 'end': 380}, {'entity_group': 'MISC', 'score': 0.70606506, 'word': '##nsky', 'start': 380, 'end': 384}, {'entity_group': 'MISC', 'score': 0.40981552, 'word': 'Ka', 'start': 424, 'end': 426}, {'entity_group': 'ORG', 'score': 0.5048579, 'word': '##ndi', 'start': 426, 'end': 429}, {'entity_group': 'MISC', 'score': 0.6623158, 'word': '##nsky', 'start': 429, 'end': 433}])
 list([])]
['812' '70.0' '0'
 '--\ntitle: "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub"\nthumbnail: blog/assets/156_huggylingo/Huggy_Lingo.png\nauthors:\n- user: davanstrien\n---\n\n## Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub\n\n\n\n**tl;dr**: We\'re using machine learning to detect the language of Hub datasets with no language metadata, and [librarian-bots](https://huggingface.co/librarian-bots) to make pull requests to add this metadata. \n\nThe Hugging Face Hub has become the repository where the community shares machine learning models, datasets, and applications. As the number of datasets grows, metadata becomes increasingly important as a tool for finding the right resource for your use case.\n\nIn this blog post, I\'m excited to share some early experiments which seek to use machine learning to improve the metadata for datasets hosted on the Hugging Face Hub.\n\n### Language Metadata for Datasets on the Hub'
 list([{'entity_group': 'MISC', 'score': 0.8675378, 'word': 'Hu', 'start': 11, 'end': 13}, {'entity_group': 'MISC', 'score': 0.71903574, 'word': 'Ling', 'start': 17, 'end': 21}, {'entity_group': 'MISC', 'score': 0.8350913, 'word': 'Hugging Face Hub', 'start': 83, 'end': 99}, {'entity_group': 'MISC', 'score': 0.48607847, 'word': 'Hu', 'start': 139, 'end': 141}, {'entity_group': 'MISC', 'score': 0.56771463, 'word': 'Ling', 'start': 145, 'end': 149}, {'entity_group': 'MISC', 'score': 0.55058837, 'word': 'Hu', 'start': 192, 'end': 194}, {'entity_group': 'MISC', 'score': 0.6223679, 'word': 'Ling', 'start': 198, 'end': 202}, {'entity_group': 'MISC', 'score': 0.73434067, 'word': 'Hugging Face Hub', 'start': 264, 'end': 280}, {'entity_group': 'MISC', 'score': 0.48192924, 'word': 'Hub', 'start': 350, 'end': 353}, {'entity_group': 'MISC', 'score': 0.6333714, 'word': 'Hugging Face Hu', 'start': 500, 'end': 515}, {'entity_group': 'ORG', 'score': 0.51389915, 'word': '##b', 'start': 515, 'end': 516}, {'entity_group': 'MISC', 'score': 0.7388607, 'word': 'Hugging Face Hub', 'start': 906, 'end': 922}, {'entity_group': 'MISC', 'score': 0.61317444, 'word': 'Hu', 'start': 967, 'end': 969}])
 list([{'entity_group': 'MISC', 'score': 0.8675378, 'word': 'Hu', 'start': 11, 'end': 13}, {'entity_group': 'MISC', 'score': 0.8350913, 'word': 'Hugging Face Hub', 'start': 83, 'end': 99}])]
['813' '70.0' '1'
 '### Language Metadata for Datasets on the Hub\n\nThere are currently ~50K public datasets on the Hugging Face Hub. Metadata about the language used in a dataset can be specified using a [YAML](https://en.wikipedia.org/wiki/YAML) field at the top of the [dataset card](https://huggingface.co/docs/datasets/upload_dataset#create-a-dataset-card).\n\nAll public datasets specify 1,716 unique languages via a language tag in their metadata. Note that some of them will be the result of languages being specified in different ways i.e. `en` vs `eng` vs `english` vs `English`. \n\nFor example, the [IMDB dataset](https://huggingface.co/datasets/imdb) specifies `en` in the YAML metadata (indicating English):\n\n<p align="center"> \n <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/huggy_lingo/lang_metadata.png" alt="Screenshot of YAML metadata"><br> \n<em>Section of the YAML metadata for the IMDB dataset</em> \n </p>'
 list([{'entity_group': 'MISC', 'score': 0.66716325, 'word': 'Hu', 'start': 95, 'end': 97}, {'entity_group': 'MISC', 'score': 0.58092797, 'word': 'Face Hu', 'start': 103, 'end': 110}, {'entity_group': 'ORG', 'score': 0.5725881, 'word': '##face', 'start': 281, 'end': 285}, {'entity_group': 'MISC', 'score': 0.68891364, 'word': '##sh', 'start': 549, 'end': 551}, {'entity_group': 'MISC', 'score': 0.99495065, 'word': 'English', 'start': 557, 'end': 564}, {'entity_group': 'ORG', 'score': 0.9252214, 'word': 'IMDB', 'start': 587, 'end': 591}, {'entity_group': 'MISC', 'score': 0.99712735, 'word': 'English', 'start': 687, 'end': 694}, {'entity_group': 'ORG', 'score': 0.602865, 'word': '##face', 'start': 744, 'end': 748}, {'entity_group': 'ORG', 'score': 0.62547565, 'word': 'co', 'start': 749, 'end': 751}, {'entity_group': 'ORG', 'score': 0.9040873, 'word': 'IMDB', 'start': 924, 'end': 928}])
 list([{'entity_group': 'MISC', 'score': 0.99495065, 'word': 'English', 'start': 557, 'end': 564}, {'entity_group': 'ORG', 'score': 0.9252214, 'word': 'IMDB', 'start': 587, 'end': 591}, {'entity_group': 'MISC', 'score': 0.99712735, 'word': 'English', 'start': 687, 'end': 694}, {'entity_group': 'ORG', 'score': 0.9040873, 'word': 'IMDB', 'start': 924, 'end': 928}])]
['814' '70.0' '2'
 'It is perhaps unsurprising that English is by far the most common language for datasets on the Hub, with around 19% of datasets on the Hub listing their language as `en` (not including any variations of `en`, so the actual percentage is likely much higher).\n\n <p align="center"> \n     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/huggy_lingo/lang_freq.png" alt="Distribution of language tags"><br> \n     <em>The frequency and percentage frequency for datasets on the Hugging Face Hub</em> \n </p> \n\n\nWhat does the distribution of languages look like if we exclude English? We can see that there is a grouping of a few dominant languages and after that there is a pretty smooth fall in the frequencies at which languages appear.'
 list([{'entity_group': 'MISC', 'score': 0.99721235, 'word': 'English', 'start': 32, 'end': 39}, {'entity_group': 'MISC', 'score': 0.5811876, 'word': 'Hub', 'start': 95, 'end': 98}, {'entity_group': 'MISC', 'score': 0.40776998, 'word': 'Hub', 'start': 135, 'end': 138}, {'entity_group': 'MISC', 'score': 0.8456036, 'word': 'Hu', 'start': 515, 'end': 517}, {'entity_group': 'MISC', 'score': 0.62038094, 'word': 'Face Hub', 'start': 523, 'end': 531}, {'entity_group': 'MISC', 'score': 0.9619265, 'word': 'English', 'start': 611, 'end': 618}])
 list([{'entity_group': 'MISC', 'score': 0.99721235, 'word': 'English', 'start': 32, 'end': 39}, {'entity_group': 'MISC', 'score': 0.8456036, 'word': 'Hu', 'start': 515, 'end': 517}, {'entity_group': 'MISC', 'score': 0.9619265, 'word': 'English', 'start': 611, 'end': 618}])]
['815' '70.0' '3'
 '<p align="center"> \n     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/huggy_lingo/lang_freq_distribution.png" alt="Distribution of language tags"><br> \n     <em>Distribution of language tags for datasets on the hub excluding English.</em> \n </p> \n\nHowever, there is a major caveat to this. Most datasets (around 87%) do not specify the language used; only approximately 13% of datasets include language information in their metadata.\n\n\n<p align="center"> \n     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/huggy_lingo/has_lang_info_bar.png" alt="Barchart"><br> \n     <em>The percent of datasets which have language metadata. True indicates language metadata is specified, False means no language data is listed. No card data means that there isn\'t any metadata or it couldn\'t be loaded by the `huggingface_hub` Python library.</em> \n</p> \n\n#### Why is Language Metadata Important?'
 list([{'entity_group': 'MISC', 'score': 0.9922984, 'word': 'English', 'start': 273, 'end': 280}, {'entity_group': 'MISC', 'score': 0.7427161, 'word': 'Python', 'start': 907, 'end': 913}])
 list([{'entity_group': 'MISC', 'score': 0.9922984, 'word': 'English', 'start': 273, 'end': 280}])]
['816' '70.0' '4'
 "#### Why is Language Metadata Important?\n\nLanguage metadata can be a vital tool for finding relevant datasets. The Hugging Face Hub allows you to filter datasets by language. For example, if we want to find datasets with Dutch language we can use [a filter](https://huggingface.co/datasets?language=language:nl&sort=trending) on the Hub to include only datasets with Dutch data. \n\nCurrently this filter returns 184 datasets. However, there are datasets on the Hub which include Dutch but don't specify this in the metadata. These datasets become more difficult to find, particularly as the number of datasets on the Hub grows. \n\nMany people want to be able to find datasets for a particular language. One of the major barriers to training good open source LLMs for a particular language is a lack of high quality training data."
 list([{'entity_group': 'MISC', 'score': 0.6806048, 'word': 'Hu', 'start': 115, 'end': 117}, {'entity_group': 'MISC', 'score': 0.47102994, 'word': 'Face', 'start': 123, 'end': 127}, {'entity_group': 'ORG', 'score': 0.46813667, 'word': 'Hub', 'start': 128, 'end': 131}, {'entity_group': 'MISC', 'score': 0.99932957, 'word': 'Dutch', 'start': 221, 'end': 226}, {'entity_group': 'ORG', 'score': 0.52812934, 'word': '##face', 'start': 273, 'end': 277}, {'entity_group': 'MISC', 'score': 0.99923277, 'word': 'Dutch', 'start': 367, 'end': 372}, {'entity_group': 'MISC', 'score': 0.9990294, 'word': 'Dutch', 'start': 478, 'end': 483}])
 list([{'entity_group': 'MISC', 'score': 0.99932957, 'word': 'Dutch', 'start': 221, 'end': 226}, {'entity_group': 'MISC', 'score': 0.99923277, 'word': 'Dutch', 'start': 367, 'end': 372}, {'entity_group': 'MISC', 'score': 0.9990294, 'word': 'Dutch', 'start': 478, 'end': 483}])]
['817' '70.0' '5'
 'If we switch to the task of finding relevant machine learning models, knowing what languages were included in the training data for a model can help us find models for the language we are interested in. This relies on the dataset specifying this information. \n\nFinally, knowing what languages are represented on the Hub (and which are not), helps us understand the language biases of the Hub and helps inform community efforts to address gaps in particular languages. \n\n### Predicting the Languages of Datasets Using Machine Learning\n\nWe’ve already seen that many of the datasets on the Hugging Face Hub haven’t included metadata for the language used. However, since these datasets are already shared openly, perhaps we can look at the dataset and try to identify the language using machine learning.\n\n#### Getting the Data \n\nOne way we could access some examples from a dataset is by using the datasets library to download the datasets i.e. \n\n```python\nfrom datasets import load_dataset'
 list([{'entity_group': 'MISC', 'score': 0.5689813, 'word': 'Hub', 'start': 316, 'end': 319}, {'entity_group': 'MISC', 'score': 0.5396072, 'word': 'Hub', 'start': 388, 'end': 391}, {'entity_group': 'MISC', 'score': 0.8319424, 'word': 'Hu', 'start': 587, 'end': 589}, {'entity_group': 'MISC', 'score': 0.53557855, 'word': 'Face Hub', 'start': 595, 'end': 603}])
 list([{'entity_group': 'MISC', 'score': 0.8319424, 'word': 'Hu', 'start': 587, 'end': 589}])]
['818' '70.0' '6'
 '```python\nfrom datasets import load_dataset\n\ndataset = load_dataset("biglam/on_the_books")'
 list([]) list([])]
['819' '70.0' '7'
 '```\n\nHowever, for some of the datasets on the Hub, we might be keen not to download the whole dataset. We could instead try to load a sample of the dataset. However, depending on how the dataset was created, we might still end up downloading more data than we’d need onto the machine we’re working on. \n\nLuckily, many datasets on the Hub are available via the [datasets server](https://huggingface.co/docs/datasets-server/index). The datasets server is an API that allows us to access datasets hosted on the Hub without downloading the dataset locally. The Datasets Server powers the Datasets Viewer preview you will see for many datasets hosted on the Hub.'
 list([{'entity_group': 'MISC', 'score': 0.38905495, 'word': 'Hub', 'start': 46, 'end': 49}, {'entity_group': 'LOC', 'score': 0.40857923, 'word': 'Hu', 'start': 334, 'end': 336}, {'entity_group': 'MISC', 'score': 0.40924335, 'word': '##b', 'start': 336, 'end': 337}, {'entity_group': 'LOC', 'score': 0.3886418, 'word': 'Hu', 'start': 508, 'end': 510}, {'entity_group': 'MISC', 'score': 0.35051054, 'word': '##b', 'start': 510, 'end': 511}, {'entity_group': 'ORG', 'score': 0.836124, 'word': 'Datasets Server', 'start': 557, 'end': 572}, {'entity_group': 'LOC', 'score': 0.5302389, 'word': 'Hu', 'start': 653, 'end': 655}])
 list([{'entity_group': 'ORG', 'score': 0.836124, 'word': 'Datasets Server', 'start': 557, 'end': 572}])]
['820' '70.0' '8'
 'For this first experiment with predicting language for datasets, we define a list of column names and data types likely to contain textual content i.e. `text` or `prompt` column names and `string` features are likely to be relevant `image` is not. This means we can avoid predicting the language for datasets where language information is less relevant, for example, image classification datasets. We use the Datasets Server to get 20 rows of text data to pass to a machine learning model (we could modify this to take more or fewer examples from the dataset). \n\nThis approach means that for the majority of datasets on the Hub we can quickly request the contents of likely text columns for the first 20 rows in a dataset. \n\n#### Predicting the Language of a Dataset'
 list([{'entity_group': 'ORG', 'score': 0.88746494, 'word': 'Datasets Server', 'start': 409, 'end': 424}, {'entity_group': 'ORG', 'score': 0.3509818, 'word': 'Hu', 'start': 624, 'end': 626}])
 list([{'entity_group': 'ORG', 'score': 0.88746494, 'word': 'Datasets Server', 'start': 409, 'end': 424}])]
['821' '70.0' '9'
 '#### Predicting the Language of a Dataset \n\nOnce we have some examples of text from a dataset, we need to predict the language. There are various options here, but for this work, we used the [facebook/fasttext-language-identification](https://huggingface.co/facebook/fasttext-language-identification) fastText model created by [Meta](https://huggingface.co/facebook) as part of the [No Language Left Behind](https://ai.facebook.com/research/no-language-left-behind/) work. This model can detect 217 languages which will likely represent the majority of languages for datasets hosted on the Hub. \n\nWe pass 20 examples to the model representing rows from a dataset. This results in 20 individual language predictions (one per row) for each dataset.  \n\nOnce we have these predictions, we do some additional filtering to determine if we will accept the predictions as a metadata suggestion. This roughly consists of:'
 list([{'entity_group': 'ORG', 'score': 0.7138331, 'word': 'Met', 'start': 328, 'end': 331}, {'entity_group': 'ORG', 'score': 0.5158537, 'word': '##face', 'start': 349, 'end': 353}, {'entity_group': 'MISC', 'score': 0.7346535, 'word': 'No Language', 'start': 383, 'end': 394}, {'entity_group': 'MISC', 'score': 0.5363845, 'word': 'Behind', 'start': 400, 'end': 406}, {'entity_group': 'ORG', 'score': 0.3345973, 'word': 'Hu', 'start': 590, 'end': 592}])
 list([])]
['822' '70.0' '10'
 '- Grouping the predictions for each dataset by language: some datasets return predictions for multiple languages. We group these predictions by the language predicted i.e. if a dataset returns predictions for English and Dutch, we group the English and Dutch predictions together. \n- For datasets with multiple languages predicted, we count how many predictions we have for each language. If a language is predicted less than 20% of the time, we discard this prediction. i.e. if we have 18 predictions for English and only 2 for Dutch we discard the Dutch predictions. \n- We calculate the mean score for all predictions for a language. If the mean score associated with a languages prediction is below 80% we discard this prediction.\n\n <p align="center"> \n     <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/huggy_lingo/prediction-flow.png" alt="Prediction workflow"><br> \n     <em>Diagram showing how predictions are handled.</em> \n </p>'
 list([{'entity_group': 'MISC', 'score': 0.9948565, 'word': 'English', 'start': 209, 'end': 216}, {'entity_group': 'MISC', 'score': 0.99778086, 'word': 'Dutch', 'start': 221, 'end': 226}, {'entity_group': 'MISC', 'score': 0.9988305, 'word': 'English', 'start': 241, 'end': 248}, {'entity_group': 'MISC', 'score': 0.99878114, 'word': 'Dutch', 'start': 253, 'end': 258}, {'entity_group': 'MISC', 'score': 0.9929853, 'word': 'English', 'start': 506, 'end': 513}, {'entity_group': 'MISC', 'score': 0.99770564, 'word': 'Dutch', 'start': 529, 'end': 534}, {'entity_group': 'MISC', 'score': 0.9986249, 'word': 'Dutch', 'start': 550, 'end': 555}])
 list([{'entity_group': 'MISC', 'score': 0.9948565, 'word': 'English', 'start': 209, 'end': 216}, {'entity_group': 'MISC', 'score': 0.99778086, 'word': 'Dutch', 'start': 221, 'end': 226}, {'entity_group': 'MISC', 'score': 0.9988305, 'word': 'English', 'start': 241, 'end': 248}, {'entity_group': 'MISC', 'score': 0.99878114, 'word': 'Dutch', 'start': 253, 'end': 258}, {'entity_group': 'MISC', 'score': 0.9929853, 'word': 'English', 'start': 506, 'end': 513}, {'entity_group': 'MISC', 'score': 0.99770564, 'word': 'Dutch', 'start': 529, 'end': 534}, {'entity_group': 'MISC', 'score': 0.9986249, 'word': 'Dutch', 'start': 550, 'end': 555}])]
['823' '70.0' '11'
 "Once we’ve done this filtering, we have a further step of deciding how to use these predictions. The fastText language prediction model returns predictions as an [ISO 639-3](https://en.wikipedia.org/wiki/ISO_639-3) code (an international standard for language codes) along with a script type. i.e. `kor_Hang` is the ISO 693-3 language code for Korean (kor) + Hangul script (Hang) a [ISO 15924](https://en.wikipedia.org/wiki/ISO_15924) code representing the script of a language.\n\nWe discard the script information since this isn't currently captured consistently as metadata on the Hub and, where possible, we convert the language prediction returned by the model from [ISO 639-3](https://en.wikipedia.org/wiki/ISO_639-3) to [ISO 639-1](https://en.wikipedia.org/wiki/ISO_639-1) language codes. This is largely done because these language codes have better support in the Hub UI for navigating datasets."
 list([{'entity_group': 'MISC', 'score': 0.82798725, 'word': 'ISO 639', 'start': 163, 'end': 170}, {'entity_group': 'MISC', 'score': 0.6689119, 'word': '3', 'start': 171, 'end': 172}, {'entity_group': 'ORG', 'score': 0.4504864, 'word': '##ia', 'start': 192, 'end': 194}, {'entity_group': 'MISC', 'score': 0.9939178, 'word': 'ISO', 'start': 204, 'end': 207}, {'entity_group': 'MISC', 'score': 0.6369587, 'word': '639', 'start': 208, 'end': 211}, {'entity_group': 'MISC', 'score': 0.35169104, 'word': 'Hang', 'start': 303, 'end': 307}, {'entity_group': 'MISC', 'score': 0.9374082, 'word': 'ISO 693', 'start': 316, 'end': 323}, {'entity_group': 'MISC', 'score': 0.57067025, 'word': '3', 'start': 324, 'end': 325}, {'entity_group': 'MISC', 'score': 0.9947083, 'word': 'Korean', 'start': 344, 'end': 350}, {'entity_group': 'MISC', 'score': 0.9403233, 'word': 'Hangul', 'start': 359, 'end': 365}, {'entity_group': 'MISC', 'score': 0.7479063, 'word': 'Hang', 'start': 374, 'end': 378}, {'entity_group': 'MISC', 'score': 0.726595, 'word': 'ISO 159', 'start': 383, 'end': 390}, {'entity_group': 'MISC', 'score': 0.97048247, 'word': 'ISO', 'start': 424, 'end': 427}, {'entity_group': 'MISC', 'score': 0.8069168, 'word': 'ISO 63', 'start': 670, 'end': 676}, {'entity_group': 'MISC', 'score': 0.9491844, 'word': 'ISO', 'start': 711, 'end': 714}, {'entity_group': 'MISC', 'score': 0.85143185, 'word': 'ISO 63', 'start': 726, 'end': 732}, {'entity_group': 'MISC', 'score': 0.7982742, 'word': '1', 'start': 734, 'end': 735}, {'entity_group': 'MISC', 'score': 0.97465116, 'word': 'ISO', 'start': 767, 'end': 770}, {'entity_group': 'MISC', 'score': 0.59846973, 'word': '1', 'start': 775, 'end': 776}])
 list([{'entity_group': 'MISC', 'score': 0.82798725, 'word': 'ISO 639', 'start': 163, 'end': 170}, {'entity_group': 'MISC', 'score': 0.9939178, 'word': 'ISO', 'start': 204, 'end': 207}, {'entity_group': 'MISC', 'score': 0.9374082, 'word': 'ISO 693', 'start': 316, 'end': 323}, {'entity_group': 'MISC', 'score': 0.9947083, 'word': 'Korean', 'start': 344, 'end': 350}, {'entity_group': 'MISC', 'score': 0.9403233, 'word': 'Hangul', 'start': 359, 'end': 365}, {'entity_group': 'MISC', 'score': 0.97048247, 'word': 'ISO', 'start': 424, 'end': 427}, {'entity_group': 'MISC', 'score': 0.8069168, 'word': 'ISO 63', 'start': 670, 'end': 676}, {'entity_group': 'MISC', 'score': 0.9491844, 'word': 'ISO', 'start': 711, 'end': 714}, {'entity_group': 'MISC', 'score': 0.85143185, 'word': 'ISO 63', 'start': 726, 'end': 732}, {'entity_group': 'MISC', 'score': 0.97465116, 'word': 'ISO', 'start': 767, 'end': 770}])]
['824' '70.0' '12'
 "For some ISO 639-3 codes, there is no ISO 639-1 equivalent. For these cases we manually specify a mapping if we deem it to make sense, for example Standard Arabic (`arb`) is mapped to Arabic (`ar`). Where an obvious mapping is not possible, we currently don't suggest metadata for this dataset. In future iterations of this work we may take a different approach. It is important to recognise this approach does come with downsides, since it reduces the diversity of languages which might be suggested and also relies on subjective judgments about what languages can be mapped to others. \n\nBut the process doesn't stop here. After all, what use is predicting the language of the datasets if we can't share that information with the rest of the community?\n\n### Using Librarian-Bot to Update Metadata"
 list([{'entity_group': 'MISC', 'score': 0.9360226, 'word': 'ISO 639 - 3', 'start': 9, 'end': 18}, {'entity_group': 'MISC', 'score': 0.933403, 'word': 'ISO 639 - 1', 'start': 38, 'end': 47}, {'entity_group': 'MISC', 'score': 0.96686876, 'word': 'Standard Arabic', 'start': 147, 'end': 162}, {'entity_group': 'MISC', 'score': 0.9952304, 'word': 'Arabic', 'start': 184, 'end': 190}])
 list([{'entity_group': 'MISC', 'score': 0.9360226, 'word': 'ISO 639 - 3', 'start': 9, 'end': 18}, {'entity_group': 'MISC', 'score': 0.933403, 'word': 'ISO 639 - 1', 'start': 38, 'end': 47}, {'entity_group': 'MISC', 'score': 0.96686876, 'word': 'Standard Arabic', 'start': 147, 'end': 162}, {'entity_group': 'MISC', 'score': 0.9952304, 'word': 'Arabic', 'start': 184, 'end': 190}])]
['825' '70.0' '13'
 "### Using Librarian-Bot to Update Metadata\n\nTo ensure this valuable language metadata is incorporated back into the Hub, we turn to Librarian-Bot! Librarian-Bot takes the language predictions generated by Meta's [facebook/fasttext-language-identification](https://huggingface.co/facebook/fasttext-language-identification) fastText model and opens pull requests to add this information to the metadata of each respective dataset. \n\nThis system not only updates the datasets with language information, but also does it swiftly and efficiently, without requiring manual work from humans. If the owner of a repo decided to approve and merge the pull request, then the language metadata becomes available for all users, significantly enhancing the usability of the Hugging Face Hub. You can keep track of what the librarian-bot is doing [here](https://huggingface.co/librarian-bot/activity/community)! \n\n#### Next Steps"
 list([{'entity_group': 'ORG', 'score': 0.820776, 'word': 'Li', 'start': 10, 'end': 12}, {'entity_group': 'ORG', 'score': 0.91982025, 'word': 'Li', 'start': 132, 'end': 134}, {'entity_group': 'ORG', 'score': 0.5080315, 'word': 'Bo', 'start': 142, 'end': 144}, {'entity_group': 'ORG', 'score': 0.8890695, 'word': 'Li', 'start': 147, 'end': 149}, {'entity_group': 'ORG', 'score': 0.5677926, 'word': '##rian', 'start': 152, 'end': 156}, {'entity_group': 'ORG', 'score': 0.6171576, 'word': 'Bot', 'start': 157, 'end': 160}, {'entity_group': 'ORG', 'score': 0.96704197, 'word': 'Meta', 'start': 205, 'end': 209}, {'entity_group': 'ORG', 'score': 0.66701007, 'word': '##face', 'start': 271, 'end': 275}, {'entity_group': 'ORG', 'score': 0.56696236, 'word': 'co', 'start': 276, 'end': 278}, {'entity_group': 'MISC', 'score': 0.55620384, 'word': 'Hu', 'start': 760, 'end': 762}, {'entity_group': 'MISC', 'score': 0.36749518, 'word': 'Face Hu', 'start': 768, 'end': 775}])
 list([{'entity_group': 'ORG', 'score': 0.820776, 'word': 'Li', 'start': 10, 'end': 12}, {'entity_group': 'ORG', 'score': 0.91982025, 'word': 'Li', 'start': 132, 'end': 134}, {'entity_group': 'ORG', 'score': 0.8890695, 'word': 'Li', 'start': 147, 'end': 149}, {'entity_group': 'ORG', 'score': 0.96704197, 'word': 'Meta', 'start': 205, 'end': 209}])]
['826' '70.0' '14'
 "#### Next Steps \n\nAs the number of datasets on the Hub grows, metadata becomes increasingly important. Language metadata, in particular, can be incredibly valuable for identifying the correct dataset for your use case.\n\nWith the assistance of the Datasets Server and the [Librarian-Bots](https://huggingface.co/librarian-bots), we can update our dataset metadata at a scale that wouldn't be possible manually. As a result, we're enriching the Hub and making it an even more powerful tool for data scientists, linguists, and AI enthusiasts around the world. \n\nAs the machine learning librarian at Hugging Face, I continue exploring opportunities for automatic metadata enrichment for machine learning artefacts hosted on the Hub. Feel free to reach out (daniel at thiswebsite dot co) if you have ideas or want to collaborate on this effort!"
 list([{'entity_group': 'LOC', 'score': 0.30724266, 'word': 'Hu', 'start': 51, 'end': 53}, {'entity_group': 'MISC', 'score': 0.3652411, 'word': '##b', 'start': 53, 'end': 54}, {'entity_group': 'ORG', 'score': 0.9960014, 'word': 'Datasets Server', 'start': 247, 'end': 262}, {'entity_group': 'ORG', 'score': 0.9783927, 'word': 'Li', 'start': 272, 'end': 274}, {'entity_group': 'ORG', 'score': 0.7327482, 'word': '##rian', 'start': 277, 'end': 281}, {'entity_group': 'ORG', 'score': 0.88571894, 'word': 'Bots', 'start': 282, 'end': 286}, {'entity_group': 'ORG', 'score': 0.8750003, 'word': '##face', 'start': 303, 'end': 307}, {'entity_group': 'ORG', 'score': 0.7344617, 'word': 'co', 'start': 308, 'end': 310}, {'entity_group': 'ORG', 'score': 0.912213, 'word': 'Hugging Face', 'start': 596, 'end': 608}, {'entity_group': 'LOC', 'score': 0.3909957, 'word': 'Hu', 'start': 724, 'end': 726}, {'entity_group': 'MISC', 'score': 0.4086686, 'word': '##b', 'start': 726, 'end': 727}])
 list([{'entity_group': 'ORG', 'score': 0.9960014, 'word': 'Datasets Server', 'start': 247, 'end': 262}, {'entity_group': 'ORG', 'score': 0.9783927, 'word': 'Li', 'start': 272, 'end': 274}, {'entity_group': 'ORG', 'score': 0.88571894, 'word': 'Bots', 'start': 282, 'end': 286}, {'entity_group': 'ORG', 'score': 0.8750003, 'word': '##face', 'start': 303, 'end': 307}, {'entity_group': 'ORG', 'score': 0.912213, 'word': 'Hugging Face', 'start': 596, 'end': 608}])]
['827' '71.0' '0'
 '!--Copyright 2020 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\nspecific language governing permissions and limitations under the License.\n\n⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n\n-->\n\n# Trainer'
 list([{'entity_group': 'ORG', 'score': 0.9901479, 'word': 'HuggingFace Team', 'start': 22, 'end': 38}, {'entity_group': 'MISC', 'score': 0.99658716, 'word': 'Apache License', 'start': 81, 'end': 95}, {'entity_group': 'MISC', 'score': 0.6315872, 'word': '2', 'start': 105, 'end': 106}, {'entity_group': 'MISC', 'score': 0.99416995, 'word': 'License', 'start': 115, 'end': 122}, {'entity_group': 'MISC', 'score': 0.99455065, 'word': 'License', 'start': 182, 'end': 189}, {'entity_group': 'MISC', 'score': 0.988383, 'word': 'License', 'start': 220, 'end': 227}, {'entity_group': 'ORG', 'score': 0.64696234, 'word': 'apache', 'start': 243, 'end': 249}, {'entity_group': 'MISC', 'score': 0.9860701, 'word': 'License', 'start': 366, 'end': 373}, {'entity_group': 'MISC', 'score': 0.9909671, 'word': 'License', 'start': 491, 'end': 498}, {'entity_group': 'MISC', 'score': 0.99181926, 'word': 'License', 'start': 573, 'end': 580}, {'entity_group': 'MISC', 'score': 0.7033036, 'word': 'MD', 'start': 681, 'end': 683}, {'entity_group': 'ORG', 'score': 0.5486843, 'word': '##X', 'start': 683, 'end': 684}, {'entity_group': 'MISC', 'score': 0.5207587, 'word': 'Mark', 'start': 728, 'end': 732}])
 list([{'entity_group': 'ORG', 'score': 0.9901479, 'word': 'HuggingFace Team', 'start': 22, 'end': 38}, {'entity_group': 'MISC', 'score': 0.99658716, 'word': 'Apache License', 'start': 81, 'end': 95}, {'entity_group': 'MISC', 'score': 0.99416995, 'word': 'License', 'start': 115, 'end': 122}, {'entity_group': 'MISC', 'score': 0.99455065, 'word': 'License', 'start': 182, 'end': 189}, {'entity_group': 'MISC', 'score': 0.988383, 'word': 'License', 'start': 220, 'end': 227}, {'entity_group': 'MISC', 'score': 0.9860701, 'word': 'License', 'start': 366, 'end': 373}, {'entity_group': 'MISC', 'score': 0.9909671, 'word': 'License', 'start': 491, 'end': 498}, {'entity_group': 'MISC', 'score': 0.99181926, 'word': 'License', 'start': 573, 'end': 580}])]
['828' '71.0' '1'
 "-->\n\n# Trainer\n\nThe [`Trainer`] class provides an API for feature-complete training in PyTorch, and it supports distributed training on multiple GPUs/TPUs, mixed precision for [NVIDIA GPUs](https://nvidia.github.io/apex/), [AMD GPUs](https://rocm.docs.amd.com/en/latest/rocm.html), and [`torch.amp`](https://pytorch.org/docs/stable/amp.html) for PyTorch. [`Trainer`] goes hand-in-hand with the [`TrainingArguments`] class, which offers a wide range of options to customize how a model is trained. Together, these two classes provide a complete training API.\n\n[`Seq2SeqTrainer`] and [`Seq2SeqTrainingArguments`] inherit from the [`Trainer`] and [`TrainingArgument`] classes and they're adapted for training models for sequence-to-sequence tasks such as summarization or translation.\n\n<Tip warning={true}>\n\nThe [`Trainer`] class is optimized for 🤗 Transformers models and can have surprising behaviors\nwhen used with other models. When using it with your own model, make sure:"
 list([{'entity_group': 'ORG', 'score': 0.56017417, 'word': 'Train', 'start': 22, 'end': 27}, {'entity_group': 'ORG', 'score': 0.97515965, 'word': 'PyTorch', 'start': 87, 'end': 94}, {'entity_group': 'MISC', 'score': 0.9346528, 'word': 'NVI', 'start': 177, 'end': 180}, {'entity_group': 'ORG', 'score': 0.57364374, 'word': '##DI', 'start': 180, 'end': 182}, {'entity_group': 'MISC', 'score': 0.7681272, 'word': '##A', 'start': 182, 'end': 183}, {'entity_group': 'ORG', 'score': 0.9474726, 'word': '##vidia', 'start': 199, 'end': 204}, {'entity_group': 'MISC', 'score': 0.7358507, 'word': 'AM', 'start': 224, 'end': 226}, {'entity_group': 'ORG', 'score': 0.64696306, 'word': '##D', 'start': 226, 'end': 227}, {'entity_group': 'ORG', 'score': 0.85141015, 'word': 'pytorch', 'start': 308, 'end': 315}, {'entity_group': 'ORG', 'score': 0.9816996, 'word': 'PyTorch', 'start': 346, 'end': 353}, {'entity_group': 'ORG', 'score': 0.6467097, 'word': 'Train', 'start': 357, 'end': 362}, {'entity_group': 'ORG', 'score': 0.8607224, 'word': 'TrainingA', 'start': 396, 'end': 405}, {'entity_group': 'ORG', 'score': 0.7025886, 'word': '##nts', 'start': 410, 'end': 413}, {'entity_group': 'ORG', 'score': 0.5589005, 'word': '##er', 'start': 573, 'end': 575}, {'entity_group': 'ORG', 'score': 0.78996897, 'word': '##A', 'start': 599, 'end': 600}, {'entity_group': 'ORG', 'score': 0.5921541, 'word': '##nts', 'start': 605, 'end': 608}, {'entity_group': 'ORG', 'score': 0.7081459, 'word': 'Trainer', 'start': 630, 'end': 637}, {'entity_group': 'ORG', 'score': 0.8113097, 'word': 'TrainingA', 'start': 646, 'end': 655}, {'entity_group': 'ORG', 'score': 0.62383795, 'word': '##nt', 'start': 660, 'end': 662}, {'entity_group': 'ORG', 'score': 0.6399164, 'word': 'Trainer', 'start': 811, 'end': 818}, {'entity_group': 'ORG', 'score': 0.9284213, 'word': 'Transformers', 'start': 846, 'end': 858}])
 list([{'entity_group': 'ORG', 'score': 0.97515965, 'word': 'PyTorch', 'start': 87, 'end': 94}, {'entity_group': 'MISC', 'score': 0.9346528, 'word': 'NVI', 'start': 177, 'end': 180}, {'entity_group': 'ORG', 'score': 0.9474726, 'word': '##vidia', 'start': 199, 'end': 204}, {'entity_group': 'ORG', 'score': 0.85141015, 'word': 'pytorch', 'start': 308, 'end': 315}, {'entity_group': 'ORG', 'score': 0.9816996, 'word': 'PyTorch', 'start': 346, 'end': 353}, {'entity_group': 'ORG', 'score': 0.8607224, 'word': 'TrainingA', 'start': 396, 'end': 405}, {'entity_group': 'ORG', 'score': 0.8113097, 'word': 'TrainingA', 'start': 646, 'end': 655}, {'entity_group': 'ORG', 'score': 0.9284213, 'word': 'Transformers', 'start': 846, 'end': 858}])]
['829' '71.0' '2'
 '- your model always return tuples or subclasses of [`~utils.ModelOutput`]\n- your model can compute the loss if a `labels` argument is provided and that loss is returned as the first\n  element of the tuple (if your model returns tuples)\n- your model can accept multiple label arguments (use `label_names` in [`TrainingArguments`] to indicate their name to the [`Trainer`]) but none of them should be named `"label"`\n\n</Tip>\n\n## Trainer[[api-reference]]\n\n[[autodoc]] Trainer\n    - all\n\n## Seq2SeqTrainer\n\n[[autodoc]] Seq2SeqTrainer\n    - evaluate\n    - predict\n\n## TrainingArguments\n\n[[autodoc]] TrainingArguments\n    - all\n\n## Seq2SeqTrainingArguments\n\n[[autodoc]] Seq2SeqTrainingArguments\n    - all'
 list([]) list([])]
['830' '72.0' '0'
 'Gradio Demo: upload_button_component_events\n\n\n```\n!pip install -q gradio \n```'
 list([]) list([])]
['831' '72.0' '1' '```\nimport gradio as gr' list([]) list([])]
['832' '72.0' '2'
 'with gr.Blocks() as demo:\n    \n    with gr.Row():\n        with gr.Column():\n            upload_btn = gr.UploadButton(label="Upload Single File", file_count="single")\n        with gr.Column():\n            output_file_1 = gr.File(label="Upload Single File Output", file_count="single")\n            num_load_btn_1 = gr.Number(label="# Load Upload Single File", value=0)\n            output_click_1 = gr.Number(label="# Click Upload Single File Output", value=0)\n            upload_btn.upload(lambda s,n: (s, n + 1), [upload_btn, num_load_btn_1], [output_file_1, num_load_btn_1])\n            upload_btn.click(lambda n: (n + 1), output_click_1, [output_click_1])\n    with gr.Row():\n        with gr.Column():\n            upload_btn_multiple = gr.UploadButton(label="Upload Multiple Files", file_count="multiple")\n        with gr.Column():\n            output_file_2 = gr.File(label="Upload Multiple Files Output", file_count="multiple")'
 list([]) list([])]
['833' '72.0' '3'
 'output_file_2 = gr.File(label="Upload Multiple Files Output", file_count="multiple")\n            num_load_btn_2 = gr.Number(label="# Load Upload Multiple Files", value=0)\n            output_click_2 = gr.Number(label="# Click Upload Multiple Files Output", value=0)\n            upload_btn_multiple.upload(lambda s,n: (s, n + 1), [upload_btn_multiple, num_load_btn_2], [output_file_2, num_load_btn_2])\n            upload_btn_multiple.click(lambda n: (n + 1), output_click_2, [output_click_2])'
 list([]) list([])]
['834' '72.0' '4' 'if __name__ == "__main__":\n    demo.launch()' list([])
 list([])]
['835' '72.0' '5' '```'
 list([{'entity_group': 'PER', 'score': 0.4322449, 'word': '`', 'start': 0, 'end': 1}, {'entity_group': 'PER', 'score': 0.43227673, 'word': '`', 'start': 1, 'end': 2}, {'entity_group': 'PER', 'score': 0.43234685, 'word': '`', 'start': 2, 'end': 3}])
 list([])]
['836' '73.0' '0'
 'Normalization and pre-tokenization[[normalization-and-pre-tokenization]]\n\n<CourseFloatingBanner chapter={6}\n  classNames="absolute z-10 right-0 top-0"\n  notebooks={[\n    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter6/section4.ipynb"},\n    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter6/section4.ipynb"},\n]} />\n\nBefore we dive more deeply into the three most common subword tokenization algorithms used with Transformer models (Byte-Pair Encoding [BPE], WordPiece, and Unigram), we\'ll first take a look at the preprocessing that each tokenizer applies to text. Here\'s a high-level overview of the steps in the tokenization pipeline:'
 list([{'entity_group': 'ORG', 'score': 0.78064424, 'word': 'Google Colab', 'start': 179, 'end': 191}, {'entity_group': 'ORG', 'score': 0.9439462, 'word': 'Aws Studio', 'start': 327, 'end': 337}, {'entity_group': 'MISC', 'score': 0.7496787, 'word': 'Transformer', 'start': 568, 'end': 579}, {'entity_group': 'MISC', 'score': 0.8603583, 'word': 'By', 'start': 588, 'end': 590}, {'entity_group': 'MISC', 'score': 0.5875153, 'word': 'En', 'start': 598, 'end': 600}, {'entity_group': 'MISC', 'score': 0.7528926, 'word': 'BP', 'start': 608, 'end': 610}, {'entity_group': 'MISC', 'score': 0.81722444, 'word': 'WordPiece', 'start': 614, 'end': 623}, {'entity_group': 'MISC', 'score': 0.8169424, 'word': 'Unig', 'start': 629, 'end': 633}])
 list([{'entity_group': 'ORG', 'score': 0.9439462, 'word': 'Aws Studio', 'start': 327, 'end': 337}, {'entity_group': 'MISC', 'score': 0.8603583, 'word': 'By', 'start': 588, 'end': 590}, {'entity_group': 'MISC', 'score': 0.81722444, 'word': 'WordPiece', 'start': 614, 'end': 623}, {'entity_group': 'MISC', 'score': 0.8169424, 'word': 'Unig', 'start': 629, 'end': 633}])]
['837' '73.0' '1'
 '<div class="flex justify-center">\n<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter6/tokenization_pipeline.svg" alt="The tokenization pipeline.">\n<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter6/tokenization_pipeline-dark.svg" alt="The tokenization pipeline.">\n</div>\n\nBefore splitting a text into subtokens (according to its model), the tokenizer performs two steps: _normalization_ and _pre-tokenization_.\n\n## Normalization[[normalization]]\n\n<Youtube id="4IIC2jI9CaU"/>\n\nThe normalization step involves some general cleanup, such as removing needless whitespace, lowercasing, and/or removing accents. If you\'re familiar with [Unicode normalization](http://www.unicode.org/reports/tr15/) (such as NFC or NFKC), this is also something the tokenizer may apply.'
 list([{'entity_group': 'MISC', 'score': 0.98376846, 'word': 'Unicode', 'start': 794, 'end': 801}, {'entity_group': 'ORG', 'score': 0.990417, 'word': 'NFC', 'start': 864, 'end': 867}, {'entity_group': 'ORG', 'score': 0.959275, 'word': 'NFKC', 'start': 871, 'end': 875}])
 list([{'entity_group': 'MISC', 'score': 0.98376846, 'word': 'Unicode', 'start': 794, 'end': 801}, {'entity_group': 'ORG', 'score': 0.990417, 'word': 'NFC', 'start': 864, 'end': 867}, {'entity_group': 'ORG', 'score': 0.959275, 'word': 'NFKC', 'start': 871, 'end': 875}])]
['838' '73.0' '2'
 'The 🤗 Transformers `tokenizer` has an attribute called `backend_tokenizer` that provides access to the underlying tokenizer from the 🤗 Tokenizers library:\n\n```py\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")\nprint(type(tokenizer.backend_tokenizer))'
 list([{'entity_group': 'ORG', 'score': 0.9547936, 'word': '🤗 Transformers', 'start': 4, 'end': 18}, {'entity_group': 'ORG', 'score': 0.8698481, 'word': '🤗 Tokenizers', 'start': 133, 'end': 145}])
 list([{'entity_group': 'ORG', 'score': 0.9547936, 'word': '🤗 Transformers', 'start': 4, 'end': 18}, {'entity_group': 'ORG', 'score': 0.8698481, 'word': '🤗 Tokenizers', 'start': 133, 'end': 145}])]
['839' '73.0' '3'
 '```\n\n```python out\n<class \'tokenizers.Tokenizer\'>\n```\n\nThe `normalizer` attribute of the `tokenizer` object has a `normalize_str()` method that we can use to see how the normalization is performed:\n\n```py\nprint(tokenizer.backend_tokenizer.normalizer.normalize_str("Héllò hôw are ü?"))\n```\n\n```python out\n\'hello how are u?\''
 list([]) list([])]
['840' '73.0' '4'
 '```\n\nIn this example, since we picked the `bert-base-uncased` checkpoint, the normalization applied lowercasing and removed the accents. \n\n<Tip>\n\n✏️ **Try it out!** Load a tokenizer from the `bert-base-cased` checkpoint and pass the same example to it. What are the main differences you can see between the cased and uncased versions of the tokenizer?\n\n</Tip>\n\n## Pre-tokenization[[pre-tokenization]]\n\n<Youtube id="grlLV8AIXug"/>\n\nAs we will see in the next sections, a tokenizer cannot be trained on raw text alone. Instead, we first need to split the texts into small entities, like words. That\'s where the pre-tokenization step comes in. As we saw in [Chapter 2](/course/chapter2), a word-based tokenizer can simply split a raw text into words on whitespace and punctuation. Those words will be the boundaries of the subtokens the tokenizer can learn during its training.'
 list([]) list([])]
['841' '73.0' '5'
 'To see how a fast tokenizer performs pre-tokenization, we can use the `pre_tokenize_str()` method of the `pre_tokenizer` attribute of the `tokenizer` object:\n\n```py\ntokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str("Hello, how are  you?")'
 list([]) list([])]
['842' '73.0' '6'
 '```\n\n```python out\n[(\'Hello\', (0, 5)), (\',\', (5, 6)), (\'how\', (7, 10)), (\'are\', (11, 14)), (\'you\', (16, 19)), (\'?\', (19, 20))]\n```\n\nNotice how the tokenizer is already keeping track of the offsets, which is how it can give us the offset mapping we used in the previous section. Here the tokenizer ignores the two spaces and replaces them with just one, but the offset jumps between `are` and `you` to account for that.\n\nSince we\'re using a BERT tokenizer, the pre-tokenization involves splitting on whitespace and punctuation. Other tokenizers can have different rules for this step. For example, if we use the GPT-2 tokenizer:\n\n```py\ntokenizer = AutoTokenizer.from_pretrained("gpt2")\ntokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str("Hello, how are  you?")'
 list([{'entity_group': 'ORG', 'score': 0.54229975, 'word': 'B', 'start': 440, 'end': 441}])
 list([])]
['843' '73.0' '7'
 '```\n\nit will split on whitespace and punctuation as well, but it will keep the spaces and replace them with a `Ġ` symbol, enabling it to recover the original spaces if we decode the tokens:\n\n```python out\n[(\'Hello\', (0, 5)), (\',\', (5, 6)), (\'Ġhow\', (6, 10)), (\'Ġare\', (10, 14)), (\'Ġ\', (14, 15)), (\'Ġyou\', (15, 19)),\n (\'?\', (19, 20))]\n```\n\nAlso note that unlike the BERT tokenizer, this tokenizer does not ignore the double space.\n\nFor a last example, let\'s have a look at the T5 tokenizer, which is based on the SentencePiece algorithm:\n\n```py\ntokenizer = AutoTokenizer.from_pretrained("t5-small")\ntokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str("Hello, how are  you?")\n```\n\n```python out\n[(\'▁Hello,\', (0, 6)), (\'▁how\', (7, 10)), (\'▁are\', (11, 14)), (\'▁you?\', (16, 20))]'
 list([{'entity_group': 'MISC', 'score': 0.27047756, 'word': 'B', 'start': 365, 'end': 366}, {'entity_group': 'MISC', 'score': 0.7040054, 'word': 'SentencePiece', 'start': 512, 'end': 525}])
 list([])]
['844' '73.0' '8'
 "```\n\nLike the GPT-2 tokenizer, this one keeps spaces and replaces them with a specific token (`_`), but the T5 tokenizer only splits on whitespace, not punctuation. Also note that it added a space by default at the beginning of the sentence (before `Hello`) and ignored the double space between `are` and `you`.\n\nNow that we've seen a little of how some different tokenizers process text, we can start to explore the underlying algorithms themselves. We'll begin with a quick look at the broadly widely applicable SentencePiece; then, over the next three sections, we'll examine how the three main algorithms used for subword tokenization work.\n\n## SentencePiece[[sentencepiece]]"
 list([{'entity_group': 'MISC', 'score': 0.5536038, 'word': 'GP', 'start': 14, 'end': 16}, {'entity_group': 'MISC', 'score': 0.85066503, 'word': '2', 'start': 18, 'end': 19}, {'entity_group': 'MISC', 'score': 0.8952866, 'word': 'Sen', 'start': 514, 'end': 517}, {'entity_group': 'MISC', 'score': 0.78833956, 'word': '##iece', 'start': 523, 'end': 527}, {'entity_group': 'MISC', 'score': 0.48858267, 'word': '##ie', 'start': 658, 'end': 660}])
 list([{'entity_group': 'MISC', 'score': 0.85066503, 'word': '2', 'start': 18, 'end': 19}, {'entity_group': 'MISC', 'score': 0.8952866, 'word': 'Sen', 'start': 514, 'end': 517}])]
['845' '73.0' '9'
 "## SentencePiece[[sentencepiece]]\n\n[SentencePiece](https://github.com/google/sentencepiece) is a tokenization algorithm for the preprocessing of text that you can use with any of the models we will see in the next three sections. It considers the text as a sequence of Unicode characters, and replaces spaces with a special character, `▁`. Used in conjunction with the Unigram algorithm (see [section 7](/course/chapter7/7)), it doesn't even require a pre-tokenization step, which is very useful for languages where the space character is not used (like Chinese or Japanese).\n\nThe other main feature of SentencePiece is *reversible tokenization*: since there is no special treatment of spaces, decoding the tokens is done simply by concatenating them and replacing the `_`s with spaces -- this results in the normalized text. As we saw earlier, the BERT tokenizer removes repeating spaces, so its tokenization is not reversible.\n\n## Algorithm overview[[algorithm-overview]]"
 list([{'entity_group': 'MISC', 'score': 0.43285987, 'word': '##ie', 'start': 12, 'end': 14}, {'entity_group': 'MISC', 'score': 0.98626965, 'word': 'Unicode', 'start': 269, 'end': 276}, {'entity_group': 'MISC', 'score': 0.7058019, 'word': 'Unig', 'start': 369, 'end': 373}, {'entity_group': 'ORG', 'score': 0.46285653, 'word': '##ram', 'start': 373, 'end': 376}, {'entity_group': 'MISC', 'score': 0.9633461, 'word': 'Chinese', 'start': 554, 'end': 561}, {'entity_group': 'MISC', 'score': 0.9925527, 'word': 'Japanese', 'start': 565, 'end': 573}, {'entity_group': 'MISC', 'score': 0.55124074, 'word': 'Sen', 'start': 603, 'end': 606}, {'entity_group': 'MISC', 'score': 0.44949478, 'word': '##iece', 'start': 612, 'end': 616}, {'entity_group': 'ORG', 'score': 0.70714253, 'word': 'BERT', 'start': 849, 'end': 853}])
 list([{'entity_group': 'MISC', 'score': 0.98626965, 'word': 'Unicode', 'start': 269, 'end': 276}, {'entity_group': 'MISC', 'score': 0.9633461, 'word': 'Chinese', 'start': 554, 'end': 561}, {'entity_group': 'MISC', 'score': 0.9925527, 'word': 'Japanese', 'start': 565, 'end': 573}])]
['846' '73.0' '10'
 "## Algorithm overview[[algorithm-overview]]\n\nIn the following sections, we'll dive into the three main subword tokenization algorithms: BPE (used by GPT-2 and others), WordPiece (used for example by BERT), and Unigram (used by T5 and others). Before we get started, here's a quick overview of how they each work. Don't hesitate to come back to this table after reading each of the next sections if it doesn't make sense to you yet."
 list([{'entity_group': 'ORG', 'score': 0.72692525, 'word': 'BPE', 'start': 136, 'end': 139}, {'entity_group': 'ORG', 'score': 0.84185594, 'word': 'GPT - 2', 'start': 149, 'end': 154}, {'entity_group': 'MISC', 'score': 0.6328268, 'word': 'WordP', 'start': 168, 'end': 173}, {'entity_group': 'ORG', 'score': 0.4549316, 'word': '##ie', 'start': 173, 'end': 175}, {'entity_group': 'MISC', 'score': 0.6671633, 'word': '##ce', 'start': 175, 'end': 177}, {'entity_group': 'ORG', 'score': 0.99111414, 'word': 'BERT', 'start': 199, 'end': 203}, {'entity_group': 'MISC', 'score': 0.64729494, 'word': 'Unig', 'start': 210, 'end': 214}, {'entity_group': 'ORG', 'score': 0.6103554, 'word': '##ram', 'start': 214, 'end': 217}, {'entity_group': 'ORG', 'score': 0.9822288, 'word': 'T5', 'start': 227, 'end': 229}])
 list([{'entity_group': 'ORG', 'score': 0.84185594, 'word': 'GPT - 2', 'start': 149, 'end': 154}, {'entity_group': 'ORG', 'score': 0.99111414, 'word': 'BERT', 'start': 199, 'end': 203}, {'entity_group': 'ORG', 'score': 0.9822288, 'word': 'T5', 'start': 227, 'end': 229}])]
['847' '73.0' '11'
 'Model | BPE | WordPiece | Unigram\n:----:|:---:|:---------:|:------:\nTraining | Starts from a small vocabulary and learns rules to merge tokens |  Starts from a small vocabulary and learns rules to merge tokens | Starts from a large vocabulary and learns rules to remove tokens\nTraining step | Merges the tokens corresponding to the most common pair | Merges the tokens corresponding to the pair with the best score based on the frequency of the pair, privileging pairs where each individual token is less frequent | Removes all the tokens in the vocabulary that will minimize the loss computed on the whole corpus\nLearns | Merge rules and a vocabulary | Just a vocabulary | A vocabulary with a score for each token'
 list([]) list([])]
['848' '73.0' '12'
 'Encoding | Splits a word into characters and applies the merges learned during training | Finds the longest subword starting from the beginning that is in the vocabulary, then does the same for the rest of the word | Finds the most likely split into tokens, using the scores learned during training'
 list([]) list([])]
['849' '73.0' '13' "Now let's dive into BPE!" list([]) list([])]
['850' '74.0' '0'
 '!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\nspecific language governing permissions and limitations under the License.\n-->\n\n# Map pools\n\nMap pools allow you to instantiate multiple versions of your environment on the backend, the enables higher \nthroughput with parallelization of interaction in simulations and embodied environments.\nUsing map pools is simple with 🤗 Simulate. First define a function that will generate your environment, we call each environment instance a "map".'
 list([{'entity_group': 'ORG', 'score': 0.99123573, 'word': 'HuggingFace Team', 'start': 22, 'end': 38}, {'entity_group': 'MISC', 'score': 0.9956285, 'word': 'Apache License', 'start': 81, 'end': 95}, {'entity_group': 'MISC', 'score': 0.51857233, 'word': '2', 'start': 105, 'end': 106}, {'entity_group': 'MISC', 'score': 0.9925565, 'word': 'License', 'start': 115, 'end': 122}, {'entity_group': 'MISC', 'score': 0.99141496, 'word': 'License', 'start': 182, 'end': 189}, {'entity_group': 'MISC', 'score': 0.98547965, 'word': 'License', 'start': 220, 'end': 227}, {'entity_group': 'ORG', 'score': 0.7064187, 'word': '##pache', 'start': 244, 'end': 249}, {'entity_group': 'MISC', 'score': 0.9810059, 'word': 'License', 'start': 366, 'end': 373}, {'entity_group': 'MISC', 'score': 0.985437, 'word': 'License', 'start': 491, 'end': 498}, {'entity_group': 'MISC', 'score': 0.98954993, 'word': 'License', 'start': 573, 'end': 580}, {'entity_group': 'MISC', 'score': 0.5208189, 'word': 'Si', 'start': 831, 'end': 833}])
 list([{'entity_group': 'ORG', 'score': 0.99123573, 'word': 'HuggingFace Team', 'start': 22, 'end': 38}, {'entity_group': 'MISC', 'score': 0.9956285, 'word': 'Apache License', 'start': 81, 'end': 95}, {'entity_group': 'MISC', 'score': 0.9925565, 'word': 'License', 'start': 115, 'end': 122}, {'entity_group': 'MISC', 'score': 0.99141496, 'word': 'License', 'start': 182, 'end': 189}, {'entity_group': 'MISC', 'score': 0.98547965, 'word': 'License', 'start': 220, 'end': 227}, {'entity_group': 'MISC', 'score': 0.9810059, 'word': 'License', 'start': 366, 'end': 373}, {'entity_group': 'MISC', 'score': 0.985437, 'word': 'License', 'start': 491, 'end': 498}, {'entity_group': 'MISC', 'score': 0.98954993, 'word': 'License', 'start': 573, 'end': 580}])]
['851' '74.0' '1'
 '```\ndef generate_map(index):\n    root = sm.Asset(name=f"root_{index}")\n    root += sm.Box(\n        name=f"floor_{index}",\n        position=[0, -0.05, 0],\n        scaling=[10, 0.1, 10],\n        material=sm.Material.BLUE,\n        with_collider=True,\n    )\n    root += sm.Box(\n        name=f"wall1_{index}",\n        position=[-1, 0.5, 0],\n        scaling=[0.1, 1, 5.1],\n        material=sm.Material.GRAY75,\n        with_collider=True,\n    )\n    root += sm.Box(\n        name=f"wall2_{index}",\n        position=[1, 0.5, 0],\n        scaling=[0.1, 1, 5.1],\n        material=sm.Material.GRAY75,\n        with_collider=True,\n    )\n    root += sm.Box(\n        name=f"wall3_{index}",\n        position=[0, 0.5, 4.5],\n        scaling=[5.9, 1, 0.1],\n        material=sm.Material.GRAY75,\n        with_collider=True,\n    )\n\n    # add actors, sensors, reward functions etc ...\n\n    return root'
 list([]) list([])]
['852' '74.0' '2'
 '```\n\nYou can then provide the `generate_map` method as an argument to the `sm.ParallelRLEnv` class, which will instantiate `n_maps`. \nTraining with a subset of the maps is possible using the `n_show` option. At each environment reset, it cycles through to the next map.\n\n[[autodoc]] ParallelRLEnv'
 list([{'entity_group': 'ORG', 'score': 0.54900116, 'word': '##RL', 'start': 291, 'end': 293}])
 list([])]
['853' '75.0' '0'
 '@gradio/imageeditor\n\n## 0.2.0\n\n### Features\n\n- [#6809](https://github.com/gradio-app/gradio/pull/6809) [`1401d99`](https://github.com/gradio-app/gradio/commit/1401d99ade46d87da75b5f5808a3354c49f1d1ea) - Fix `ImageEditor` interaction story.  Thanks [@hannahblair](https://github.com/hannahblair)!\n\n## 0.1.5\n\n### Fixes\n\n- [#6799](https://github.com/gradio-app/gradio/pull/6799) [`c352811`](https://github.com/gradio-app/gradio/commit/c352811f76d4126613ece0a584f8c552fdd8d1f6) - Adds docstrings for `gr.WaveformOptions`, `gr.Brush`, and `gr.Eraser`, fixes examples for `ImageEditor`, and allows individual images to be used as the initial `value` for `ImageEditor`.  Thanks [@abidlabs](https://github.com/abidlabs)!\n\n## 0.1.4\n\n### Patch Changes'
 list([{'entity_group': 'ORG', 'score': 0.9578381, 'word': 'ImageEditor', 'start': 208, 'end': 219}, {'entity_group': 'ORG', 'score': 0.73169005, 'word': 'WaveformOptions', 'start': 500, 'end': 515}, {'entity_group': 'ORG', 'score': 0.8598883, 'word': 'Brush', 'start': 522, 'end': 527}, {'entity_group': 'ORG', 'score': 0.93174803, 'word': 'ImageEditor', 'start': 567, 'end': 578}, {'entity_group': 'ORG', 'score': 0.9183117, 'word': 'ImageEditor', 'start': 649, 'end': 660}])
 list([{'entity_group': 'ORG', 'score': 0.9578381, 'word': 'ImageEditor', 'start': 208, 'end': 219}, {'entity_group': 'ORG', 'score': 0.8598883, 'word': 'Brush', 'start': 522, 'end': 527}, {'entity_group': 'ORG', 'score': 0.93174803, 'word': 'ImageEditor', 'start': 567, 'end': 578}, {'entity_group': 'ORG', 'score': 0.9183117, 'word': 'ImageEditor', 'start': 649, 'end': 660}])]
['854' '75.0' '1'
 '## 0.1.4\n\n### Patch Changes\n\n- Updated dependencies [[`5d51fbc`](https://github.com/gradio-app/gradio/commit/5d51fbce7826da840a2fd4940feb5d9ad6f1bc5a), [`34f9431`](https://github.com/gradio-app/gradio/commit/34f943101bf7dd6b8a8974a6131c1ed7c4a0dac0)]:\n  - @gradio/upload@0.5.4\n  - @gradio/client@0.9.1\n  - @gradio/image@0.5.1\n\n## 0.1.3\n\n### Patch Changes'
 list([]) list([])]
['855' '75.0' '2'
 '- Updated dependencies [[`6a9151d`](https://github.com/gradio-app/gradio/commit/6a9151d5c9432c724098da7d88a539aaaf5ffe88), [`21cfb0a`](https://github.com/gradio-app/gradio/commit/21cfb0acc309bb1a392f4d8a8e42f6be864c5978), [`d76bcaa`](https://github.com/gradio-app/gradio/commit/d76bcaaaf0734aaf49a680f94ea9d4d22a602e70), [`67ddd40`](https://github.com/gradio-app/gradio/commit/67ddd40b4b70d3a37cb1637c33620f8d197dbee0), [`053bec9`](https://github.com/gradio-app/gradio/commit/053bec98be1127e083414024e02cf0bebb0b5142), [`bdf81fe`](https://github.com/gradio-app/gradio/commit/bdf81fead86e1d5a29e6b036f1fff677f6480e6b), [`4d1cbbc`](https://github.com/gradio-app/gradio/commit/4d1cbbcf30833ef1de2d2d2710c7492a379a9a00), [`5177132`](https://github.com/gradio-app/gradio/commit/5177132d718c77f6d47869b4334afae6380394cb)]:\n  - @gradio/image@0.5.0\n  - @gradio/upload@0.5.3\n  - @gradio/client@0.9.0\n  - @gradio/wasm@0.4.0\n  - @gradio/icons@0.3.2\n  - @gradio/atoms@0.4.0\n  - @gradio/statustracker@0.4.2'
 list([{'entity_group': 'ORG', 'score': 0.5477564, 'word': '##ith', 'start': 144, 'end': 147}, {'entity_group': 'ORG', 'score': 0.5098663, 'word': 'com', 'start': 150, 'end': 153}, {'entity_group': 'ORG', 'score': 0.65859497, 'word': '##ith', 'start': 342, 'end': 345}, {'entity_group': 'ORG', 'score': 0.62970954, 'word': '##ith', 'start': 540, 'end': 543}])
 list([])]
['856' '75.0' '3'
 '## 0.1.2\n\n### Patch Changes\n\n- Updated dependencies [[`b639e04`](https://github.com/gradio-app/gradio/commit/b639e040741e6c0d9104271c81415d7befbd8cf3), [`206af31`](https://github.com/gradio-app/gradio/commit/206af31d7c1a31013364a44e9b40cf8df304ba50)]:\n  - @gradio/image@0.4.2\n  - @gradio/icons@0.3.1\n  - @gradio/atoms@0.3.1\n  - @gradio/statustracker@0.4.1\n  - @gradio/upload@0.5.2\n\n## 0.1.1\n\n### Patch Changes\n\n- Updated dependencies [[`71f1a1f99`](https://github.com/gradio-app/gradio/commit/71f1a1f9931489d465c2c1302a5c8d768a3cd23a)]:\n  - @gradio/client@0.8.2\n  - @gradio/image@0.4.1\n  - @gradio/upload@0.5.1\n\n## 0.1.0\n\n### Highlights\n\n#### New `ImageEditor` component ([#6169](https://github.com/gradio-app/gradio/pull/6169) [`9caddc17b`](https://github.com/gradio-app/gradio/commit/9caddc17b1dea8da1af8ba724c6a5eab04ce0ed8))\n\nA brand new component, completely separate from `Image` that provides simple editing capabilities.'
 list([{'entity_group': 'ORG', 'score': 0.75404924, 'word': 'ImageEdit', 'start': 648, 'end': 657}])
 list([])]
['857' '75.0' '4'
 'A brand new component, completely separate from `Image` that provides simple editing capabilities.\n\n- Set background images from file uploads, webcam, or just paste!\n- Crop images with an improved cropping UI. App authors can event set specific crop size, or crop ratios (`1:1`, etc)\n- Paint on top of any image (or no image) and erase any mistakes!\n- The ImageEditor supports layers, confining draw and erase actions to that layer.\n- More flexible access to data. The image component returns a composite image representing the final state of the canvas as well as providing the background and all layers as individual images.\n- Fully customisable. All features can be enabled and disabled. Even the brush color swatches can be customised.\n\n<video src="https://user-images.githubusercontent.com/12937446/284027169-31188926-fd16-4a1c-8718-998e7aae4695.mp4" autoplay muted></video>\n\n```py'
 list([{'entity_group': 'MISC', 'score': 0.51440716, 'word': 'Image', 'start': 49, 'end': 54}, {'entity_group': 'ORG', 'score': 0.5371757, 'word': '`', 'start': 54, 'end': 55}, {'entity_group': 'ORG', 'score': 0.90428627, 'word': 'ImageEditor', 'start': 356, 'end': 367}])
 list([{'entity_group': 'ORG', 'score': 0.90428627, 'word': 'ImageEditor', 'start': 356, 'end': 367}])]
['858' '75.0' '5'
 '```py\n\ndef fn(im):\n    im["composite"] # the full canvas\n    im["background"] # the background image\n    im["layers"] # a list of individual layers\n\n\nim = gr.ImageEditor(\n    # decide which sources you\'d like to accept\n    sources=["upload", "webcam", "clipboard"],\n    # set a cropsize constraint, can either be a ratio or a concrete [width, height]\n    crop_size="1:1",\n    # enable crop (or disable it)\n    transforms=["crop"],\n    # customise the brush\n    brush=Brush(\n      default_size="25", # or leave it as \'auto\'\n      color_mode="fixed", # \'fixed\' hides the user swatches and colorpicker, \'defaults\' shows it\n      default_color="hotpink", # html names are supported\n      colors=[\n        "rgba(0, 150, 150, 1)", # rgb(a)\n        "#fff", # hex rgb\n        "hsl(360, 120, 120)" # in fact any valid colorstring\n      ]\n    ),\n    brush=Eraser(default_size="25")\n)'
 list([{'entity_group': 'ORG', 'score': 0.5339448, 'word': 'ImageE', 'start': 158, 'end': 164}, {'entity_group': 'ORG', 'score': 0.84361947, 'word': 'Brush', 'start': 467, 'end': 472}])
 list([{'entity_group': 'ORG', 'score': 0.84361947, 'word': 'Brush', 'start': 467, 'end': 472}])]
['859' '75.0' '6'
 '```\n\nThanks [@pngwn](https://github.com/pngwn)!\n\n### Fixes\n\n- [#6502](https://github.com/gradio-app/gradio/pull/6502) [`070f71c93`](https://github.com/gradio-app/gradio/commit/070f71c933d846ce8e2fe11cdd9bc0f3f897f29f) - Ensure image editor crop and draw cursor works as expected when the scroll position changes. Thanks [@pngwn](https://github.com/pngwn)!\n\n# @gradio/image'
 list([{'entity_group': 'ORG', 'score': 0.52195376, 'word': '##ith', 'start': 79, 'end': 82}])
 list([])]
['860' '76.0' '0'
 'How to contribute to simulate?\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.0-4baaaa.svg)](CODE_OF_CONDUCT.md)\n\nSimulation environments is an open source project, so all contributions and suggestions are welcome.\n\nYou can contribute in many different ways: giving ideas, answering questions, reporting bugs, proposing enhancements, \nimproving the documentation, fixing bugs,...\n\nMany thanks in advance to every contributor.\n\nIn order to facilitate healthy, constructive behavior in an open and inclusive community, we all respect and abide by \nour [code of conduct](CODE_OF_CONDUCT.md).\n\n## How to work on an open Issue?\nYou have the list of open Issues at: https://github.com/huggingface/simulate/issues\n\nSome of them may have the label `help wanted`: that means that any contributor is welcomed!\n\nIf you would like to work on any of the open Issues:'
 list([]) list([])]
['861' '76.0' '1'
 "If you would like to work on any of the open Issues:\n\n1. Make sure it is not already assigned to someone else. You have the assignee (if any) on the top of the right column of the Issue page.\n\n2. You can self-assign it by commenting on the Issue page with one of the keywords: `#take` or `#self-assign`.\n\n3. Work on your self-assigned issue and eventually create a Pull Request.\n\n## How to create a Pull Request?\n1. Fork the [repository](https://github.com/huggingface/simulate) by clicking on the 'Fork' button on the repository's page. This creates a copy of the code under your GitHub user account.\n\n2. Clone your fork to your local disk, and add the base repository as a remote:\n\n\t```bash\n\tgit clone git@github.com:<your Github handle>/simulate.git\n\tcd simulate\n\tgit remote add upstream https://github.com/huggingface/simulate.git"
 list([{'entity_group': 'MISC', 'score': 0.66478574, 'word': 'Issues', 'start': 45, 'end': 51}, {'entity_group': 'ORG', 'score': 0.73909664, 'word': 'GitHub', 'start': 581, 'end': 587}, {'entity_group': 'MISC', 'score': 0.81657887, 'word': 'Gith', 'start': 725, 'end': 729}, {'entity_group': 'ORG', 'score': 0.520677, 'word': '##ub', 'start': 729, 'end': 731}])
 list([{'entity_group': 'MISC', 'score': 0.81657887, 'word': 'Gith', 'start': 725, 'end': 729}])]
['862' '76.0' '2'
 '```\n\n3. Create a new branch to hold your development changes:\n\n\t```bash\n\tgit checkout -b a-descriptive-name-for-my-changes\n\t```\n\n\t**do not** work on the `main` branch.\n\n4. Set up a development environment by running the following command in a virtual environment:\n\n\t```bash\n\tpip install -e ".[dev]"\n\t```\n\n   (If simulate was already installed in the virtual environment, remove\n   it with `pip uninstall simulate` before reinstalling it in editable\n   mode with the `-e` flag.)\n\n5. Develop the features on your branch. If you want to add a dataset see more in-detail instructions in the section [*How to add a dataset*](#how-to-add-a-dataset). \n\n6. Format your code. Run black and isort so that your newly added files look nice with the following command:\n\n\t```bash\n\tmake style\n\t```\n\n7. Once you\'re happy with your dataset script file, add your changes and make a commit to record your changes locally:\n\n\t```bash\n\tgit add simulate/<your_dataset_name>\n\tgit commit'
 list([]) list([])]
['863' '76.0' '3'
 '```\n\n\tIt is a good idea to sync your copy of the code with the original\n\trepository regularly. This way you can quickly account for changes:\n\n\t```bash\n\tgit fetch upstream\n\tgit rebase upstream/main\n    ```\n\n   Push the changes to your account using:\n\n   ```bash\n   git push -u origin a-descriptive-name-for-my-changes\n   ```\n\n8. Once you are satisfied, go the webpage of your fork on GitHub. Click on "Pull request" to send your to the project maintainers for review.\n\n## Code of conduct\n\nThis project adheres to the HuggingFace [code of conduct](CODE_OF_CONDUCT.md). \nBy participating, you are expected to uphold this code.'
 list([{'entity_group': 'ORG', 'score': 0.53754, 'word': 'GitHub', 'start': 383, 'end': 389}, {'entity_group': 'MISC', 'score': 0.7966547, 'word': 'Hugging', 'start': 516, 'end': 523}, {'entity_group': 'ORG', 'score': 0.45124298, 'word': '##F', 'start': 523, 'end': 524}, {'entity_group': 'MISC', 'score': 0.87136334, 'word': '##ace', 'start': 524, 'end': 527}])
 list([{'entity_group': 'MISC', 'score': 0.87136334, 'word': '##ace', 'start': 524, 'end': 527}])]
['864' '77.0' '0'
 'Gradio Demo: chatinterface_system_prompt\n\n\n```\n!pip install -q gradio \n```\n\n\n```\nimport gradio as gr\nimport time\n\ndef echo(message, history, system_prompt, tokens):\n    response = f"System prompt: {system_prompt}\\n Message: {message}."\n    for i in range(min(len(response), int(tokens))):\n        time.sleep(0.05)\n        yield response[: i+1]\n\ndemo = gr.ChatInterface(echo, \n                        additional_inputs=[\n                            gr.Textbox("You are helpful AI.", label="System Prompt"), \n                            gr.Slider(10, 100)\n                        ]\n                       )\n\nif __name__ == "__main__":\n    demo.queue().launch()\n```'
 list([]) list([])]
['865' '78.0' '0'
 "CSP-ResNeXt\n\n**CSPResNeXt** is a convolutional neural network where we apply the Cross Stage Partial Network (CSPNet) approach to [ResNeXt](https://paperswithcode.com/method/resnext). The CSPNet partitions the feature map of the base layer into two parts and then merges them through a cross-stage hierarchy. The use of a split and merge strategy allows for more gradient flow through the network.\n\n## How do I use this model on an image?\n\nTo load a pretrained model:\n\n```py\n>>> import timm\n>>> model = timm.create_model('cspresnext50', pretrained=True)\n>>> model.eval()"
 list([{'entity_group': 'ORG', 'score': 0.7988208, 'word': 'CS', 'start': 0, 'end': 2}, {'entity_group': 'ORG', 'score': 0.6743746, 'word': 'Re', 'start': 4, 'end': 6}, {'entity_group': 'ORG', 'score': 0.6986756, 'word': '##N', 'start': 7, 'end': 8}, {'entity_group': 'ORG', 'score': 0.66438746, 'word': 'CSPR', 'start': 15, 'end': 19}, {'entity_group': 'ORG', 'score': 0.61916524, 'word': '##N', 'start': 21, 'end': 22}, {'entity_group': 'MISC', 'score': 0.93436396, 'word': 'Cross Stage', 'start': 81, 'end': 92}, {'entity_group': 'ORG', 'score': 0.46287656, 'word': 'Part', 'start': 93, 'end': 97}, {'entity_group': 'MISC', 'score': 0.49735522, 'word': 'Network', 'start': 101, 'end': 108}, {'entity_group': 'ORG', 'score': 0.8191047, 'word': 'CSPNet', 'start': 110, 'end': 116}, {'entity_group': 'MISC', 'score': 0.31450963, 'word': 'Re', 'start': 131, 'end': 133}, {'entity_group': 'ORG', 'score': 0.5234187, 'word': '##N', 'start': 134, 'end': 135}, {'entity_group': 'ORG', 'score': 0.9918749, 'word': 'CSPNet', 'start': 188, 'end': 194}])
 list([{'entity_group': 'MISC', 'score': 0.93436396, 'word': 'Cross Stage', 'start': 81, 'end': 92}, {'entity_group': 'ORG', 'score': 0.8191047, 'word': 'CSPNet', 'start': 110, 'end': 116}, {'entity_group': 'ORG', 'score': 0.9918749, 'word': 'CSPNet', 'start': 188, 'end': 194}])]
['866' '78.0' '1'
 '```\n\nTo load and preprocess the image:\n\n```py \n>>> import urllib\n>>> from PIL import Image\n>>> from timm.data import resolve_data_config\n>>> from timm.data.transforms_factory import create_transform\n\n>>> config = resolve_data_config({}, model=model)\n>>> transform = create_transform(**config)\n\n>>> url, filename = ("https://github.com/pytorch/hub/raw/master/images/dog.jpg", "dog.jpg")\n>>> urllib.request.urlretrieve(url, filename)\n>>> img = Image.open(filename).convert(\'RGB\')\n>>> tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n```\n\nTo get the model predictions:\n\n```py\n>>> import torch\n>>> with torch.no_grad():\n...     out = model(tensor)\n>>> probabilities = torch.nn.functional.softmax(out[0], dim=0)\n>>> print(probabilities.shape)\n>>> # prints: torch.Size([1000])'
 list([{'entity_group': 'ORG', 'score': 0.8820946, 'word': 'PIL', 'start': 74, 'end': 77}])
 list([{'entity_group': 'ORG', 'score': 0.8820946, 'word': 'PIL', 'start': 74, 'end': 77}])]
['867' '78.0' '2'
 '```\n\nTo get the top-5 predictions class names:\n\n```py\n>>> # Get imagenet class mappings\n>>> url, filename = ("https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt", "imagenet_classes.txt")\n>>> urllib.request.urlretrieve(url, filename) \n>>> with open("imagenet_classes.txt", "r") as f:\n...     categories = [s.strip() for s in f.readlines()]\n\n>>> # Print top categories per image\n>>> top5_prob, top5_catid = torch.topk(probabilities, 5)\n>>> for i in range(top5_prob.size(0)):\n...     print(categories[top5_catid[i]], top5_prob[i].item())\n>>> # prints class names and probabilities like:\n>>> # [(\'Samoyed\', 0.6425196528434753), (\'Pomeranian\', 0.04062102362513542), (\'keeshond\', 0.03186424449086189), (\'white wolf\', 0.01739676296710968), (\'Eskimo dog\', 0.011717947199940681)]'
 list([{'entity_group': 'ORG', 'score': 0.45751625, 'word': '##yt', 'start': 145, 'end': 147}, {'entity_group': 'MISC', 'score': 0.66602254, 'word': 'Samoyed', 'start': 616, 'end': 623}, {'entity_group': 'MISC', 'score': 0.95495075, 'word': 'Pomeranian', 'start': 649, 'end': 659}, {'entity_group': 'MISC', 'score': 0.9684437, 'word': 'Eskimo', 'start': 758, 'end': 764}])
 list([{'entity_group': 'MISC', 'score': 0.95495075, 'word': 'Pomeranian', 'start': 649, 'end': 659}, {'entity_group': 'MISC', 'score': 0.9684437, 'word': 'Eskimo', 'start': 758, 'end': 764}])]
['868' '78.0' '3'
 "```\n\nReplace the model name with the variant you want to use, e.g. `cspresnext50`. You can find the IDs in the model summaries at the top of this page.\n\nTo extract image features with this model, follow the [timm feature extraction examples](../feature_extraction), just change the name of the model you want to use.\n\n## How do I finetune this model?\n\nYou can finetune any of the pre-trained models just by changing the classifier (the last layer).\n\n```py\n>>> model = timm.create_model('cspresnext50', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)"
 list([]) list([])]
['869' '78.0' '4'
 "```\nTo finetune on your own dataset, you have to write a training loop or adapt [timm's training\nscript](https://github.com/rwightman/pytorch-image-models/blob/master/train.py) to use your dataset.\n\n## How do I train this model?\n\nYou can follow the [timm recipe scripts](../scripts) for training a new model afresh.\n\n## Citation\n\n```BibTeX\n@misc{wang2019cspnet,\n      title={CSPNet: A New Backbone that can Enhance Learning Capability of CNN}, \n      author={Chien-Yao Wang and Hong-Yuan Mark Liao and I-Hau Yeh and Yueh-Hua Wu and Ping-Yang Chen and Jun-Wei Hsieh},\n      year={2019},\n      eprint={1911.11929},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}"
 list([{'entity_group': 'ORG', 'score': 0.7076284, 'word': 'CSPNet', 'start': 375, 'end': 381}, {'entity_group': 'MISC', 'score': 0.45767725, 'word': 'New', 'start': 385, 'end': 388}, {'entity_group': 'ORG', 'score': 0.99402845, 'word': 'CNN', 'start': 438, 'end': 441}, {'entity_group': 'PER', 'score': 0.9785573, 'word': 'Chien - Yao Wang', 'start': 459, 'end': 473}, {'entity_group': 'PER', 'score': 0.9921623, 'word': 'Hong', 'start': 478, 'end': 482}, {'entity_group': 'PER', 'score': 0.9908639, 'word': 'Yuan Mark Liao', 'start': 483, 'end': 497}, {'entity_group': 'PER', 'score': 0.9942525, 'word': 'I', 'start': 502, 'end': 503}, {'entity_group': 'PER', 'score': 0.992561, 'word': 'Hau Yeh', 'start': 504, 'end': 511}, {'entity_group': 'PER', 'score': 0.9155469, 'word': 'Yueh - Hua Wu', 'start': 516, 'end': 527}, {'entity_group': 'PER', 'score': 0.99869627, 'word': 'Ping', 'start': 532, 'end': 536}, {'entity_group': 'PER', 'score': 0.99926746, 'word': 'Yang Chen', 'start': 537, 'end': 546}, {'entity_group': 'PER', 'score': 0.9981178, 'word': 'Jun', 'start': 551, 'end': 554}, {'entity_group': 'PER', 'score': 0.98859304, 'word': 'Wei Hsieh', 'start': 555, 'end': 564}])
 list([{'entity_group': 'ORG', 'score': 0.99402845, 'word': 'CNN', 'start': 438, 'end': 441}, {'entity_group': 'PER', 'score': 0.9785573, 'word': 'Chien - Yao Wang', 'start': 459, 'end': 473}, {'entity_group': 'PER', 'score': 0.9921623, 'word': 'Hong', 'start': 478, 'end': 482}, {'entity_group': 'PER', 'score': 0.9908639, 'word': 'Yuan Mark Liao', 'start': 483, 'end': 497}, {'entity_group': 'PER', 'score': 0.9942525, 'word': 'I', 'start': 502, 'end': 503}, {'entity_group': 'PER', 'score': 0.992561, 'word': 'Hau Yeh', 'start': 504, 'end': 511}, {'entity_group': 'PER', 'score': 0.9155469, 'word': 'Yueh - Hua Wu', 'start': 516, 'end': 527}, {'entity_group': 'PER', 'score': 0.99869627, 'word': 'Ping', 'start': 532, 'end': 536}, {'entity_group': 'PER', 'score': 0.99926746, 'word': 'Yang Chen', 'start': 537, 'end': 546}, {'entity_group': 'PER', 'score': 0.9981178, 'word': 'Jun', 'start': 551, 'end': 554}, {'entity_group': 'PER', 'score': 0.98859304, 'word': 'Wei Hsieh', 'start': 555, 'end': 564}])]
['870' '78.0' '5' '```'
 list([{'entity_group': 'PER', 'score': 0.4322449, 'word': '`', 'start': 0, 'end': 1}, {'entity_group': 'PER', 'score': 0.43227673, 'word': '`', 'start': 1, 'end': 2}, {'entity_group': 'PER', 'score': 0.43234685, 'word': '`', 'start': 2, 'end': 3}])
 list([])]
['871' '78.0' '6'
 "<!--\nType: model-index\nCollections:\n- Name: CSP ResNeXt\n  Paper:\n    Title: 'CSPNet: A New Backbone that can Enhance Learning Capability of CNN'\n    URL: https://paperswithcode.com/paper/cspnet-a-new-backbone-that-can-enhance\nModels:\n- Name: cspresnext50\n  In Collection: CSP ResNeXt\n  Metadata:\n    FLOPs: 3962945536\n    Parameters: 20570000\n    File Size: 82562887\n    Architecture:\n    - 1x1 Convolution\n    - Batch Normalization\n    - Convolution\n    - Global Average Pooling\n    - Grouped Convolution\n    - Max Pooling\n    - ReLU\n    - ResNeXt Block\n    - Residual Connection\n    - Softmax\n    Tasks:\n    - Image Classification\n    Training Techniques:\n    - Label Smoothing\n    - Polynomial Learning Rate Decay\n    - SGD with Momentum\n    - Weight Decay\n    Training Data:\n    - ImageNet\n    Training Resources: 1x GPU\n    ID: cspresnext50\n    LR: 0.1\n    Layers: 50\n    Crop Pct: '0.875'\n    Momentum: 0.9\n    Batch Size: 128\n    Image Size: '224'\n    Weight Decay: 0.005"
 list([{'entity_group': 'ORG', 'score': 0.78326875, 'word': 'CS', 'start': 44, 'end': 46}, {'entity_group': 'ORG', 'score': 0.69881153, 'word': 'CSPNet', 'start': 77, 'end': 83}, {'entity_group': 'ORG', 'score': 0.99284756, 'word': 'CNN', 'start': 140, 'end': 143}, {'entity_group': 'ORG', 'score': 0.5911892, 'word': 'CS', 'start': 272, 'end': 274}, {'entity_group': 'ORG', 'score': 0.8897302, 'word': 'ImageNet', 'start': 785, 'end': 793}])
 list([{'entity_group': 'ORG', 'score': 0.99284756, 'word': 'CNN', 'start': 140, 'end': 143}, {'entity_group': 'ORG', 'score': 0.8897302, 'word': 'ImageNet', 'start': 785, 'end': 793}])]
['872' '78.0' '7'
 "Momentum: 0.9\n    Batch Size: 128\n    Image Size: '224'\n    Weight Decay: 0.005\n    Interpolation: bilinear\n    Training Steps: 8000000\n  Code: https://github.com/rwightman/pytorch-image-models/blob/d8e69206be253892b2956341fea09fdebfaae4e3/timm/models/cspnet.py#L430\n  Weights: https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/cspresnext50_ra_224-648b4713.pth\n  Results:\n  - Task: Image Classification\n    Dataset: ImageNet\n    Metrics:\n      Top 1 Accuracy: 80.05%\n      Top 5 Accuracy: 94.94%\n-->"
 list([{'entity_group': 'ORG', 'score': 0.5151666, 'word': 'ImageNet', 'start': 447, 'end': 455}])
 list([])]
['873' '79.0' '0'
 '!--Copyright 2023 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\nspecific language governing permissions and limitations under the License.\n-->\n\n# MultiDiffusion\n\n[MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation](https://huggingface.co/papers/2302.08113) is by Omer Bar-Tal, Lior Yariv, Yaron Lipman, and Tali Dekel.\n\nThe abstract from the paper is:'
 list([{'entity_group': 'ORG', 'score': 0.99233913, 'word': 'HuggingFace Team', 'start': 22, 'end': 38}, {'entity_group': 'MISC', 'score': 0.9971407, 'word': 'Apache License', 'start': 81, 'end': 95}, {'entity_group': 'MISC', 'score': 0.60292006, 'word': '2', 'start': 105, 'end': 106}, {'entity_group': 'MISC', 'score': 0.9943487, 'word': 'License', 'start': 115, 'end': 122}, {'entity_group': 'MISC', 'score': 0.9931657, 'word': 'License', 'start': 182, 'end': 189}, {'entity_group': 'MISC', 'score': 0.9846978, 'word': 'License', 'start': 220, 'end': 227}, {'entity_group': 'ORG', 'score': 0.6552168, 'word': '##pache', 'start': 244, 'end': 249}, {'entity_group': 'MISC', 'score': 0.9816051, 'word': 'License', 'start': 366, 'end': 373}, {'entity_group': 'MISC', 'score': 0.98901784, 'word': 'License', 'start': 491, 'end': 498}, {'entity_group': 'MISC', 'score': 0.99171185, 'word': 'License', 'start': 573, 'end': 580}, {'entity_group': 'PER', 'score': 0.96926117, 'word': 'Omer Bar - Tal', 'start': 726, 'end': 738}, {'entity_group': 'PER', 'score': 0.9836149, 'word': 'Lior Yariv', 'start': 740, 'end': 750}, {'entity_group': 'PER', 'score': 0.99725693, 'word': 'Yaron Lipman', 'start': 752, 'end': 764}, {'entity_group': 'PER', 'score': 0.9979212, 'word': 'Tali Dekel', 'start': 770, 'end': 780}])
 list([{'entity_group': 'ORG', 'score': 0.99233913, 'word': 'HuggingFace Team', 'start': 22, 'end': 38}, {'entity_group': 'MISC', 'score': 0.9971407, 'word': 'Apache License', 'start': 81, 'end': 95}, {'entity_group': 'MISC', 'score': 0.9943487, 'word': 'License', 'start': 115, 'end': 122}, {'entity_group': 'MISC', 'score': 0.9931657, 'word': 'License', 'start': 182, 'end': 189}, {'entity_group': 'MISC', 'score': 0.9846978, 'word': 'License', 'start': 220, 'end': 227}, {'entity_group': 'MISC', 'score': 0.9816051, 'word': 'License', 'start': 366, 'end': 373}, {'entity_group': 'MISC', 'score': 0.98901784, 'word': 'License', 'start': 491, 'end': 498}, {'entity_group': 'MISC', 'score': 0.99171185, 'word': 'License', 'start': 573, 'end': 580}, {'entity_group': 'PER', 'score': 0.96926117, 'word': 'Omer Bar - Tal', 'start': 726, 'end': 738}, {'entity_group': 'PER', 'score': 0.9836149, 'word': 'Lior Yariv', 'start': 740, 'end': 750}, {'entity_group': 'PER', 'score': 0.99725693, 'word': 'Yaron Lipman', 'start': 752, 'end': 764}, {'entity_group': 'PER', 'score': 0.9979212, 'word': 'Tali Dekel', 'start': 770, 'end': 780}])]
['874' '79.0' '1'
 '*Recent advances in text-to-image generation with diffusion models present transformative capabilities in image quality. However, user controllability of the generated image, and fast adaptation to new tasks still remains an open challenge, currently mostly addressed by costly and long re-training and fine-tuning or ad-hoc adaptations to specific image generation tasks. In this work, we present MultiDiffusion, a unified framework that enables versatile and controllable image generation, using a pre-trained text-to-image diffusion model, without any further training or finetuning. At the center of our approach is a new generation process, based on an optimization task that binds together multiple diffusion generation processes with a shared set of parameters or constraints. We show that MultiDiffusion can be readily applied to generate high quality and diverse images that adhere to user-provided controls, such as desired aspect ratio (e.g., panorama), and spatial guiding signals,'
 list([{'entity_group': 'MISC', 'score': 0.7719743, 'word': 'MultiD', 'start': 398, 'end': 404}, {'entity_group': 'MISC', 'score': 0.75798535, 'word': 'MultiD', 'start': 797, 'end': 803}])
 list([])]
['875' '79.0' '2'
 'user-provided controls, such as desired aspect ratio (e.g., panorama), and spatial guiding signals, ranging from tight segmentation masks to bounding boxes.*'
 list([]) list([])]
['876' '79.0' '3'
 "You can find additional information about MultiDiffusion on the [project page](https://multidiffusion.github.io/), [original codebase](https://github.com/omerbt/MultiDiffusion), and try it out in a [demo](https://huggingface.co/spaces/weizmannscience/MultiDiffusion).\n\n## Tips\n\nWhile calling [`StableDiffusionPanoramaPipeline`], it's possible to specify the `view_batch_size` parameter to be > 1.\nFor some GPUs with high performance, this can speedup the generation process and increase VRAM usage.\n\nTo generate panorama-like images make sure you pass the width parameter accordingly. We recommend a width value of 2048 which is the default."
 list([{'entity_group': 'ORG', 'score': 0.47617385, 'word': 'Multi', 'start': 42, 'end': 47}, {'entity_group': 'MISC', 'score': 0.3786124, 'word': '##D', 'start': 47, 'end': 48}, {'entity_group': 'ORG', 'score': 0.5263464, 'word': '##usion', 'start': 51, 'end': 56}, {'entity_group': 'ORG', 'score': 0.5273648, 'word': 'MultiDiffusion', 'start': 161, 'end': 175}, {'entity_group': 'ORG', 'score': 0.4422691, 'word': 'Multi', 'start': 251, 'end': 256}, {'entity_group': 'ORG', 'score': 0.55108553, 'word': '##usion', 'start': 260, 'end': 265}])
 list([])]
['877' '79.0' '4'
 'Circular padding is applied to ensure there are no stitching artifacts when working with panoramas to ensure a seamless transition from the rightmost part to the leftmost part. By enabling circular padding (set `circular_padding=True`), the operation applies additional crops after the rightmost point of the image, allowing the model to "see” the transition from the rightmost part to the leftmost part. This helps maintain visual consistency in a 360-degree sense and creates a proper “panorama” that can be viewed using 360-degree panorama viewers. When decoding latents in Stable Diffusion, circular padding is applied to ensure that the decoded latents match in the RGB space.\n\nFor example, without circular padding, there is a stitching artifact (default):\n![img](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/indoor_%20no_circular_padding.png)'
 list([{'entity_group': 'MISC', 'score': 0.46492216, 'word': 'St', 'start': 577, 'end': 579}, {'entity_group': 'MISC', 'score': 0.5920741, 'word': 'Di', 'start': 584, 'end': 586}, {'entity_group': 'MISC', 'score': 0.8659734, 'word': 'R', 'start': 671, 'end': 672}])
 list([{'entity_group': 'MISC', 'score': 0.8659734, 'word': 'R', 'start': 671, 'end': 672}])]
['878' '79.0' '5'
 'But with circular padding, the right and the left parts are matching (`circular_padding=True`):\n![img](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/indoor_%20circular_padding.png)\n\n<Tip>\n\nMake sure to check out the Schedulers [guide](../../using-diffusers/schedulers) to learn how to explore the tradeoff between scheduler speed and quality, and see the [reuse components across pipelines](../../using-diffusers/loading#reuse-components-across-pipelines) section to learn how to efficiently load the same components into multiple pipelines.\n\n</Tip>\n\n## StableDiffusionPanoramaPipeline\n[[autodoc]] StableDiffusionPanoramaPipeline\n\t- __call__\n\t- all\n\n## StableDiffusionPipelineOutput\n[[autodoc]] pipelines.stable_diffusion.StableDiffusionPipelineOutput'
 list([]) list([])]
['879' '80.0' '0'
 '!--Copyright 2022 The HuggingFace Team. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with\nthe License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on\nan "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\nspecific language governing permissions and limitations under the License.\n-->\n\n# Actors\n\n[[autodoc]] SimpleActor\n\n[[autodoc]] EgocentricCameraActor\n\n\nUnder construction 🚧.'
 list([{'entity_group': 'ORG', 'score': 0.9902598, 'word': 'HuggingFace Team', 'start': 22, 'end': 38}, {'entity_group': 'MISC', 'score': 0.9970906, 'word': 'Apache License', 'start': 81, 'end': 95}, {'entity_group': 'MISC', 'score': 0.58884233, 'word': '2', 'start': 105, 'end': 106}, {'entity_group': 'MISC', 'score': 0.99457574, 'word': 'License', 'start': 115, 'end': 122}, {'entity_group': 'MISC', 'score': 0.9938478, 'word': 'License', 'start': 182, 'end': 189}, {'entity_group': 'MISC', 'score': 0.98639977, 'word': 'License', 'start': 220, 'end': 227}, {'entity_group': 'ORG', 'score': 0.67594194, 'word': '##pache', 'start': 244, 'end': 249}, {'entity_group': 'MISC', 'score': 0.9862964, 'word': 'License', 'start': 366, 'end': 373}, {'entity_group': 'MISC', 'score': 0.9908222, 'word': 'License', 'start': 491, 'end': 498}, {'entity_group': 'MISC', 'score': 0.99183756, 'word': 'License', 'start': 573, 'end': 580}])
 list([{'entity_group': 'ORG', 'score': 0.9902598, 'word': 'HuggingFace Team', 'start': 22, 'end': 38}, {'entity_group': 'MISC', 'score': 0.9970906, 'word': 'Apache License', 'start': 81, 'end': 95}, {'entity_group': 'MISC', 'score': 0.99457574, 'word': 'License', 'start': 115, 'end': 122}, {'entity_group': 'MISC', 'score': 0.9938478, 'word': 'License', 'start': 182, 'end': 189}, {'entity_group': 'MISC', 'score': 0.98639977, 'word': 'License', 'start': 220, 'end': 227}, {'entity_group': 'MISC', 'score': 0.9862964, 'word': 'License', 'start': 366, 'end': 373}, {'entity_group': 'MISC', 'score': 0.9908222, 'word': 'License', 'start': 491, 'end': 498}, {'entity_group': 'MISC', 'score': 0.99183756, 'word': 'License', 'start': 573, 'end': 580}])]
['880' '81.0' '0'
 'ow to preprocess pairs of sentences? We have seen how to tokenize single sentences and batch them together in the "Batching inputs together" video. If this code look unfamiliar to you, be sure to check that video again! Here we will focus on tasks that classify pairs of sentences. For instance, we may want to classify whether two texts are paraphrases or not. Here is an example taken from the Quora Question Pairs dataset, which focuses on identifying duplicate questions. In the first pair, the two questions are duplicates; in the second, they are not. Another pair classification problem is when we want to know if two sentences are logically related or not (a problem called Natural Language Inference or NLI). In this example taken from the MultiNLI dataset, we have a pair of sentences for each possible label: contradiction, neutral or entailment (which is a fancy way of saying the first sentence implies the second). So classifying pairs of sentences is a problem worth studying. In fact,'
 list([{'entity_group': 'MISC', 'score': 0.7463456, 'word': 'Q', 'start': 396, 'end': 397}, {'entity_group': 'ORG', 'score': 0.40426505, 'word': '##uora', 'start': 397, 'end': 401}, {'entity_group': 'MISC', 'score': 0.70471334, 'word': 'Pairs', 'start': 411, 'end': 416}, {'entity_group': 'MISC', 'score': 0.99239606, 'word': 'Natural Language Inference', 'start': 682, 'end': 708}, {'entity_group': 'MISC', 'score': 0.9885719, 'word': 'NLI', 'start': 712, 'end': 715}, {'entity_group': 'MISC', 'score': 0.7026406, 'word': 'MultiNLI', 'start': 749, 'end': 757}])
 list([{'entity_group': 'MISC', 'score': 0.99239606, 'word': 'Natural Language Inference', 'start': 682, 'end': 708}, {'entity_group': 'MISC', 'score': 0.9885719, 'word': 'NLI', 'start': 712, 'end': 715}])]
['881' '81.0' '1'
 "implies the second). So classifying pairs of sentences is a problem worth studying. In fact, in the GLUE benchmark (which is an academic benchmark for text classification), 8 of the 10 datasets are focused on tasks using pairs of sentences. That's why models like BERT are often pretrained with a dual objective: on top of the language modeling objective, they often have an objective related to sentence pairs. For instance, during pretraining, BERT is shown pairs of sentences and must predict both the value of randomly masked tokens and whether the second sentence follows from the first. Fortunately, the tokenizer from the Transformers library has a nice API to deal with pairs of sentences: you just have to pass them as two arguments to the tokenizer. On top of the input IDs and the attention mask we studied already, it returns a new field called token type IDs, which tells the model which tokens belong to the first sentence and which ones belong to the second sentence. Zooming in a"
 list([{'entity_group': 'MISC', 'score': 0.89614105, 'word': 'GLUE', 'start': 100, 'end': 104}, {'entity_group': 'ORG', 'score': 0.95332426, 'word': 'BERT', 'start': 264, 'end': 268}, {'entity_group': 'ORG', 'score': 0.9054393, 'word': 'BERT', 'start': 446, 'end': 450}, {'entity_group': 'ORG', 'score': 0.98398995, 'word': 'Transformers', 'start': 629, 'end': 641}])
 list([{'entity_group': 'MISC', 'score': 0.89614105, 'word': 'GLUE', 'start': 100, 'end': 104}, {'entity_group': 'ORG', 'score': 0.95332426, 'word': 'BERT', 'start': 264, 'end': 268}, {'entity_group': 'ORG', 'score': 0.9054393, 'word': 'BERT', 'start': 446, 'end': 450}, {'entity_group': 'ORG', 'score': 0.98398995, 'word': 'Transformers', 'start': 629, 'end': 641}])]
['882' '81.0' '2'
 'tokens belong to the first sentence and which ones belong to the second sentence. Zooming in a little bit, here are the input IDs, aligned with the tokens they correspond to, their respective token type ID and attention mask. We can see the tokenizer also added special tokens so we have a CLS token, the tokens from the first sentence, a SEP token, the tokens from the second sentence, and a final SEP token. If we have several pairs of sentences, we can tokenize them together by passing the list of first sentences, then the list of second sentences and all the keyword arguments we studied already, like padding=True. Zooming in at the result, we can see how the tokenizer added padding to the second pair of sentences, to make the two outputs the same length, and properly dealt with token type IDS and attention masks for the two sentences. This is then all ready to pass through our model!'
 list([]) list([])]
['883' '82.0' '0'
 '!--⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\nrendered properly in your Markdown viewer.\n-->\n\n# Download files from the Hub\n\nThe `huggingface_hub` library provides functions to download files from the repositories\nstored on the Hub. You can use these functions independently or integrate them into your\nown library, making it more convenient for your users to interact with the Hub. This\nguide will show you how to:\n\n* Download and cache a single file.\n* Download and cache an entire repository.\n* Download files to a local folder. \n\n## Download a single file\n\nThe [`hf_hub_download`] function is the main function for downloading files from the Hub.\nIt downloads the remote file, caches it on disk (in a version-aware way), and returns its local file path.\n\n<Tip>'
 list([{'entity_group': 'MISC', 'score': 0.7695052, 'word': 'Mark', 'start': 32, 'end': 36}, {'entity_group': 'MISC', 'score': 0.67116886, 'word': 'MDX', 'start': 101, 'end': 104}, {'entity_group': 'MISC', 'score': 0.8139757, 'word': 'Mark', 'start': 148, 'end': 152}, {'entity_group': 'LOC', 'score': 0.39038956, 'word': 'Hu', 'start': 196, 'end': 198}, {'entity_group': 'LOC', 'score': 0.47462282, 'word': 'Hu', 'start': 304, 'end': 306}, {'entity_group': 'LOC', 'score': 0.39509377, 'word': 'Hu', 'start': 454, 'end': 456}, {'entity_group': 'LOC', 'score': 0.3610518, 'word': 'Hub', 'start': 722, 'end': 725}])
 list([{'entity_group': 'MISC', 'score': 0.8139757, 'word': 'Mark', 'start': 148, 'end': 152}])]
['884' '82.0' '1'
 '<Tip>\n\nThe returned filepath is a pointer to the HF local cache. Therefore, it is important to not modify the file to avoid\nhaving a corrupted cache. If you are interested in getting to know more about how files are cached, please refer to our\n[caching guide](./manage-cache).\n\n</Tip>\n\n### From latest version\n\nSelect the file to download using the `repo_id`, `repo_type` and `filename` parameters. By default, the file will\nbe considered as being part of a `model` repo.\n\n```python\n>>> from huggingface_hub import hf_hub_download\n>>> hf_hub_download(repo_id="lysandre/arxiv-nlp", filename="config.json")\n\'/root/.cache/huggingface/hub/models--lysandre--arxiv-nlp/snapshots/894a9adde21d9a3e3843e6d5aeaaf01875c7fade/config.json\'\n\n# Download from a dataset\n>>> hf_hub_download(repo_id="google/fleurs", filename="fleurs.py", repo_type="dataset")\n\'/root/.cache/huggingface/hub/datasets--google--fleurs/snapshots/199e4ae37915137c555b1765c01477c216287d34/fleurs.py\''
 list([]) list([])]
['885' '82.0' '2'
 '```\n\n### From specific version\n\nBy default, the latest version from the `main` branch is downloaded. However, in some cases you want to download a file\nat a particular version (e.g. from a specific branch, a PR, a tag or a commit hash).\nTo do so, use the `revision` parameter:\n\n```python\n# Download from the `v1.0` tag\n>>> hf_hub_download(repo_id="lysandre/arxiv-nlp", filename="config.json", revision="v1.0")\n\n# Download from the `test-branch` branch\n>>> hf_hub_download(repo_id="lysandre/arxiv-nlp", filename="config.json", revision="test-branch")\n\n# Download from Pull Request #3\n>>> hf_hub_download(repo_id="lysandre/arxiv-nlp", filename="config.json", revision="refs/pr/3")\n\n# Download from a specific commit hash\n>>> hf_hub_download(repo_id="lysandre/arxiv-nlp", filename="config.json", revision="877b84a8f93f2d619faa2a6e514a32beef88ab0a")'
 list([]) list([])]
['886' '82.0' '3'
 '```\n\n**Note:** When using the commit hash, it must be the full-length hash instead of a 7-character commit hash.\n\n### Construct a download URL\n\nIn case you want to construct the URL used to download a file from a repo, you can use [`hf_hub_url`] which returns a URL.\nNote that it is used internally by [`hf_hub_download`].\n\n## Download an entire repository\n\n[`snapshot_download`] downloads an entire repository at a given revision. It uses internally [`hf_hub_download`] which\nmeans all downloaded files are also cached on your local disk. Downloads are made concurrently to speed-up the process.\n\nTo download a whole repository, just pass the `repo_id` and `repo_type`:\n\n```python\n>>> from huggingface_hub import snapshot_download\n>>> snapshot_download(repo_id="lysandre/arxiv-nlp")\n\'/home/lysandre/.cache/huggingface/hub/models--lysandre--arxiv-nlp/snapshots/894a9adde21d9a3e3843e6d5aeaaf01875c7fade\''
 list([]) list([])]
['887' '82.0' '4'
 '# Or from a dataset\n>>> snapshot_download(repo_id="google/fleurs", repo_type="dataset")\n\'/home/lysandre/.cache/huggingface/hub/datasets--google--fleurs/snapshots/199e4ae37915137c555b1765c01477c216287d34\''
 list([]) list([])]
['888' '82.0' '5'
 '```\n\n[`snapshot_download`] downloads the latest revision by default. If you want a specific repository revision, use the\n`revision` parameter:\n\n```python\n>>> from huggingface_hub import snapshot_download\n>>> snapshot_download(repo_id="lysandre/arxiv-nlp", revision="refs/pr/1")'
 list([]) list([])]
['889' '82.0' '6'
 '```\n\n### Filter files to download\n\n[`snapshot_download`] provides an easy way to download a repository. However, you don\'t always want to download the\nentire content of a repository. For example, you might want to prevent downloading all `.bin` files if you know you\'ll\nonly use the `.safetensors` weights. You can do that using `allow_patterns` and `ignore_patterns` parameters.\n\nThese parameters accept either a single pattern or a list of patterns. Patterns are Standard Wildcards (globbing\npatterns) as documented [here](https://tldp.org/LDP/GNU-Linux-Tools-Summary/html/x11655.htm). The pattern matching is\nbased on [`fnmatch`](https://docs.python.org/3/library/fnmatch.html).\n\nFor example, you can use `allow_patterns` to only download JSON configuration files:\n\n```python\n>>> from huggingface_hub import snapshot_download\n>>> snapshot_download(repo_id="lysandre/arxiv-nlp", allow_patterns="*.json")'
 list([{'entity_group': 'ORG', 'score': 0.532596, 'word': 'L', 'start': 542, 'end': 543}, {'entity_group': 'MISC', 'score': 0.94013286, 'word': 'GNU', 'start': 546, 'end': 549}, {'entity_group': 'MISC', 'score': 0.9653391, 'word': 'Linux', 'start': 550, 'end': 555}, {'entity_group': 'MISC', 'score': 0.8390096, 'word': 'JSON', 'start': 742, 'end': 746}])
 list([{'entity_group': 'MISC', 'score': 0.94013286, 'word': 'GNU', 'start': 546, 'end': 549}, {'entity_group': 'MISC', 'score': 0.9653391, 'word': 'Linux', 'start': 550, 'end': 555}, {'entity_group': 'MISC', 'score': 0.8390096, 'word': 'JSON', 'start': 742, 'end': 746}])]
['890' '82.0' '7'
 '```\n\nOn the other hand, `ignore_patterns` can exclude certain files from being downloaded. The\nfollowing example ignores the `.msgpack` and `.h5` file extensions:\n\n```python\n>>> from huggingface_hub import snapshot_download\n>>> snapshot_download(repo_id="lysandre/arxiv-nlp", ignore_patterns=["*.msgpack", "*.h5"])\n```\n\nFinally, you can combine both to precisely filter your download. Here is an example to download all json and markdown\nfiles except `vocab.json`.\n\n```python\n>>> from huggingface_hub import snapshot_download\n>>> snapshot_download(repo_id="gpt2", allow_patterns=["*.md", "*.json"], ignore_patterns="vocab.json")'
 list([]) list([])]
['891' '82.0' '8'
 '```\n\n## Download file(s) to local folder\n\nThe recommended (and default) way to download files from the Hub is to use the [cache-system](./manage-cache).\nYou can define your cache location by setting `cache_dir` parameter (both in [`hf_hub_download`] and [`snapshot_download`]).'
 list([{'entity_group': 'ORG', 'score': 0.431399, 'word': 'Hub', 'start': 103, 'end': 106}])
 list([])]
['892' '82.0' '9'
 'However, in some cases you want to download files and move them to a specific folder. This is useful to get a workflow\ncloser to what `git` commands offer. You can do that using the `local_dir` and `local_dir_use_symlinks` parameters:\n- `local_dir` must be a path to a folder on your system. The downloaded files will keep the same file structure as in the\nrepo. For example if `filename="data/train.csv"` and `local_dir="path/to/folder"`, then the returned filepath will be\n`"path/to/folder/data/train.csv"`.\n- `local_dir_use_symlinks` defines how the file must be saved in your local folder.\n  - The default behavior (`"auto"`) is to duplicate small files (<5MB) and use symlinks for bigger files. Symlinks allow\n    to optimize both bandwidth and disk usage. However manually editing a symlinked file might corrupt the cache, hence\n    the duplication for small files. The 5MB threshold can be configured with the `HF_HUB_LOCAL_DIR_AUTO_SYMLINK_THRESHOLD`\n    environment variable.'
 list([]) list([])]
['893' '82.0' '10'
 "environment variable.\n  - If `local_dir_use_symlinks=True` is set, all files are symlinked for an optimal disk space optimization. This is\n    for example useful when downloading a huge dataset with thousands of small files.\n  - Finally, if you don't want symlinks at all you can disable them (`local_dir_use_symlinks=False`). The cache directory\n    will still be used to check wether the file is already cached or not. If already cached, the file is **duplicated**\n    from the cache (i.e. saves bandwidth but increases disk usage). If the file is not already cached, it will be\n    downloaded and moved directly to the local dir. This means that if you need to reuse it somewhere else later, it\n    will be **re-downloaded**."
 list([]) list([])]
['894' '82.0' '11'
 'Here is a table that summarizes the different options to help you choose the parameters that best suit your use case.'
 list([]) list([])]
['895' '82.0' '12'
 '<!-- Generated with https://www.tablesgenerator.com/markdown_tables -->\n| Parameters | File already cached | Returned path | Can read path? | Can save to path? | Optimized bandwidth | Optimized disk usage |\n|---|:---:|:---:|:---:|:---:|:---:|:---:|\n| `local_dir=None` |  | symlink in cache | ✅ | ❌<br>_(save would corrupt the cache)_ | ✅ | ✅ |\n| `local_dir="path/to/folder"`<br>`local_dir_use_symlinks="auto"` |  | file or symlink in folder | ✅ | ✅ _(for small files)_ <br> ⚠️ _(for big files do not resolve path before saving)_ | ✅ | ✅ |\n| `local_dir="path/to/folder"`<br>`local_dir_use_symlinks=True` |  | symlink in folder | ✅ | ⚠️<br>_(do not resolve path before saving)_ | ✅ | ✅ |\n| `local_dir="path/to/folder"`<br>`local_dir_use_symlinks=False` | No | file in folder | ✅ | ✅ | ❌<br>_(if re-run, file is re-downloaded)_ | ⚠️<br>(multiple copies if ran in multiple folders) |'
 list([]) list([])]
['896' '82.0' '13'
 '| `local_dir="path/to/folder"`<br>`local_dir_use_symlinks=False` | Yes | file in folder | ✅ | ✅ | ⚠️<br>_(file has to be cached first)_ | ❌<br>_(file is duplicated)_ |'
 list([]) list([])]
['897' '82.0' '14'
 '**Note:** if you are on a Windows machine, you need to enable developer mode or run `huggingface_hub` as admin to enable\nsymlinks. Check out the [cache limitations](../guides/manage-cache#limitations) section for more details.\n\n## Download from the CLI\n\nYou can use the `huggingface-cli download` command from the terminal to directly download files from the Hub.\nInternally, it uses the same [`hf_hub_download`] and [`snapshot_download`] helpers described above and prints the\nreturned path to the terminal.\n\n```bash\n>>> huggingface-cli download gpt2 config.json\n/home/wauplin/.cache/huggingface/hub/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10/config.json'
 list([{'entity_group': 'MISC', 'score': 0.9902969, 'word': 'Windows', 'start': 26, 'end': 33}, {'entity_group': 'ORG', 'score': 0.85153943, 'word': 'CLI', 'start': 249, 'end': 252}, {'entity_group': 'LOC', 'score': 0.28012872, 'word': 'Hu', 'start': 359, 'end': 361}, {'entity_group': 'ORG', 'score': 0.32182837, 'word': '##b', 'start': 361, 'end': 362}])
 list([{'entity_group': 'MISC', 'score': 0.9902969, 'word': 'Windows', 'start': 26, 'end': 33}, {'entity_group': 'ORG', 'score': 0.85153943, 'word': 'CLI', 'start': 249, 'end': 252}])]
['898' '82.0' '15'
 '```\n\nYou can download multiple files at once which displays a progress bar and returns the snapshot path in which the files\nare located:\n\n```bash\n>>> huggingface-cli download gpt2 config.json model.safetensors\nFetching 2 files: 100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 23831.27it/s]\n/home/wauplin/.cache/huggingface/hub/models--gpt2/snapshots/11c5a3d5811f50298f278a704980280950aedb10'
 list([]) list([])]
['899' '82.0' '16'
 '```\n\nFor more details about the CLI download command, please refer to the [CLI guide](./cli#huggingface-cli-download).\n\n## Faster downloads\n\nIf you are running on a machine with high bandwidth, you can increase your download speed with [`hf_transfer`](https://github.com/huggingface/hf_transfer), a Rust-based library developed to speed up file transfers with the Hub. To enable it, install the package (`pip install hf_transfer`) and set `HF_HUB_ENABLE_HF_TRANSFER=1` as an environment variable.\n\n<Tip>\n\nProgress bars are supported in `hf_transfer` starting from version `0.1.4`. Consider upgrading (`pip install -U hf-transfer`) if you plan to enable faster downloads.\n\n</Tip>\n\n<Tip warning={true}>\n\n`hf_transfer` is a power user tool! It is tested and production-ready, but it lacks user-friendly features like advanced error handling or proxies. For more details, please take a look at this [section](https://huggingface.co/docs/huggingface_hub/hf_transfer).\n\n</Tip>'
 list([{'entity_group': 'MISC', 'score': 0.46390685, 'word': 'C', 'start': 32, 'end': 33}, {'entity_group': 'MISC', 'score': 0.75688773, 'word': 'C', 'start': 75, 'end': 76}, {'entity_group': 'ORG', 'score': 0.4218911, 'word': '##L', 'start': 76, 'end': 77}, {'entity_group': 'MISC', 'score': 0.79814416, 'word': 'Rust', 'start': 299, 'end': 303}, {'entity_group': 'ORG', 'score': 0.5033964, 'word': 'Hub', 'start': 364, 'end': 367}])
 list([])]
['900' '83.0' '0'
 'Two types of value-based methods [[two-types-value-based-methods]]\n\nIn value-based methods,\xa0**we learn a value function**\xa0that\xa0**maps a state to the expected value of being at that state.**\n\n<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/vbm-1.jpg" alt="Value Based Methods"/>\n\nThe value of a state is the\xa0**expected discounted return**\xa0the agent can get if it\xa0**starts at that state and then acts according to our policy.**\n\n<Tip>\nBut what does it mean to act according to our policy? After all, we don\'t have a policy in value-based methods since we train a value function and not a policy.\n</Tip>\n\nRemember that the goal of an\xa0**RL agent is to have an optimal policy π\\*.**\n\nTo find the optimal policy, we learned about two different methods:'
 list([]) list([])]
['901' '83.0' '1'
 'To find the optimal policy, we learned about two different methods:\n\n- *Policy-based methods:*\xa0**Directly train the policy**\xa0to select what action to take given a state (or a probability distribution over actions at that state). In this case, we\xa0**don\'t have a value function.**\n\n<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/two-approaches-2.jpg" alt="Two RL approaches"/>\n\nThe policy takes a state as input and outputs what action to take at that state (deterministic policy: a policy that output one action given a state, contrary to stochastic policy that output a probability distribution over actions).\n\nAnd consequently,\xa0**we don\'t define by hand the behavior of our policy; it\'s the training that will define it.**\n\n- *Value-based methods:*\xa0**Indirectly, by training a value function**\xa0that outputs the value of a state or a state-action pair. Given this value function, our policy\xa0**will take an action.**'
 list([]) list([])]
['902' '83.0' '2'
 'Since the policy is not trained/learned,\xa0**we need to specify its behavior.**\xa0For instance, if we want a policy that, given the value function, will take actions that always lead to the biggest reward,\xa0**we\'ll create a Greedy Policy.**\n\n<figure>\n  <img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/two-approaches-3.jpg" alt="Two RL approaches"/>\n  <figcaption>Given a state, our action-value function (that we train) outputs the value of each action at that state. Then, our pre-defined Greedy Policy selects the action that will yield the highest value given a state or a state action pair.</figcaption>\n</figure>\n\nConsequently, whatever method you use to solve your problem,\xa0**you will have a policy**. In the case of value-based methods, you don\'t train the policy: your policy\xa0**is just a simple pre-specified function**\xa0(for instance, the Greedy Policy) that\xa0uses the values given by the value-function to select its actions.'
 list([{'entity_group': 'MISC', 'score': 0.75729424, 'word': 'Policy', 'start': 226, 'end': 232}, {'entity_group': 'MISC', 'score': 0.7176625, 'word': 'Policy', 'start': 549, 'end': 555}, {'entity_group': 'MISC', 'score': 0.7922665, 'word': 'Policy', 'start': 906, 'end': 912}])
 list([])]
['903' '83.0' '3'
 'So the difference is:\n\n- In policy-based training,\xa0**the optimal policy (denoted π\\*) is found by training the policy directly.**\n- In value-based training,\xa0**finding an optimal value function (denoted Q\\* or V\\*, we\'ll study the difference below) leads to having an optimal policy.**\n\n<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/link-value-policy.jpg" alt="Link between value and policy"/>\n\nIn fact, most of the time, in value-based methods, you\'ll use\xa0**an Epsilon-Greedy Policy**\xa0that handles the exploration/exploitation trade-off; we\'ll talk about this when we talk about Q-Learning in the second part of this unit.\n\n\nAs we mentioned above, we have two types of value-based functions:\n\n## The state-value function [[state-value-function]]\n\nWe write the state value function under a policy π like this:'
 list([{'entity_group': 'MISC', 'score': 0.69594955, 'word': 'E', 'start': 520, 'end': 521}])
 list([])]
['904' '83.0' '4'
 'We write the state value function under a policy π like this:\n\n<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/state-value-function-1.jpg" alt="State value function"/>\n\nFor each state, the state-value function outputs the expected return if the agent **starts at that state** and then follows the policy forever afterward (for all future timesteps, if you prefer).\n\n<figure>\n<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/state-value-function-2.jpg" alt="State value function"/>\n  <figcaption>If we take the state with value -7: it\'s the expected return starting at that state and taking actions according to our policy (greedy policy), so right, right, right, down, down, right, right.</figcaption>\n</figure>\n\n## The action-value function [[action-value-function]]'
 list([]) list([])]
['905' '83.0' '5'
 '## The action-value function [[action-value-function]]\n\nIn the action-value function, for each state and action pair, the action-value function\xa0**outputs the expected return**\xa0if the agent starts in that state, takes that action, and then follows the policy forever after.\n\nThe value of taking action \\\\(a\\\\) in state \\\\(s\\\\) under a policy \\\\(π\\\\) is:\n\n<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/action-state-value-function-1.jpg" alt="Action State value function"/>\n<img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/action-state-value-function-2.jpg" alt="Action State value function"/>\n\n\nWe see that the difference is:\n\n- For the state-value function, we calculate\xa0**the value of a state \\\\(S_t\\\\)**\n- For the action-value function, we calculate\xa0**the value of the state-action pair ( \\\\(S_t, A_t\\\\) ) hence the value of taking that action at that state.**'
 list([]) list([])]
['906' '83.0' '6'
 '<figure>\n  <img src="https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/two-types.jpg" alt="Two types of value function"/>\n  <figcaption>\nNote: We didn\'t fill all the state-action pairs for the example of Action-value function</figcaption>\n</figure>\n\nIn either case, whichever value function we choose (state-value or action-value function),\xa0**the returned value is the expected return.**\n\nHowever, the problem is that\xa0**to calculate EACH value of a state or a state-action pair, we need to sum all the rewards an agent can get if it starts at that state.**\n\nThis can be a computationally expensive process, and that\'s\xa0**where the Bellman equation comes in to help us.**'
 list([{'entity_group': 'PER', 'score': 0.59929335, 'word': 'Bellman', 'start': 675, 'end': 682}])
 list([])]
['907' '84.0' '0'
 "The Hugging Face Course\n\nThis repo contains the content that's used to create the **[Hugging Face course](https://huggingface.co/course/chapter1/1)**. The course teaches you about applying Transformers to various tasks in natural language processing and beyond. Along the way, you'll learn how to use the [Hugging Face](https://huggingface.co/) ecosystem — [🤗 Transformers](https://github.com/huggingface/transformers), [🤗 Datasets](https://github.com/huggingface/datasets), [🤗 Tokenizers](https://github.com/huggingface/tokenizers), and [🤗 Accelerate](https://github.com/huggingface/accelerate) — as well as the [Hugging Face Hub](https://huggingface.co/models). It's completely free and open-source!\n\n## 🌎 Languages and translations"
 list([{'entity_group': 'MISC', 'score': 0.62895644, 'word': 'Hu', 'start': 4, 'end': 6}, {'entity_group': 'MISC', 'score': 0.9391146, 'word': 'Face', 'start': 12, 'end': 16}, {'entity_group': 'MISC', 'score': 0.4975515, 'word': 'Hu', 'start': 85, 'end': 87}, {'entity_group': 'MISC', 'score': 0.9364981, 'word': 'Face', 'start': 93, 'end': 97}, {'entity_group': 'MISC', 'score': 0.66256124, 'word': 'Transformers', 'start': 189, 'end': 201}, {'entity_group': 'MISC', 'score': 0.65597504, 'word': 'Hu', 'start': 306, 'end': 308}, {'entity_group': 'MISC', 'score': 0.7460257, 'word': 'Face', 'start': 314, 'end': 318}, {'entity_group': 'ORG', 'score': 0.7946036, 'word': '##face', 'start': 335, 'end': 339}, {'entity_group': 'ORG', 'score': 0.573499, 'word': 'co', 'start': 340, 'end': 342}, {'entity_group': 'ORG', 'score': 0.5939724, 'word': 'Transformers', 'start': 360, 'end': 372}, {'entity_group': 'MISC', 'score': 0.7103997, 'word': 'Hu', 'start': 614, 'end': 616}, {'entity_group': 'MISC', 'score': 0.890353, 'word': 'Face', 'start': 622, 'end': 626}])
 list([{'entity_group': 'MISC', 'score': 0.9391146, 'word': 'Face', 'start': 12, 'end': 16}, {'entity_group': 'MISC', 'score': 0.9364981, 'word': 'Face', 'start': 93, 'end': 97}, {'entity_group': 'MISC', 'score': 0.890353, 'word': 'Face', 'start': 622, 'end': 626}])]
['908' '84.0' '1'
 '| Language                                                                      | Source                                                                             | Authors                                                                                                                                                                                                                                                                                                                                                  |'
 list([]) list([])]
['909' '84.0' '2'
 '|:------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|'
 list([]) list([])]
['910' '84.0' '3'
 '| [English](https://huggingface.co/course/en/chapter1/1)                        | [`chapters/en`](https://github.com/huggingface/course/tree/main/chapters/en)       | [@sgugger](https://github.com/sgugger), [@lewtun](https://github.com/lewtun), [@LysandreJik](https://github.com/LysandreJik), [@Rocketknight1](https://github.com/Rocketknight1), [@sashavor](https://github.com/sashavor), [@osanseviero](https://github.com/osanseviero), [@SaulLu](https://github.com/SaulLu), [@lvwerra](https://github.com/lvwerra) |'
 list([{'entity_group': 'MISC', 'score': 0.97264296, 'word': 'English', 'start': 3, 'end': 10}, {'entity_group': 'ORG', 'score': 0.8263197, 'word': 'LysandreJik', 'start': 247, 'end': 258}, {'entity_group': 'ORG', 'score': 0.7762458, 'word': 'LysandreJik', 'start': 279, 'end': 290}, {'entity_group': 'ORG', 'score': 0.5507543, 'word': 'Rocketk', 'start': 295, 'end': 302}, {'entity_group': 'ORG', 'score': 0.5921037, 'word': 'Rocket', 'start': 329, 'end': 335}, {'entity_group': 'LOC', 'score': 0.33774, 'word': 'Saul', 'start': 437, 'end': 441}, {'entity_group': 'ORG', 'score': 0.55557317, 'word': '##L', 'start': 441, 'end': 442}, {'entity_group': 'LOC', 'score': 0.41685954, 'word': 'Saul', 'start': 464, 'end': 468}, {'entity_group': 'ORG', 'score': 0.6833526, 'word': '##L', 'start': 468, 'end': 469}])
 list([{'entity_group': 'MISC', 'score': 0.97264296, 'word': 'English', 'start': 3, 'end': 10}, {'entity_group': 'ORG', 'score': 0.8263197, 'word': 'LysandreJik', 'start': 247, 'end': 258}])]
['911' '84.0' '4'
 '| [Bengali](https://huggingface.co/course/bn/chapter1/1) (WIP)                  | [`chapters/bn`](https://github.com/huggingface/course/tree/main/chapters/bn)       | [@avishek-018](https://github.com/avishek-018), [@eNipu](https://github.com/eNipu)                                                                                                                                                                                                                                                                       |'
 list([{'entity_group': 'MISC', 'score': 0.94912994, 'word': 'Bengali', 'start': 3, 'end': 10}])
 list([{'entity_group': 'MISC', 'score': 0.94912994, 'word': 'Bengali', 'start': 3, 'end': 10}])]
['912' '84.0' '5'
 '| [German](https://huggingface.co/course/de/chapter1/1) (WIP)                   | [`chapters/de`](https://github.com/huggingface/course/tree/main/chapters/de)       | [@JesperDramsch](https://github.com/JesperDramsch), [@MarcusFra](https://github.com/MarcusFra), [@fabridamicelli](https://github.com/fabridamicelli)                                                                                                                                                                                                                                                          |'
 list([{'entity_group': 'MISC', 'score': 0.9958324, 'word': 'German', 'start': 3, 'end': 9}, {'entity_group': 'ORG', 'score': 0.64546096, 'word': 'JesperDramsch', 'start': 169, 'end': 182}, {'entity_group': 'ORG', 'score': 0.5958836, 'word': 'JesperDramsch', 'start': 203, 'end': 216}, {'entity_group': 'ORG', 'score': 0.7295725, 'word': 'MarcusF', 'start': 221, 'end': 228}, {'entity_group': 'ORG', 'score': 0.72445786, 'word': 'MarcusF', 'start': 251, 'end': 258}])
 list([{'entity_group': 'MISC', 'score': 0.9958324, 'word': 'German', 'start': 3, 'end': 9}])]
['913' '84.0' '6'
 '| [Spanish](https://huggingface.co/course/es/chapter1/1) (WIP)                  | [`chapters/es`](https://github.com/huggingface/course/tree/main/chapters/es)       | [@camartinezbu](https://github.com/camartinezbu), [@munozariasjm](https://github.com/munozariasjm), [@fordaz](https://github.com/fordaz)                                                                                                                                                                                                                 |'
 list([{'entity_group': 'MISC', 'score': 0.988898, 'word': 'Spanish', 'start': 3, 'end': 10}, {'entity_group': 'ORG', 'score': 0.45748246, 'word': '##ine', 'start': 175, 'end': 178}])
 list([{'entity_group': 'MISC', 'score': 0.988898, 'word': 'Spanish', 'start': 3, 'end': 10}])]
['914' '84.0' '7'
 '| [Persian](https://huggingface.co/course/fa/chapter1/1) (WIP)                  | [`chapters/fa`](https://github.com/huggingface/course/tree/main/chapters/fa)       | [@jowharshamshiri](https://github.com/jowharshamshiri), [@schoobani](https://github.com/schoobani)                                                                                                                                                                                                                                                       |'
 list([{'entity_group': 'MISC', 'score': 0.9967519, 'word': 'Persian', 'start': 3, 'end': 10}, {'entity_group': 'LOC', 'score': 0.32662338, 'word': '##har', 'start': 172, 'end': 175}])
 list([{'entity_group': 'MISC', 'score': 0.9967519, 'word': 'Persian', 'start': 3, 'end': 10}])]
['915' '84.0' '8'
 '| [French](https://huggingface.co/course/fr/chapter1/1)                         | [`chapters/fr`](https://github.com/huggingface/course/tree/main/chapters/fr)       | [@lbourdois](https://github.com/lbourdois), [@ChainYo](https://github.com/ChainYo), [@melaniedrevet](https://github.com/melaniedrevet), [@abdouaziz](https://github.com/abdouaziz)                                                                                                                                                                       |'
 list([{'entity_group': 'MISC', 'score': 0.9965553, 'word': 'French', 'start': 3, 'end': 9}])
 list([{'entity_group': 'MISC', 'score': 0.9965553, 'word': 'French', 'start': 3, 'end': 9}])]
['916' '84.0' '9'
 '| [Gujarati](https://huggingface.co/course/gu/chapter1/1) (WIP)                 | [`chapters/gu`](https://github.com/huggingface/course/tree/main/chapters/gu)       | [@pandyaved98](https://github.com/pandyaved98)                                                                                                                                                                                                                                                                                                           |'
 list([{'entity_group': 'MISC', 'score': 0.79310083, 'word': 'Gujarati', 'start': 3, 'end': 11}])
 list([])]
['917' '84.0' '10'
 '| [Hebrew](https://huggingface.co/course/he/chapter1/1) (WIP)                   | [`chapters/he`](https://github.com/huggingface/course/tree/main/chapters/he)       | [@omer-dor](https://github.com/omer-dor)                                                                                                                                                                                                                                                                                                                 |'
 list([{'entity_group': 'MISC', 'score': 0.9882181, 'word': 'Hebrew', 'start': 3, 'end': 9}])
 list([{'entity_group': 'MISC', 'score': 0.9882181, 'word': 'Hebrew', 'start': 3, 'end': 9}])]
['918' '84.0' '11'
 '| [Hindi](https://huggingface.co/course/hi/chapter1/1) (WIP)                    | [`chapters/hi`](https://github.com/huggingface/course/tree/main/chapters/hi)       | [@pandyaved98](https://github.com/pandyaved98)                                                                                                                                                                                                                                                                                                           |'
 list([{'entity_group': 'MISC', 'score': 0.97698396, 'word': 'Hindi', 'start': 3, 'end': 8}])
 list([{'entity_group': 'MISC', 'score': 0.97698396, 'word': 'Hindi', 'start': 3, 'end': 8}])]
['919' '84.0' '12'
 '| [Bahasa Indonesia](https://huggingface.co/course/id/chapter1/1) (WIP)                   | [`chapters/id`](https://github.com/huggingface/course/tree/main/chapters/id)       | [@gstdl](https://github.com/gstdl)                                                                                                                                                                                                                                                                                                           |'
 list([{'entity_group': 'MISC', 'score': 0.49643606, 'word': 'Bahasa', 'start': 3, 'end': 9}, {'entity_group': 'LOC', 'score': 0.5398611, 'word': 'Indonesia', 'start': 10, 'end': 19}])
 list([])]
['920' '84.0' '13'
 '| [Italian](https://huggingface.co/course/it/chapter1/1) (WIP)                  | [`chapters/it`](https://github.com/huggingface/course/tree/main/chapters/it)       | [@CaterinaBi](https://github.com/CaterinaBi), [@ClonedOne](https://github.com/ClonedOne),    [@Nolanogenn](https://github.com/Nolanogenn), [@EdAbati](https://github.com/EdAbati), [@gdacciaro](https://github.com/gdacciaro)                                                                                                                                                                  |'
 list([{'entity_group': 'MISC', 'score': 0.99556005, 'word': 'Italian', 'start': 3, 'end': 10}, {'entity_group': 'ORG', 'score': 0.80129033, 'word': 'CaterinaBi', 'start': 169, 'end': 179}, {'entity_group': 'ORG', 'score': 0.77593845, 'word': 'CaterinaBi', 'start': 200, 'end': 210}, {'entity_group': 'ORG', 'score': 0.75896734, 'word': 'C', 'start': 215, 'end': 216}, {'entity_group': 'ORG', 'score': 0.8478284, 'word': '##dOne', 'start': 220, 'end': 224}, {'entity_group': 'ORG', 'score': 0.6718634, 'word': 'C', 'start': 245, 'end': 246}, {'entity_group': 'ORG', 'score': 0.89272654, 'word': '##One', 'start': 251, 'end': 254}, {'entity_group': 'ORG', 'score': 0.79132074, 'word': 'Nolanogenn', 'start': 262, 'end': 272}, {'entity_group': 'ORG', 'score': 0.64989287, 'word': 'Nolanogenn', 'start': 293, 'end': 303}, {'entity_group': 'ORG', 'score': 0.8261651, 'word': 'EdAbati', 'start': 308, 'end': 315}, {'entity_group': 'ORG', 'score': 0.72905827, 'word': 'EdAbati', 'start': 336, 'end': 343}])
 list([{'entity_group': 'MISC', 'score': 0.99556005, 'word': 'Italian', 'start': 3, 'end': 10}, {'entity_group': 'ORG', 'score': 0.80129033, 'word': 'CaterinaBi', 'start': 169, 'end': 179}, {'entity_group': 'ORG', 'score': 0.8478284, 'word': '##dOne', 'start': 220, 'end': 224}, {'entity_group': 'ORG', 'score': 0.89272654, 'word': '##One', 'start': 251, 'end': 254}, {'entity_group': 'ORG', 'score': 0.8261651, 'word': 'EdAbati', 'start': 308, 'end': 315}])]
['921' '84.0' '14'
 '| [Japanese](https://huggingface.co/course/ja/chapter1/1) (WIP)                 | [`chapters/ja`](https://github.com/huggingface/course/tree/main/chapters/ja)       | [@hiromu166](https://github.com/@hiromu166), [@younesbelkada](https://github.com/@younesbelkada), [@HiromuHota](https://github.com/@HiromuHota)                                                                                                                                                                                                       |'
 list([{'entity_group': 'MISC', 'score': 0.99635965, 'word': 'Japanese', 'start': 3, 'end': 11}, {'entity_group': 'PER', 'score': 0.6000436, 'word': 'Hi', 'start': 267, 'end': 269}, {'entity_group': 'LOC', 'score': 0.4695385, 'word': '##rom', 'start': 269, 'end': 272}, {'entity_group': 'LOC', 'score': 0.45057854, 'word': '##H', 'start': 273, 'end': 274}, {'entity_group': 'PER', 'score': 0.502237, 'word': 'Hi', 'start': 299, 'end': 301}, {'entity_group': 'LOC', 'score': 0.5155775, 'word': '##rom', 'start': 301, 'end': 304}, {'entity_group': 'LOC', 'score': 0.49787095, 'word': '##H', 'start': 305, 'end': 306}])
 list([{'entity_group': 'MISC', 'score': 0.99635965, 'word': 'Japanese', 'start': 3, 'end': 11}])]
['922' '84.0' '15'
 '| [Korean](https://huggingface.co/course/ko/chapter1/1) (WIP)                   | [`chapters/ko`](https://github.com/huggingface/course/tree/main/chapters/ko)       | [@Doohae](https://github.com/Doohae), [@wonhyeongseo](https://github.com/wonhyeongseo), [@dlfrnaos19](https://github.com/dlfrnaos19), [@nsbg](https://github.com/nsbg)                                                                                                                                                                                                                                                                                                                     |'
 list([{'entity_group': 'MISC', 'score': 0.9969779, 'word': 'Korean', 'start': 3, 'end': 9}, {'entity_group': 'ORG', 'score': 0.3010402, 'word': 'Doo', 'start': 169, 'end': 172}, {'entity_group': 'ORG', 'score': 0.5336505, 'word': '##e', 'start': 174, 'end': 175}, {'entity_group': 'ORG', 'score': 0.3258203, 'word': 'Doo', 'start': 196, 'end': 199}])
 list([{'entity_group': 'MISC', 'score': 0.9969779, 'word': 'Korean', 'start': 3, 'end': 9}])]
['923' '84.0' '16'
 '| [Portuguese](https://huggingface.co/course/pt/chapter1/1) (WIP)               | [`chapters/pt`](https://github.com/huggingface/course/tree/main/chapters/pt)       | [@johnnv1](https://github.com/johnnv1), [@victorescosta](https://github.com/victorescosta), [@LincolnVS](https://github.com/LincolnVS)                                                                                                                                                                                                                   |'
 list([{'entity_group': 'MISC', 'score': 0.9934942, 'word': 'Portuguese', 'start': 3, 'end': 13}, {'entity_group': 'ORG', 'score': 0.45243102, 'word': 'Lincoln', 'start': 261, 'end': 268}, {'entity_group': 'ORG', 'score': 0.41484305, 'word': 'Lincoln', 'start': 291, 'end': 298}])
 list([{'entity_group': 'MISC', 'score': 0.9934942, 'word': 'Portuguese', 'start': 3, 'end': 13}])]
['924' '84.0' '17'
 '| [Russian](https://huggingface.co/course/ru/chapter1/1) (WIP)                  | [`chapters/ru`](https://github.com/huggingface/course/tree/main/chapters/ru)       | [@pdumin](https://github.com/pdumin), [@svv73](https://github.com/svv73)                                                                                                                                                                                                                                                                                 |'
 list([{'entity_group': 'MISC', 'score': 0.99896896, 'word': 'Russian', 'start': 3, 'end': 10}, {'entity_group': 'ORG', 'score': 0.45173988, 'word': '##ith', 'start': 107, 'end': 110}])
 list([{'entity_group': 'MISC', 'score': 0.99896896, 'word': 'Russian', 'start': 3, 'end': 10}])]
['925' '84.0' '18'
 '| [Thai](https://huggingface.co/course/th/chapter1/1) (WIP)                     | [`chapters/th`](https://github.com/huggingface/course/tree/main/chapters/th)       | [@peeraponw](https://github.com/peeraponw), [@a-krirk](https://github.com/a-krirk), [@jomariya23156](https://github.com/jomariya23156), [@ckingkan](https://github.com/ckingkan)                                                                                                                                                                         |'
 list([{'entity_group': 'MISC', 'score': 0.96796316, 'word': 'Thai', 'start': 3, 'end': 7}])
 list([{'entity_group': 'MISC', 'score': 0.96796316, 'word': 'Thai', 'start': 3, 'end': 7}])]
['926' '84.0' '19'
 '| [Turkish](https://huggingface.co/course/tr/chapter1/1) (WIP)                  | [`chapters/tr`](https://github.com/huggingface/course/tree/main/chapters/tr)       | [@tanersekmen](https://github.com/tanersekmen), [@mertbozkir](https://github.com/mertbozkir), [@ftarlaci](https://github.com/ftarlaci), [@akkasayaz](https://github.com/akkasayaz)                                                                                                                                                                       |'
 list([{'entity_group': 'MISC', 'score': 0.99724764, 'word': 'Turkish', 'start': 3, 'end': 10}])
 list([{'entity_group': 'MISC', 'score': 0.99724764, 'word': 'Turkish', 'start': 3, 'end': 10}])]
['927' '84.0' '20'
 '| [Vietnamese](https://huggingface.co/course/vi/chapter1/1)               | [`chapters/vi`](https://github.com/huggingface/course/tree/main/chapters/vi)       | [@honghanhh](https://github.com/honghanhh)                                                                                                                                                                                                                                                                                                               |'
 list([{'entity_group': 'MISC', 'score': 0.99846673, 'word': 'Vietnamese', 'start': 3, 'end': 13}])
 list([{'entity_group': 'MISC', 'score': 0.99846673, 'word': 'Vietnamese', 'start': 3, 'end': 13}])]
['928' '84.0' '21'
 '| [Chinese (simplified)](https://huggingface.co/course/zh-CN/chapter1/1)  | [`chapters/zh-CN`](https://github.com/huggingface/course/tree/main/chapters/zh-CN) | [@zhlhyx](https://github.com/zhlhyx), [petrichor1122](https://github.com/petrichor1122), [@1375626371](https://github.com/1375626371)                                                                                                                                                                                                                    |'
 list([{'entity_group': 'MISC', 'score': 0.9904013, 'word': 'Chinese', 'start': 3, 'end': 10}])
 list([{'entity_group': 'MISC', 'score': 0.9904013, 'word': 'Chinese', 'start': 3, 'end': 10}])]
['929' '84.0' '22'
 '| [Chinese (traditional)](https://huggingface.co/course/zh-TW/chapter1/1) (WIP) | [`chapters/zh-TW`](https://github.com/huggingface/course/tree/main/chapters/zh-TW) | [@davidpeng86](https://github.com/davidpeng86)                                                                                                                                                                                                                                                                                                           |'
 list([{'entity_group': 'MISC', 'score': 0.9921605, 'word': 'Chinese', 'start': 3, 'end': 10}])
 list([{'entity_group': 'MISC', 'score': 0.9921605, 'word': 'Chinese', 'start': 3, 'end': 10}])]
